                                                Understanding the Linux Kernel (Third Edition)
Linux kernel version : 2.6.34.1

Chapter 1 : Introducation
    Linux joins System V Release 4 (SVR4),developed by AT&T.
    other UNIX OS or UNIX-like OS :
      4.4 BSD
      Digital UNIX
      AIX
      HP-UX
      Solaris
      Mac OS X
      ...

      (opensource)
      FreeBSD
      NetBSD
      OpenBSD
      Linux
      ...

    The common attributes between Linux and well-known commercial Unix kernels :
      monolithic kernel
      compiled and statically linked traditional Unix kernels
      (of course support module for dynamically load and unload)
      kernel threading
      multithreaded application support(lightweight process LWP supporting)
      preemptive kernel
      multiprocessor support(SMP)
      filesystem

      streams(but Linux has no analogue to the STREAMS I/O subsystem introduced in SVR4)  

    The advantages of Linux :
      Linux is cost-free
      Linux is fully customizable in all its components
      Linux runs on low-end,inexpensive hardware platforms
      Linux is powerful
      Linux developers are excellent programmers
      The linux kernel can be very small and compact
      Linux is highly compatible with many common operating systems
      Linux is well supported

    Basic Operating System Concepts :
      the operating system must fulfill two main objectives :
        >  interact with the hardware components,servicing all low-level programmable elements
	       included in the hardware platform.
	    >  provide an execution environment to the applications that run on the computer system.
	
      modern OS does not allow user program interact with hardware directly and forbid them to
      access arbitrary memory locations.
      in particular,the hardware introduces at least two different execution modes for the CPU :
        a nonprivileged mode for user programs
	    a privileged mode for the kernel
	    /*  UNIX calls these
	     *  User Mode and Kernel Mode
	     */

    Multiuser Systems :
      A multiuser system is a computer that is able to concurrently and independently execute several
      applications belonging to two or more users.

      Concurrently :
        applications can be active at the same time and contend for various resources such as CPU,memory,
	    hard disks,and so on.
      Independently :
        each application can perform its task with no concern for what the applications of the other uses are
	    doing.

      Multiuser operating systems must include several features :
        >  An authentication mechanism for verifying the user's identify
	    >  A protection mechanism against buggy user programs that could block other applications running 
	       in the system
	    >  A protection mechanism against malicious user programs that could interfere with or spy on the 
	       activity of other users
	    >  An accounting mechanism that limits the amount of resource units assigned to each user

      To ensure safe protection mechanisms,operating systems must use the hardware protection associated 
      with the CPU privileged mode.
      Unix is a multiuser system that enforces the hardware protection of system resources.

    Users and Groups :
      in a multiuser system,each user has a private space on the machine,the operating system must ensure that
      the private portion of a user space is visible only to its owner.Unix-like system use UserID or UID as
      user identifier,it is a unique number.
      to selectively share material with other users,each user is a member of one or more user groups,which 
      are identified by a unique number called a user group ID.each file is associated with exactly one group.
      any Unix-like operating system has a special user called root or superuser,the root user can do almost
      everything,because the operating system does not apply the usual protection mechanism to it.

    Processes :
      A process can be defined either as "an instance of a program in execution" or  as the "execution context"
      of a running program.
      in traditional operating systems,a process executes a single sequence of instructions in an address space;
      the address space is the set of memory addresses that the process is allowed to reference.

      multiple processes environment :
        in modern operating system allow processes with multiple execution flows,that is,multiple sequences
	    of instructions executed in the same address space.
	    system that allow concurent active processes are said to be multiprogramming or multiprocessing.

	  multiuser systems must enforce an multiple processes environment,but some multiprocessing operating
	  systems are not multiuser.

	  it is important to distinguish programs from processes;several processes can execute the same program
	  concurently,while the same process can execute several programs sequentially.

	  scheduler is an important system compoent in multiprocessing system,which process should be hold the 
	  CPU to execute is determined by scheduler.
	
	  preemptable :
	    some operating systems allow only nonpreemptable processes,which means that the scheduler is invoked
	    only when a process voluntarily relinquishes the CPU.but process of a multiuser system must be
	    preemptable.

	    UNIX is a multiuer and multiprocessing operating system with  preemptable processes.

	    UNIX-like operating systems adopt a process/kernel model.each process has the illusion that it is the
	    only process on the machine,and it has exclusive access to the operating system services.

    Kernel Architecture :
      monolithic kernel,each kernel layer is integrated into the whole kernel program and runs in Kernel Mode
      on behalf of the current process.

      microkernel operating systems demand a very small set of functions from the kernel,generally including a 
      few synchronization primitives,a simple scheduler,and an interprocess communication mechanism.
      several system processes that run on top of the microkernel implement other operating system layer functions,
      like memory allocators,device drivers,and system call handlers.

      comparison between monolithic kernel and microkernel :
        1>  microkernel is slower than monolithic kernel,because kernel layer communication has a cost.
	    2>  microkernel force the system programmers to adopt a modularized approach,that means microkernel
	        is very modularized.every relativly kernel layer is independent program that must interact with
	        the other layers through well-defined and clean software interfaces.
	    3>  microkernel can be easily ported to other architectures fairly easily.all hardware-dependent components
	        are generally encapsulated in the microkernel code.
        4>  microkernel tend to make better use of random access memory than monolithic kernel,system processes
	        that are not implementing needed functionalities might be swapped out or destroyed.

        UNIX and UNIX-like operating system almost satisfy all advantages of microkernel.

      the main advantages of using modules include :
        >  a modularized approach.
	    >  platform independence
	    >  frugal main memory usage
	    >  no performance penalty

    An Overview of Unix Filesystem :
      the UNIX operating system design is centered on its filesystem,which has several interesting characteristics.

        Files - A Unix file is an information container structured as a sequence of bytes;the kernel does not
	      	    interpret the contents of a file.

        Hard and Soft Links - A filename included in a directory is called a file hard link,or more simply,a link.
	     	      	          Soft links also called symbolic links,symbolic links are short files that contain an
			                  arbitrary pathname of another file.

		Hard links limitations :
		  it is not possible to create hard links for directories.
		  links can be created only among files included in the same filesystem.

	    File Types - File type represent what the file is.
	      Unix files may have one of the following types :
		    Regular file
		    Directory
		    Symbolic link
		    Block-oriented device file
		    Character-oriented device file
		    Pipe and named pipe
		    Socket

	    File Descriptor and Inode - A file descriptor is a number greater than or equal to zero,the number
	     		    	            associared with a file data structure which represent the file opened by
				                    process.
				                    All information needed by the filesystem to handle a file is included in a 
				                    data structure called an inode.each file has its own inode,which the filesystem
				                    uses to identify the file.

        Access Rights and File Mode - there are three types of access rights :
	      read
		  write
		  execute
		  /*  access rights occupied nine bits  */
				      
		Three additonal flags :
		  suid(Set User ID)
		  sgid(Set Group ID)
		  sticky - an executable file with the sticky flag set corresponds to request to
		  	       the kernel to keep the program in memory after its execution terminates.

		File Mode is a mode mixed Access Rights and Additonal flags.

        File-Handling System Calls -  kernel provide some primitives to user mode to help user interact with actual
	 	             	      	      file stored in block device.
				                      opening a file - open
				                      accessing an opened file - read write lseek ...
				                      closing a file - close
				                      renaming and deleting a file - rename unlink link ...
				       
    An Overview of Unix Kernels :
      Unix kernels provide an execution environment in which applications may run.
      
      The Process/Kernel Mode - Actually,some CPUs can have more than two execution states,but all standard Unix
      	  		       	        kernels use only Kernel Mode and User Mode.
	    A program usually executes in User Mode and switches to Kernel Mode only when requesting
		a service provided by the kernel.when the kernel has satisfied the program's request,it
		puts the program back in User Mode.the way is system calls.
		after sets up parameters of syscall,then executes the hardware-dependent CPU instruction to
		switch from User Mode to Kernel Mode.
		Unix systems include a few privileged processes called kernel threads with the following characteristics :
		  >  they run in Kernel Mode in the kernel address space
		  >  they do not interact with users,and thus do not require terminal devices
		  >  they are usually created during system startup and remain alive until the system
		     is shut down.
		Unix kernels do much more than handle system calls;in fact,kernel routines can be actived in several ways :
		  >  A process invokes a system call
		  >  the CPU executing the process signals an exception,which is an unusual condition such as
		     an invalid instruction.the kernel handles the exception on behalf of the process that 
		     caused it.
		  >  A peripheral device issues an interrupt signal to the CPU to notify it of an event such
		     as a request for attention,a status change,of the completion of an I/O operation.
		     each interrupt signal is dealt by a kernel program called an interrupt handler.
		  >  A kernel thread is executed.because it runs in Kernel Mode,the corresponding program
		     must be considered part of the kernel.

      Process Implementation - To let the kernel manage processes,each process is represented by a process descriptor that
      	      		           includes information about the current state of the process.
			                   that include :
			                     >  the program counter(PC) and stack pointer(SP) registers
				                 >  the general purpose registers
				                 >  the floating point registers
				                 >  the processor control registers(Processor Status Word) containing information about
				                    the CPU state
				                 >  the memory management registers used to keep track of the RAM accessed by the process

	  When a process is scheduled,then kernel use the former stored information to recover process status,
	  and set IP to the next instruction.(it also known as PC,process counter,but IP is a instruction register)

      Reentrant Kernels - All Unix kernels are reentrant.this means that several processes may be executing in Kernel Mode at
      			          the same time.of course,on uniprocessor systems,only one process can progress,but many can be blocked
			              in Kernel Mode when waiting for the CPU or the completion of some I/O operation.
	    reentrant functions : the functions they modify only local variables and do not alter global data structures.
			                  (reentrant functions,that is how some real-time kernels are implemented)
			                  but kernel can include nonreentrant functions and use locking mechanisms to ensure that only one process
			                  can execute a nonreentrant function at a time.

			  generial kernel control path :
			    Run process -> Timer interrupt -> Deal with interrupt -> Schedule tasks -> Run process -> ...

			  when one of the following events occurs,the CPU will enter a new path to do something :
			    >  a process executing in User Mode invokdes a system call.if the service would not be satisfied,
			       then scheduler pick next process to run,the former process enter sleeping until condition is
			       satisifed or wake up by a signal.
			       (system calls is triggered via soft interrupt,on x86,it is "int 0x80")
			    >  the CPU detects an exception.CPU must starts the execution of a suitable procedure.
			       after the procedure terminates,CPU return to the path before the exception is detected.
			    >  a hardware interrupt occurs,and the interrupts enabled.
			       CPU must starts processing another kernel control path to handle the interrupt.
			    >  an interrupt occurs while the CPU is running with kernel preemption enabled,and a higher priority
			       process is runnable.(lower intterupt could be preempted by higher interrupt)

			  three states of CPU current be :
			    >  running a process in User Mode			        (process context)
			    >  running an exception or a system call handler	(process context)
			    >  running an interrupt handler	     		        (interrupt context)

      Process Address Space - Each process runs in its private address space.A process running in User Mode refers to private stack,
      	      	      	      data,and code areas.when running in Kernel Mode,the process addresses the kernel data and code areas
			                  and uses another private stack.
			                  reentrant kernel,each kernel control path refers to its own private kernel stack.
			                  sometimes,kernel shares process address space to another same program,certainly that is code area.
			                  but process also can initiativly shares its address space to another different program.(IPC)

      Synchronization and Critical Regions - reentrant kernel requires the use of synchronization.
      		      	  	   	                 if a kernel control path is suspended while acting on a kernel data structure,no other
					                         kernel control path should be allowed to act on the same data structure unless it has
					                         been reset to a consistent state.
					                         critical region :
					                           any section of code that should be finished by each process that begins it before
					                           another process can enter it.

      Kernel preemption disabling - A synchronization mechanism applicable to preemptive kernel consists of disabling kernel 
      	     			            preemption before entering a critical region and reenabling it right after levaing the region.
				                    nonpreemptability is not enough for multiprocessor systems,because two kernel control paths running
				                    on different CPUs can concurrently access the same data structure.

      Interrupt disabling - Another synchronization mechanism for uniprocessor systems consists of disabling all hardware interrupts
      			            before entering a critical region and reenabling them right after leaving it.
			                if critical region is too large,this will down system efficiency;moreover,on a multiprocessor system,
			                disabling interrupts on the local CPU is not sufficient.

      Semaphores - A semaphore is simply a counter associated with a data structure;it is checked by all kernel threads before they
      		       try to access the data structure.
		           each semaphore may be viewed as an object composed of :
		             an integer variable
		             a list of waiting processes
		             two atomic method : down() and up()

		             down() decrease semaphore value,up() increase semaphore value.if its value is less than 0,process have to wait on
		             it until semaphore is available.

      Spin locks - some kernel data structures should be protected from being concurrently accessed by kernel control paths that run
      	   	       on different CPUs.in this case,if the time required to update the data structure is short,a semaphore could be very
		           inefficient.
		           a spink lock is very similar to semaphore,but it has no process list;when a process finds the lock closed by another
		           process,it "spins" around repeatedly,executing a tight instruction loop until the lock becomes open.
		           of course,spin locks are useless in a uniprocessor environment.

      Avoiding deadlocks - the simplest case of deadlock occurs when process p1 gains access to data structure a and process p2 gains
      	       		       access to b,but p1 then waits for b and p2 waits for a.
			               Several operating systems,including Linux,avoid this problem by requesting locks in a predefined order.

    Signals and Interprocess Communication :
      Unix signals provide a mechanism for notifying processes of system events.
      there are two kinds of system events :
        Asynchronous notifications
	    Synchronous notifications

      POSIX standard defines about 20 different signals,2 of which are user-definable and may be used as a primitive mechanism for
      communication and synchronization among processes in UserMode.

      process may ignore the signal or asynchronously execute a specific procedure(signal handler),kernel provides the default
      signal handler for every signal.
      the default actions are :
        terminate the process
	    write the execution context and the contents of the address space in a file(coredump) and terminate the process
	    ignore the signal
	    suspend the process
	    resume the process's execution,if it was stopped

      SystemV IPC(AT&T's Unix System V) - semaphores, message queues, shared memory
      POSIX standard also defined some IPCs - posix semaphores, posix message queues, posix shared memory

    Process Management : 
      Unix makes a neat distinction between the process and the program it is executing.
      process is the program which is loadded into memory,it contains the resources all the program needs.
      the program it is executing,that means it had been loadded and the process is TASK_RUNNING.
      a parent process is such process it has been called fork() syscall,fork() would create a new process and its resources
      is duplicated to parent process,the process is child process.

      Copy-On-Write - this approach defers page duplication until the last moment(i.e., until the parent or the child is
      		          required to write into a page).
		              the naive implementation of fork() was quite time consuming.

      Zombie process - a process would exited if it called _exit(),and kernel send SIGCHLD to its parent.
      	     	       the zombie process is such process it had been exited but its status had not been checked,generally,
		               this work should be completed by its parent.
		               when the process exited,some resources are still effect and saved in its process address space,until
		               parent calls wait() systemcall to wait the process,that would destroy all resources.
		               if parent exited before wait its child,then kernel process init will adopts childs,that procedure calls
		               wait() periodically on its child processes.

      Process groups and login sessions - modern Unix operating systems introduce the notion of process groups to represent a 
      	      	     	       		      "job" abstraction.
					                      a job,it might be combined by several processes,and they are in the same process group,
					                      the group leader is the process whose PID is equal to the group ID.
					                      a new process would be inserted into its parent's group initially.
					                      normally,a job is treated as a single entity.
					                      moder Unix kernels also introduce login sessions.
					                      informally,a login session contains all processes that are descendants of the process that
					                      has started a working session on a specific terminal--usually,the first command shell process
					                      created for the user.
					                      all processes in a process group must be in the same login session,a login session may have
					                      several process groups active simultaneously;one of these process groups is always in the
					                      foreground,which means that it has access to the terminal.others are in the background.

    Memory Management :
      Virtual memory -  all recent Unix systems provide a useful abstraction called virtual memory.
      	      	     	virtual memory acts as a logical layer between the application memory requests and the hardware
			Memory Management Unit.(MMU)
			its puposes and advantages :
			  several processes can be executed concurrently.
			  it is possible to run applications whose memory needs are larget than the available physical memory.
			  processes can execute a program whose code is only partially loaded in memory.
			  each process is allowed to access a subset of the available physical memory.
			  processes can share a single memory image of a library or program.
			  programs can be relocatable--that is,they can be placed anywhere in physical memory.
			  programmers can write machine-independent code,because they do not need to be concerned about physical
			  memory organization.
			the main ingredient of a virtual memory subsystem is the notion of virtual address space.

      Random access memory usage - all Unix operating systems clearly distinguish between two portions of the
      	     	    	   	       random access memory(RAM).a few megabytes are dedicated to storing the kernel
				                   image.the remaining portion of RAM is usually handled by the virtual memory
				                   system and is used in three possible ways :
				                     to satisfy kernel requests for buffers,descriptors,and other dynamic kernel data structures.
				                     to satisfy process requests for generic memory areas and for memory mapping of files.
				                     to get better performance from disks and other buffered devices by means of caches.

      Kernel Memory Allocator - the kernel Memory Allocator(KMA) is a subsystem that tries to satisfy the requests fof memory areas
      	     	    	      	from all parts of the system.
				                a good KMA should have the following features :
				                  it must be fast.actually,this is the most crucial attribute,because it is invoked by all kernel
				                  subsystems.
				                  it should minimize the amount of wasted memory.
				                  it should try to reduce the memory fragmentation problem.
				                  it should be able to cooperate with the other memory management subsystems to borrow and release
				                  page frames from them.
				                  all recent Unix operating systems adopt a memory allocation strategy called demand pagine.
				                  with demand paging,a process can start program execution with none of its pages in physical memory.

      Caching - a good part of the available physical memory is used as cache for hard disks and other block devices.this is because
      	      	hard drives are very slow.
		        data read previously from disk and no longer used by any process continue to stay in RAM,and defer writing to disk as
		        long as possible.
		        the sync() system call forces disk synchronization by writing all of the "dirty" buffers into disk.to avoid data loss,
		        all operating systems take care to periodically write dirty buffers back to disk.

    Device Drivers :
      the kernel interacts with I/O devices by means of device drivers.device drivers are included in the kernel and consist of
      data structures and functions that control one or more devices.
      each driver interacts with the remaining part of the kernel through a specific interface,this approach has the following
      advantages :
        >  device-specific code can be encapsulated in a specific module.
	    >  vendors can add new devices without knowing ther kernel source code,only the interface specifications must be known.
	    >  the kernel deals with all devices in a uniform way and accesses them through the same interface.
	    >  it is possible to write a device driver as a module that can be dynamically loaded in the kernel without requiring
	       the system to be rebooted.it is also possible to dynamically unload a module that is no longer needed,therefore
	       minimizing the size of the kernel image strored in RAM.


/*  END OF CHAPTER1  */


Chapter 2 : Memory Addressing
    Memory Address :
      the three kinds of addresses on 80x86 microprocessors >
        1>  logical address
	        included in the machine language instructions to specify the address of an operand or of an instruction.
	        this type of address embodies the well-known 80x86 segmented architecture.
	        each logical address consists of a segment and an offset that denotes the distance from the start of
	        the segment to the actual address.

	    2>  linear address(also known as virtual address)
	        a signle 32-bit unsigned integer that can be used to address up to 4GB.
	        linear addresses are usually represented in hexadecimal notation,their values range from
	        0x00000000 -- 0xffffffff

    	3>  physical address
    	    used to address memory cells in memory chips.
    	    they correspond to the electrical signals sent along the address pins of the microprocessor to the memory bus.
    	    they are represented as 32-bit or 36-bit unsigned integers.

      MMU Memory Management Unit,it transforms a logical address into a linear address by means of a hardware circuit called
      a segmentation unit.
      Page Unit,it transforms the linear address into a physical address.

      In multiprocessor systems,RAM chips may be accessed concurrently(CPUs share same memory).
      Memory Arbiter is inserted between the bus and every RAM chip,it is used to ensure serially operations perform.
      (if the RAM chip is free or it is busy servicing a request by another CPU(in this case,it delay the CPU's request))
      even uniprocessor systems use memory arbiters,because they include specialized processors called DMA(Direct Memory Access)
      controllers that operate concurrently with the CPU.
      (GPU might use DMA zone)

      /*  Memory Arbiter is unvisible to program  */

    Segmentation in Hardware :
      (80386 model)
      Intel microprocessors perform address translation in two different ways called "real mode" and "protected mode".

      Segment selectors and Segmentation registers :
        a logical address consists of two parts : a segment identifier and an offset that specifies the relative address
	    within the segment.

    	Logical Address : (Segment Identifier , Offset)
    	segment identifier : a 16-bit field called the Segment Selector.
    	offset : a 32-bit field associated the segment identifier(Segment Selector).

    	Segment Selector { index (15-3), TI (2), RPL (1-0) }
    	/*  TI : Table Indicator
    	 *  RPL : Requestor Privilege Level
    	 */

    	processor provides six segmentation registers for retrive segment selector quickly :
    	  cs, ss, ds, es, fs, gs
    	  /*  the only purpose is to hold Segment Selectors  */
    	program could reuse some segmentation registers,but have to store its contents in memory,and then
    	restore it later.

    	cs : code segment register,which points to a segment containing program instructions.
    	ss : stack segment register,which points to a segment containing the current program stack.
    	ds : data segment register,which points to a segment containing global and static data.
    	es,fs,gs : these are extra segment registers available for far pointer addressing like video
    		       memory and such.
            
    	the remaining three segmentation registers are general purpose and may refer to arbitrary data segments.

    	cs register has another important function :
    	  it includes a 2-bit field that specifies the Current Privilege Level(CPL) of the CPU.
    	  value 0 denotes the highest privilege level,value 3 denotes the lowest one.
    	  (Linux only use 0(kernel mode) and 3(user mode))

          Segment Descriptors : 
            Global Descriptor Table(GDT)
    	    Local Descriptor Table(LDT)

    	each segment is represented by an 8-byte segment descriptor,they are stored either in GDT or LDT.
    	program is allowed to have its own LDT,if it have to stores some segments besides those stored in GDT.

    	gdtr : gdtr control register,it contains the address and size of the GDT in main memory.
    	ldtr : ldtr control register,it contains the address and size of the current LDT in main memory.

	Format of Segment Descriptor : (every 8-byte 64-bit)
	  Fields >
	    Base :      contains the linear address of the first byte of the segment.
	    G :         granularity flags,if it is cleared(0),the segment size is expressed in bytes;otherwise,it is
	      	        expressed in multiples of 4096 bytes.
	    Limit :     holds the offset of the last memory cell in the segment,thus binding the segment length.
	    S :         system flag,if it is cleared(0),the segment is a system segment that stores critical data 
	      	        structures such as the Local Descriptor Table;otherwise it is a normal code or data segment.
        Type :      Characterizes the segment type and its access rights.
	    DPL :       Descriptor Privilege Level,used to restrict accesses to the segment.it represents the minimal
	    	        CPU privilege level requested for accessing the segment.
        P :         Segment-Present flag,it is equal to 0 if the segment is not stored currently in main memory.
	      	        Linux always sets this flag (bit 47) to 1,because it never swaps out whole segments to disk.
        D or B :    called D or B depending on whether the segment contains code or data.
	      	        its meaning is slightly different in the two cases,but it is basically set(equal to 1) if the
		            addresses used as segment offsets are 32 bits long,and it is cleared if they are 16 bits long.
	    AVL :       may be used by the operating system,but it is ignored by Linux.

	  Composing :
	    0-15 : LIMIT (0-15)
	    16-31 : BASE (0-15)
	    32-39 : BASE (16-23)
	    40-43 : TYPE
	    44 : S
	    45-46 : DPL
	    47 : P
	    48-51 : LIMIT (16-19)
	    52 : AVL
	    53 : none
	    54 : D or B
	    55 : G
	    56-63 : BASE (24-31)

	The Segment Descriptors widely used in Linux :
	  Code Segment Descriptor -
	    it may be included either GDT or LDT,the descriptor has the S flag set.
	  Data Segment Descriptor - 
	    data segment.included either GDT or LDT,has S flag set.
	    stack segments are implemented by means of generic data segments.
	  Task State Segment Descriptor(TSSD) -
	    task state segment,it is a segment used to save the contents of the processor registers;it can appear
	    only in the GDT.The corresponding Type field has the value 11 or 9,depending on whether the corresponding
	    process is currently executing on a CPU.has no S flag.
	  Local Descriptor Table Descriptor(LDTD) -
	    a segment containing an LDT;it can appear only in the GDT.
	    the corresponding Type field has the value 2.has no S flag.

	Fast Access to Segment Descriptors :
	  80x86 processor provides an additional nonprogrammable register for each of the six programmable segmentation registers.
	  each nonprogrammable register contains the 8-byte segment descriptor specified by the segment selector contained in the
	  corresponding segmentation register.
	  every time a segment selector is loaded in a segmentation register,the corresponding segment descriptor is loaded from
	  memory into the matching nonprogrammable CPU register.

	    segs1 --> cs  &&  segd1 --> unprogrammable(cs)

	  CPU only need to access GDT or LDT is the time to change the contents of the segmentation registers!

	  segment selector fields :
	    index - identifies the segment descriptor entry contained in the GDT or in the LDT.
	    TI    - table indicator,specifies whether the segment descriptor is inclued in the GDT(TI = 0) or
	    	    in the LDT(TI = 1).
	    RPL   - requestor privilege level,specifies the current privilege level of the CPU when the corresponding
	    	    segment selector is loaded in to the cs register;it also may be used to selectively weaken the
		        processor privilege level when accessing data segments.

      segment descriptor index = GDT + segment selector index field * 8 (every segment descriptor occupy 8-byte)

	  ! the first entry in GDT always set to 0,this ensures that logical address with a null segment selector will be considered
	    invalid,thus causing a processor exception.
	  ! maximum of number of segment descriptors in GDT is 8191(2^13 - 1).

	Segmentation Unit :
	  segmentation unit handle address translation.
	  translate logical address to linear address : (in : read, out : write)
	  /*  logical addres : (composed by) segment identifer, offset  */

	    if register changed,then in segment register
	    else in nonprogrammable register
	    ->
	    if TI == 1,  in LDT(ldtr)
	    else TI == 0,  in GDT(gdtr)
	    ->
	    in index
	    ->
	    segment descriptor = index * 8 + GDT
	    ->
	    in segment descriptor
	    ->
	    in BASE field
	    ->
	    linear address = BASE + offset (LIMIT determine the length of the segment)

	Segmentation in Linux :
	  in fact,segmentation and paging do same work,linear address to physical space.
	  linux prefers paging to segmentation for these reasons :
	    >  memory management is simpler when all process use the same segment register values,
	       that is,when they share the same set of linear addresses.
	    >  one of the design objectives of Linux is portability to a wide range of architectures;
	       RISC architectures in particular have limited support for segmentation.
	    /*  linux 2.6 use segmentation only when required by the 80x86 architecture.  */

	  Linux processes running in User Mode use the same pair of segments to address instructions and data.
	    user code segment AND user data segment (Segment Selector : __USER_CS, __USER_DS /* macros */)
	  Linux processes running in Kernel Mode use the same pair of segments to address instructions and data.
	    kernel code segment AND kernel data segment (Segment Selector : __KERNEL_CS, __KERNEL_DS /* macros */)

	  CS means cs register, DS means ds register.

	  all processes either in User Mode or in Kernel Mode,may use the same logical address.
	  (linear address associated such segment start at 0,and reach the addressing limit of (2^32 - 1))

	  Linux,logical address coincide with linear address.(so all segments start at 0x00000000)

	  about RPL :
	    when CPL of cs is changed,ds and ss have to correspondingly updated.
	    e.g.
	      CPL = 3, ds -> user data segment, ss -> user stack inside user data segment
	      CPL = 0, ds -> kernel data segment, ss -> kernel stack inside kernel data segment

	    ! When switching from User Mode to Kernel Mode,Linux always makes sure that the 
	      ss register contains the Segment Selector of the kernel data segment.
          
	  when saving a pointer to an instruction or to a data structure,the kernel does not need to store the
	  Segment Selector component of the logical address,because the ss register contains the current 
	  Segment Selector.
	  /*  a function,it has a stack frame.and ss contains the Segment Selector used to get Segment Descriptor
	   *  of the stack.so a pointer just contains the offset for the Segment Descriptor(in unprogrammable register).
	   *  in the case for instruction is same,but use the cs register.
	   */

	The Linux GDT :
	  uniprocessor : one GDT
	  multiprocessor : every processor one GDT

	  all GDTs are stored in the "cpu_gdt_table" array,while the addresses and sizes of the GDTs are stored in the 
	  "cpu_gdt_descr" array.(2.6.34.1,use struct "desc_struct" to represent segment descriptor)

	  each GDT includes 18 segment descriptors and 14 null,unused,or reserved entries.unused entries are inserted
	  on purpose so that Segment Descriptors usually accessed together are kept in the same 32-byte line of hardware
	  cache.
	  the 18 segment descriptors included in each GDT point to the following segments :
	    >  four user and kernel code and data segments
	    >  a task state segment(TSS),different for each processor in the system.
	       the linear address space corresponding to a TSS is a small subset of the linear address space corresponding
	       to the kernel data segment.
	       TSS stored in the "init_tss" array.
	       in particualr :
	         BASE -> index in init_tss
		     G = 0 ; if LIMIT = 0xeb (because TSS is 236 byte)
		     TYPE = 9 || 11
		     DPL = 0
	    >  a segment including the default Local Descriptor Table(LDT),usually shared by all processes.
	    >  three Thread-Local Storage(TLS) segments :
	         multithreaded applications could make used of up to TLSs containing data local to each thread.
		    syscall set_thread_area() and get_thread_area() create and release a TLS segment for the
		    executing process.
        >  three segments related to Advanced Power Management(APM) :
	         the BIOS code makes use of segments,so when the Linux APM driver invokes BIOS functions to get
		     or set the status of APM devices,it may use custom code and data segments.
        >  five segments related to Plug and Play(PnP) BIOS services.
	       Linux PnP driver invokes BIOS functions to detect the resources used by PnP devices.
		   (custom data and data segments).
	    >  a special TSS used by the kernel to handle "Double fault" exceptions.

	  each processor has its own TSS.
	  a few entries in the GDT may depend on the process that the CPU is executing(i.e. TLS).
	  in some cases a processor may temporarily modify an entry in its copy of the GDT(i.e. invoke APM's BIOS procedure).

	The Linux LDTs :
	  most Linux User Mode applications do not make use of a Local Descriptor Table.
	  thus,kernel defines a default LDT to be shared by most processes,it is stored in the "default_ldt" array.
	  default_ldt includes five entries,and two of them are used by kernel effectively :
	    a call gate for iBCS executables;
	    a call gate for Solaris/x86 executables;

	  /*  Call gate is a mechanism provided by 80x86 to change CPU privilege while invoking a predefined function */

	  process may require to set up their own LDT,via syscall modify_ldt().(i.e. Wine)
	  any custom LDT created by modify_ldt() also requires its own segment.
	  if the CPU is executing a process which has a custom LDT,then the LDT entry in CPU GDT also be changed accordingly.

	  /*  User Mode applications also may allocate new segments by means of modify_ldt()  */
	  /*  kernel never use these segments and do not keep track of the corresponding Segment Descriptor  */

    Paging in Hardware :
      the paging unit translates linear address into physical ones,it must to check the requested access type against the
      access rights of the linear address.if the memory access is not valid,it generates a Page Fault Exception.

      linear addresses are grouped in fixed-length intervals called page :
        contiguous linear addresses within a page are mapped into contiguous physical addresses.
    	in this way,kernel can specify the physical address and the access rights of a page instead
    	of those of all the linear addresses included in it.

      page unit thinks of all RAM as partitioned into fixed-length page frames(or physical pages),each page frame contains a page.
      a page frame is a constituent of main memory,and hence it is a storage area.
      
      ! the data structures that map linear to physical addresses are called page tables,they are stored in memory and kernel will
      	initializes them before enabling page unit.	    

      ! start with 80386,80x86 processors :
      	  if cr0.PG = 1,enable page;
    	  if cr0.PG = 0,linear addresses are interpreted as physical addresses;

    regular paging :
      start with 80386,a page handles 4kB memory.
	32bit linear address : Directory(10bit), Table(10bit), Offset(12bit)
	      	     	       (most significant) (middle)     (least significant)
	translation of linear address(based on type of translation table) :
	  the physical address of the Page Directory in use is stored in a control register named cr3.
	  get Page Directory from cr3 ->
	  use Directory field to determine the Page Table associated with the linear address in Page Directory ->
	  use Table field to determine the Page Frame in the Directory ->
	  use Offset field to determine the relative position within the Page Frame

	  cr3 { Page Directory address }
	  Page Directory {
	    ...
	    Page Table
	    Page Table {	/*  10bit Directory as index  */
	      ...
	      Page Frame
	      Page Frame {      /*  10bit Table as index  */
	        address
		address		/*  12bit Offset as index for addresses in a page frame  */
		...
	      }
	    }
	  }

	  physical address = retrivePageFrame(retrivePageTable(cr3, linear.Directory), linear.Table) + Offset

	  /*  12bit Offset,each page consists of 4kB of data.  */
	  /*  10bit Directory,so Page Directory include 1024 entries;10bit Table,so Page Table include 1024 entries,
	   *  so a Page Directory can address up to 1024x1024x4096 = 2^32 memory cells.
	   */

	the entries of Page Directories and Page Tables have the same structure,each entry includes the following fields :
	  Present flag :
	    it = 1,the referred-to page(or Page Table) is contained in main memory;
	    it = 0,the referred-to page(or Page Table) is not contained in main memory,the remainder bits may be used by OS for
	    its own purpose;
	    it = 0 and access physical address via page unit,page unit will stores the linear address in cr2,and generates 
	    exception 14 : Page Fault

      Field containing the 20 most significant bits of a page frame physical address :
  	    a page frame has a 4-kB capacity,so its physical address must be multiple of 4096,so the 12 least significant
	    bits are always equal to 0.
	    it -> Page Directory,the page frame contains a Page Table;
	    it -> Page Table,the page frame contains a page of data;

	  Accessed flag :
	    page unit set each time accesses the corresponding page frame.(page unit never reset it,OS have to do this)
	    OS may be use it when selecting pages to be swapped out.
	    
	  Dirty flag :
	    Page Table entry only,it is set each time a write operation is performed on the page frame.
	    page unit never reset it,OS have to do this.

	  Read/Write flag :
	    contains the access right of the page or of the Page Table.
	    
	  User/Supervisor flag :
	    contains the privilege level required to access the page or Page Table.

	  PCD and PWT flags :
	    controls the way the page or Page Table is handled by the hardware cache.

	  Page Size flag :
	    Page Directory entry only,if it = 1,then entry refers to a 2MB- or 4MB-long page frame.

	  Global flag :
	    Page Table entry only,this flag was introduced in the Pentium Pro to prevent frequently used pages from being
	    flushed from the TLB cache.it works only if the Page Global Enable(PGE) flag of register cr4 is set.
	    
      extended paging :
        starting with the pentium model,80x86 microprocessors introduce extended paging.
    	extended paging allows page frames to be 4MB.in this case,Page Table is no longer need,thus save memory and 
    	preserve TLB entries.
	    extended paging : Directory(10bit), Offset(22bit)

	Page Directory entries for extended paging are the same as for normal paging,except that :
	  >  the Page Size flag must be set.
	  >  Only the 10 most significant bits of the 20-bit physical address field are significant.

	extended paging coexists with regular paging;it is enabled by setting the PSE flag of the cr4 processor register.

    Hardware Protection Scheme :
        only two privilege levels are associated with pages and Page Tables,it is indicated by User/Supervisor field.
	    when User/Supervisor == 0,the page can be addressed only when the CPL is less than 3.
	    when User/Supervisor == 1,the page can always be addressed.

    	segmentation has three types of access rights,but only two types of access rights are associated with pages.
    	if Read/Write == 0,the corresponding Page Table or page can only be read;otherwise it can be read and written.
    	(Read Page Directory to get Page Table,read Page Table to get page frame)

    An Example of Regular Paging :
        a process is allowed to access linear addresses from 0x20000000 - 0x2003ffff.
    	Directory field is 0010000000 for all addresses,
    	Table field contain values in 0000000000 - 0000111111 (0 - 63)
    	Offset field contain values in 000000000000 - 111111111111

    	Directory is 0x80 or 128 decimal,so the 129th entry in Page Directory will be selected,
    	the 129th entry contains the physical address of the Page Table of current process.
    	Table is 0 - 63,so all the remaining 1024 - 64(960) entries are filled with zeros,so
    	only the first Page to 63th Page in Page Table is valid.
    	Finally,use Offset to access Page Frame.

    	Suppose that the process needs to read the byte at linear address 0x20021406,this address is handled by the paging
    	unit as follows :
    	  1>  use 0x80 to select the 129th entry in Page Directory.
    	  2>  the Table field 0x21 is used to select entry 0x21 of the Page Table.
    	  3>  Finally,the Offset field 0x406 is used to select the byte at offset 0x406 in the desired page frame.

    	if process accessed a linear address which is outside to its linear address space,because the address is not in its
    	address space,thus the address's Present flag is 0,cleared,Page Unit will issues an exception.
    	all addresses are not valid for process in its linear address space,Present flag of each address will be cleared.

    The Physical Address Externsion (PAE) Paging Mechanism :
        normal CPU only supports 4GB RAM (from 80386 to the Pentium),which is used 32-bit physical addresses.
    	in pratice,due to the linear address space requirements of User Mode processes,the kernel cannot directly address
    	more than 1GB of RAM.
    	and server needs more than 4GB RAM.
    	Intel introduced a mechanism called Physical Address Extension(PAE)<36-bit physical address> on Pentium Pro processor.

    	PAE is actived by setting the Physical Address Externsion flag in the cr4 control register.
    	if PAE is open,then the Page Size flag in page directory entry will set to 1.

	PAE paging mechanism :
	  >:
	  the 64 GB of RAM are split into 2^24 distinct page frames,and the physical address field of Page Table entries has
	  been expanded from 20 to 24 bits.
	  the Page Table entry size has been doubled from 32bits to 64 bits,as a result,a 4-kB PAE Page Table includes 512
	  entries instead of 1024.

	  >:
	  a new level of Page Table called the Page Directory Pointer Table(PDPT) consisting of four 64-bit entries has
	  been introduced.

	  >:
	  the cr3 control register contains a 27-bit Page Directory Pointer Table base address field.because PDPTs are stored
	  in the first 4GB of RAM and aligned to a multiple of 32 bytes,27 bits are sufficient to represent the base address
	  of such tables.

	  >:
	  when mapping linear addresses to 4kB pages,the 32 bits of a linear address are interpreted in the following way :
	    cr3 Points to a PDPT
	    
	    bits 31-30
	      point to 1 of 4 possible entries in PDPT

	    bits 29-21
	      point to 1 of 512 possible entries in Page Directory

	    bits 20-12
	      point to 1 of 512 possible entries in Page Table

	    bits 11-0
	      Offset of 4-kB page

	    linear-address : { PDPT Index(31-30), Page Directory Index(29-21), Page Table Index(20-12), Offset(11-0) }

	  >:
	  when mapping linear addresses to 2-MB pages(PS flag open),the 32 bits of a linear address are interpreted in
	  the following way :
	    cr3 Points to a PDPT

	    bits 31-30
	      point to 1 of 4 possible entries in PDPT

	    bits 29-21
	      point to 1 of 512 possible entries in Page Directory

	    bits 20-0
	      Offset of 2-MB page

	    linear-address : { PDPT Index(31-30), Page Directory Index(29-21), Offset(20-0) }

        once cr3 is set,it is possible to address up to 4 GB of RAM,if we want to address more RAM,we will have to put 
    	a new value in cr3 or change the content of the PDPT.
    	PAE only extend physical address,User Mode processes are still address 4 GB linear address space(still 32 bits).
	    
      Paging for 64-bit Architectures : 
        Paging levels in some 64-bit architectures >
	    Platform name	      Page size		   address bits		paging levels		linear address splitting
        alpha	   	          8kB  		       43	   		    3      			    10 + 10 + 10 + 13
        ia64		          4kB		       39			    3			        9 + 9 + 9 + 12
        ppc64		          4kB		       41			    3			        10 + 10 + 9 + 12
        sh64		          4kB		       41			    3			        10 + 10 + 9 + 12
        x86_64	              4kB		       48			    4			        9 + 9 + 9 + 9 + 12

    	two levels paging :
    	  Page Directory  <level 1>
    	  Page Table	  <level 2>

    	  cr3 get Page Directory address.
    	  PD[Directory] -> Page Table
    	  PT[Table] -> Page Frame
    	  PF[Offset] -> page of data

    Hardware Cache : 
        Hardware cache memories were introduced to reduce the speed mismatch between CPU and RAM.
    	they are based on the well-known locality principle,which holds both for programs and data structures.
    	it makes sense to introduce a smaller and faster memory that contains the most recently used code and data.
    	for this purpose,a new unit called the "line" was introduced into the 80x86 architecture.

    	DRAM : dynamic RAM
    	SRAM : static RAM,it is more faster than DRAM and it is on-chip

    	the cache is subdivided into subsets of lines.
    	there are some different strategy to determine how to store cache :
    	  1>  the cache can be direct mapped,in which case a line in main memory is always stored at the exact
    	      same location in the cache.
    	  2>  the cache is fully associative,meaning that any line in memory can be stored at any location in the cache.
    	  3>  degree N-way set associative,where any line of main memory can be stored in any one of N lines of the cache.

    	      	     	   DRAM Main Memory
    	      	     	       |
    	      	     	       v
    	CPU { SRAM cache -> Cache controller <- Paging unit }

    	SRAM stores the actual lines of memory.(it is the cache memory)
    	Cache controller stores an array of entries,every entry is the line of the cache memory.
    	Each entry includes a tag and a few flags that describe the status of the cache line,the tag consists of some
    	bits that allow the cache controller to recognize the memory location currently mapped by the line.

    	The bits of the memory's physical address : { TAG, SUBSET INDEX, OFFSET }

    	when accessing a RAM memory cell,the CPU extracts the subset index from the physical address and compares the tags
    	of all lines in the subset with the high-order bits of the physical address.
    	if a line with the same tag as the high-order bits of the address is found,the CPU has a cache hit;otherwise,it
    	has a cache miss.

    	when a cache hit occurs,the cache controller behaves differently,depending on the access type :
    	  READ >
    	    controller selects the data from the cache line and transfers it into a CPU register.

    	  WRITE >
    	    write-through :
    	      write data into both cache line and mapped RAM.

    	    write-back :
    	      just write data into cache line,the controller updates RAM only when the CPU executes an instruction
    	      requiring a flush of cache entries or then a FLUSH hardware signal occurs.

    	when a cache miss occurs,the cache line is written to memory,if necessary,and the correct line is fetched from
    	RAM into the cache entry.

    	Multiprocessor system :
    	  there must have an additional hardware circuitry to synchronize the cache contents.
    	  whenever a CPU modifies its hardware cache,it must check whether the same data is contained in the other
    	  hardware cache;if so,it must notify the other CPU to update it with the proper value.(cache snooping)

          new model have more cache,L1-cache,L2-cache,L3-cache,etc.
          linux ignore hardware details,and assumes there is a single cache.

          the CD flag of the cr0 control register is used to enable or diable the cache circuitry.
          the NW flag,in the same register,specifies whether the write-through or the write-back strategy is used for
          the caches.

          some processors allow OS associate a different cache management policy with each page frame,that is PCD flag
          in Page Directory and Page Table;and PWT(Page Write-Through),which specifies whether the write-back or the 
          write-through strategy must be applied while writing data into the page frame.
          (Linux default clear these flags)

   Translation Lookaside Buffers(TLB) :
     80x86 processors include another cache called Translation Lookaside Buffers(TLB) to speed up linear address
     translation.
     when a linear address is used for the first time,the corresponding physical address is computed through slow
     accesses to the Page Tables in RAM.the physical address is then stored in a TLB entry for further accessing.
    	
     in a multiprocessor system,each CPU has its own TLB,called the local TLB of the CPU.contrary to the hardware
     cache,these local TLB need not to be synchronized,because processes running on the existing CPUs may associate
     the same linear address with different physical ones.

     when the cr3 control register of a CPU is modified,the hardware automatically invalidates all entries of the 
     local TLB,because a new set of page tables is in use and the TLBs are pointing to old data.

    Paging in Linux :
      before 2.6.11,linux paging model has three level,
      starting with 2.6.11,linux paging model has four level.
      (linux adopts a common paging model that fits both 32-bit and 64-bit architectures.)

      paging level :
        Page Global Directory
    	Page Upper Directory
    	Page Middle Directory
    	Page Table

    	PGD { PUDs }
    	PUD { PMDs }
    	PMD { PTs }
    	PT -> Page Frame (a page frame)
	
	    cr3 -> Address of PGD

      on 32-bit architecture(no PAE),PUD and PMD fields will be zero.(code still same,so it is work on 64-bit)
      but kernel keeps a position for the PUD and PMD by setting the number of entries in them to 1 and mapping
      these two entries into the proper entry of the PGD.

      on 32-bit architecture(PAE),PUD is eliminated.
      PGD -> 80x86's Page Directory Pointer Table
      PMD -> 80x86's Page Directory
      PT  -> 80x86's Page Table

      on 64-bit architecture,three or four levels of paging are used depending on the linear address bit splitting
      performed by the hardware.

      Linux's handling of processes relies heavily on paging :
        linear address to physical address,design >
	      < assign a different physical address space to each process,ensuring an efficient protection against
	        addressing errors.
	      < distinguish pages(groups of data) from page frames(physical ddress in main memory),this allows the same
	        page to be stored in a page frame,then saved to disk and later reloaded in a different page frame,
	        this is "the basic ingredient" of the virtual memory mechanism.

      The Linear Address Fields :
        the macros simplify Page Table handling >
	  PAGE_SHIFT
	    specifies the length in bits of the Offset field;
	    this macro is used by PAGE_SIZE to return the size of the page,finally,
	    the PAGE_MASK macro yields the value 0xfffff000 and is used to mask all the bits of the Offset field.

	  PMD_SHIFT
	    the total length in bits of the Offset and Table fields of a linear address;
	    the logarithm of the size of the area a Page Middle Directory entry can map.
	    the PMD_MASK macro is used to mask all the bits of the Offset and Table fields.
	    PAE -> off
	      PMD_SHIFT = 22 (12 Offset + 10 Table)
	      PMD_SIZE = 2^22 (4MB)
	      PMD_MASK = 0xffc00000

	    PAE -> on
	      PMD_SHIFT = 21 (12 Offset + 9 Table)
	      PMD_SIZE = 2^21 (2MB)
	      PMD_MASK = 0xffe00000

	    !  large pages do not make use of the last level of page tables,thus LARGE_PAGE_SIZE which yields
	       the size of a large page,is equal to PMD_SIZE(2PMD_SHIFT)
	       LARGE_PAGE_MASK is used to mask all the bits of the Offset and Table fields in a large page address,
	       is equal to PMD_MASK.

	  PUD_SHIFT
	    determines the logarithm of the size of the area a Page Upper Directory entry can map.
	    PUD_SIZE macro computes the size of the area mapped by a single entry of the Page Global Directory,
	    PUD_MASK macro is used to mask all the bits of the Offset,Table,Middle Air,and Upper Air fields.

	  PGDIR_SHIFT
	    determines the logarithm of the size of the area that a Page Global Directory entry can map.
        PGDIR_SIZE macro computes the size of the area mapped by a single entry of the Page Global Directory,
	    the PGDIR_MASK macro is used to mask all the bits of the Offset,Table,Middle Air,and Upper Air fields.
	    PAE -> off
	      PGDIR_SHIFT = 22 (the same value yielded by PMD_SHIFT and by PUD_SHIFT)
	      PGDIR_SIZE = 2^22 (4MB)
	      PGDIR_MASK = 0xffc00000

	    PAE -> on
	      PGDIR_SHIFT = 30 (12 Offset + 9 Table + 9 Middle Air)
	      PGDIR_SIZE = 2^30 (1GB)
	      PGDIR_MASK = 0xc0000000

	  PTRS_PER_PTE PTRS_PER_PMD PTRS_PER_PUD PTRS_PER_PGD
	    compute the number of entries in the Page Table,Page Middle Directory,Page Upper Directory,Page Global Directory.
	    they yield the values 1024, 1, 1, 1024, respectively; (PAE disabled)
	    they yield the values 512, 512, 1, 4, respectively; (PAE enabled)

      Page Table Handling :
        pte_t -> Page Table entry
	    pmd_t -> Page Middle Directory entry
	    pud_t -> Page Upper Directory entry
	    pgd_t -> Page Global Directory entry
	    pgprot_t -> the protection flags associated with a single entry        
	    (64-bit PAE on,32-bit PAE off)

	conversion macros :
	  pte_t __pte(unsigned int)
	  pmd_t __pmd(unsigned int)
	  pud_t __pud(unsigned int)
	  pgd_t __pgd(unsigned int)
	  pgprot_t __pgprot(unsigned int)

	  unsigned int pte_val(pte_t)
	  unsigned int pmd_val(pmd_t)
	  unsigned int pud_val(pud_t)
	  unsigned int pgd_val(pgd_t)
	  /*  reverse casting  */

	macros for RW a page table entry operations :
	  unsigned pte_none(pte_t)
	  unsigned pmd_none(pmd_t)
	  unsigned pud_none(pud_t)
	  unsigned pgd_none(pgd_t)
	  /*  return 0 if @arg == 1,return 1 if @arg == 0  */

	  pte_clear(mm, addr, ptep)
	  pmd_clear(pmd)
	  pud_clear(pud)
	  pgd_clear(pgd)
	  /*  clear an entry of the corresponding page table  */
	  /*  forbidding a process to use the linear addresses mapped by the page table entry  */

	  static inline pte_t ptep_get_and_clear(struct mm_struct *mm, unsigned long addr, pte_t *ptep);
	  /*  clears a Page Table entry and returns the previous value  */

	  set_pte(ptep, pte)
	  set_pmd(pmdp, pmd)
	  set_pud(pudp, pud)
	  set_pgd(pgdp, pgd)
	  /*  write a given value into a page table entry  */

	  set_pte_atomic(ptep, pte)
	  /*  atomic operation  */
	  /*  if PAE on,it also ensures that the 64-bit value is written atomically  */

	  static inline int pte_same(pte_t, pte_t);
	  /*  returns 1 if @arg1 == @arg2,specify @arg1.privileges == @arg2.privileges,otherwise retuns 0  */

	  static inline int pmd_large(pmd_t pte);
	  /*  returns 1 if the Page Middle Directory entry refers to a large page(2MB or 4MB),0 otherwise  */

	  static inline int pmd_bad(pmd_t pmd);
	  /*  it is used by functions to check Page Middle Directory entries passed as input parameters.
	   *  returns 1 if the entry points to a bad Page Table :
	   *    Present flag cleared
	   *    Read/Write flag cleared
	   *    Accessed or Dirty cleared
	   *    0 otherwise.
	   */

	  static inline int pud_bad(pud_t pud);
	  static inline int pgd_bad(pgd_t pgd);
	  /*  these macros always yield 0.  */

	  no pte_bad() macro is defined,because no Present,no Read/Write,no Accessed or no Dirty is legal for
	  Page Table entry.

	  pte_present(pte_t)
	  /*  returns 1 if Present == 1 or Page Size == 1,0 otherwise  */

	  Page Size flag in Page Table entries has no meaning for the paging unit of the microprocessor,
	  but kernel marks Present = 0 and Page Size = 1 for the pages present in main memory but without read,
	  write,or execute privileges.
	  any access to such pages will triggers a Page Fault exception because Present is cleared,but kernel
	  is able to detect that the Page Fault exception is not due to a missing page by checking the value of
	  Page Size!

	  pmd_present(pmd_t pmd)
	  /*  returns 1 if the Present == 1,0 otherwise  */

	  pud_present(pud_t pud)
	  pgd_present(pgd_t pgd)
	  /*  same as above  */

    query or setting functions for Page Table entry's value of any of the flags :
	  Page flag reading :
	    pte_user()	    /*  User/Supervisor  */
	    pte_read()	    /*  User/Supervisor,pages on the 80x86 processor cannot be protected against reading  */
	    pte_write()	    /*  Read/Write  */
	    pte_exec()	    /*  User/Supervisor,pages on the 80x86 processor cannot be protected against code execution  */
	    pte_dirty()     /*  Dirty  */
	    pte_young()	    /*  Accessed  */
	    pte_file()	    /*  Dirty,when the Present is cleared and the Dirty flag is set,the page belongs to a
	    		         *  non-linear disk file mapping.
			             */

	  Page flag setting :
	    mk_pte_huge()               /*  Page Size and Present  */
	    pte_wrprotect()             /*  Read/Write */
	    pte_rdprotect()             /*  User/Supervisor  */
	    pte_exprotect()             /*  User/Supervisor  */
	    pte_mkwrite()               /*  Read/Write  */
	    pte_mkread()                /*  User/Supervisor  */
	    pte_mkexec()                /*  User/Supervisor  */
	    pte_mkclean()               /*  Dirty  */
	    pte_mkdirty()               /*  Dirty  */
	    pte_mkold()	                /*  Accessed  */
	    pte_mkyoung()               /*  Accessed  */
	    pte_modify(p, v)	        /*  Sets all access rights in a Page Table entry @p to a specified value @v  */
	    ptep_set_wrprotect()    	/*  pointer version  */
	    ptep_set_access_flags() 	/*  if the Dirty == 1,sets the page's access rights to a specified value and
	    			     	         *  invokes flush_tlb_page()
				     	             */
	    ptep_mkdirty()	    	    /*  pointer version  */
	    ptep_test_and_clear_dirty()	/*  like pte_mkclen() but acts on a pointer to a Page Table entry and returns
	   				                 *  the old value of the flag
					                 */
	    ptep_test_and_clear_young()	/*  like pte_mkold() but acts on a pointer to a Page Table entry and returns 
	   				                 *  the old value of the flag
					                 */

    macros acting on Page Table entries :
	  pgd_index(addr)     
	  /*  yields the index of the entry in Page Global Directory that maps the linear address @addr  */

	  pgd_offset(mm, addr)
	  /*  yields the linear address of the entry in a Page Global Directory that corresponds to the 
	   *  address @addr,the Page Global Directory is found through a pointer within the memory descriptor
	   */

	  pgd_offset_k(addr)
	  /*  yields the linear address of the entry in the master Kernel Page Global Directory that corresponds
	   *  to the address @addr
	   */

	  pgd_page(pgd)
	  /*  yields the page descriptor address of the page frame containing the Page Upper Directory referred to
	   *  by the Page Global Directory entry @pgd,in a two or three-level paging system,this macro is
	   *  equivalent to pud_page() applied to the folded Page Upper Directory entry
	   */

	  pud_offset(pgd, addr)
	  /*  yields the linear address of the entry in a Page Upper Directory that corresponds to @addr,in a 
	   *  two- or three-level paging system,this macro yields @pgd,the address of a Page Global Directory entry
	   */

	  pud_page(pud)
	  /*  yields the linear address of the Page Middle Directory referred to by the Page Upper Directory entry @pud,
	   *  in a two- or three-level paging system,this macro is equivalent to pmd_page() applied to the foled
	   *  Page Middle Directory entry
	   */

	  pmd_index(addr)
	  /*  yields the index of the entry in the Page Middle Directory that maps the linear address @addr  */
	  
	  pmd_offset(pud, addr)
	  /*  yields the address of the entry in a Page Middle Directory that corresponds to @addr,
	   *  in a two- or three-level paging system,it yields @pud,the address of a Page Global Directory entry
	   */

	  pmd_page(pmd)
	  /*  yields the page descriptor address of the Page Table referred to by the Page Middle Directory entry @pmd,
	   *  in a two- or three-level paging system,@pmd is actually an entry of a Page Global Directory
	   */

	  mk_pte(p, prot)
	  /*  use a page descriptor @p and a group of access rights @prot to builds the corresponding Page Table entry  */

	  pte_index(@addr)
	  /*  yields the index of the entry in the Page Table that maps the linear address @addr  */

	  pte_offset_kernel(dir, addr)
	  /*  yields the linear address of the Page Table that corresponds to the linear address @addr mapped by the 
	   *  Page Middle Directory @dir,used only on the master kernel page tables
	   */

	  pte_offset_map(dir, addr)
	  /*  yields the linear address of the entry in the Page Table that corresponds to the linear address @addr,
	   *  if the Page Table is kept in high memory,the kernel establishes a temporary kernel mapping,to be released
	   *  by means of pte_unmap.
	   *  the macros pte_offset_map_nested() and pte_unmap_nested() are identical,but they use a different temporary
	   *  kernel mapping.
       */

	  pte_page(x)
	  /*  returns the page descriptor address of the page referenced by the Page Table entry @x  */

	  pte_to_pgoff(pte)
	  /*  extracts from the content @pte of a Page Table entry the file offset corresponding to a page belonging to
	   *  a non-linear file memory mapping
	   */

	  pgoff_to_pte(offset)
	  /*  sets up the content of a Page Table entry for a page belonging to a non-linear file memory mapping  */

    page allocation functions :
	  pgd_alloc(mm)
	  /*  allocates a new Page Global Directory;if PAE is on,it also allocates the three children Page Middle Directories
	   *  that map the User Mode linear addresses.the argument @mm is ignored on the 80x86 architecture.
	   */

	  pgd_free(pgd)
	  /*  releases the Page Global Directory at address @pgd;if PAE is on,it also releases the three Page Middle
       *  Directories that map the User Mode linear addresses
	   */

	  pud_alloc(mm, pgd, addr)
	  /*  in a two- or three-level paging system,this function does nothing;it simply returns the linear address of
	   *  the Page Global Directory entry pgd
	   */

	  pud_free(x)
	  /*  in a two- or three-level paging system,this macro does nothing  */

	  pmd_alloc(mm, pud, addr)
	  /*  defined so generic three-level paging systems can allocate a new Page Middle Directory for the linear address
	   *  @addr;if PAE is off,the function simply returns the @pud -- that is,the address of the entry in the
	   *  Page Global Directory;if PAE is on,the function returns the linear address of the Page Middle Directory entry
	   *  that maps the linear address @addr,the argument cw is ignored
	   */

	  pmd_free(x)
	  /*  does nothing,because Page Middle Directories are allocated and deallocated together with their parent
	   *  Page Global Directory.
	   */

	  pte_alloc_map(mm, pmd, addr)
	  /*  returns the address of the Page Table entry corresponding to @addr,if the Page Middle Directory entry is null,
	   *  the function allocates a new Page Table by invoking pte_alloc_one().
	   *  if a new Page Table is allocated,the entry corresponding to @addr is initialized and the User/Supervisor is set,
	   *  if the Page Table is kept in high memory,the kernel establishes a temporary kernel mapping,to be released by
	   *  pte_unmap().
	   */

	  pte_alloc_kernel(mm, pmd, addr)
	  /*  if @pmd associated with the address @addr is null,the function allocates a new Page Table,it then returns the 
	   *  linear address of the Page Table entry associated with @addr,used only for master kernel page tables
	   */

	  pte_free(pte)
	  /*  releases the Page Table associated with the @pte page descriptor pointer  */
	  
	  pte_free_kernel(pte)
	  /*  equivalent to pte_free(),but used for master kernel page tables  */

	  clear_page_range(mmu, start, end)
	  /*  clears the contents of the page tables of a process from linear address @start to @end by iteratively
	   *  releasing its Page Tables and clearing the Page Middle Directory entries
	   */

	  because the Page Table that is supposed to contain it might not exist,in such cases,it is necessary to allocate
	  a new page frame,fill it with zeros,and add the entry.
	  if PAE on,the kernel uses three-level paging,when the kernel creates a new Page Global Directory,it also allocates
	  the four corresponding Page Middle Directories;these are freed only when the parent Page Global Directory is released.
	  when two or three-level paging is used,the Page Upper Directory entry is always mapped as a single entry within the
	  Page Global Directory.
	
	  
      Physical Memory Layout : 
        kernel must build a physical addresses map that specifies which physical address ranges are usable by the kernel and 
	    which are unavailable(hardware device I/O shared memory or BIOS data).

	  reserved page frames :
	    those falling in the unavailable physical address ranges
	    those containing the kernel's code and initialized data structures
	    (such page frames can never be dynamically assigned or swapped to disk)

    	/*  general rule,linux kernel is installed in RAM starting from the physical address 0x00100000,
    	 *  from the second megabyte.
    	 *  the total number of page frames required depends on how the kernel is configured.
    	 */	

        why kernel loaded starting with the second megabyte?
	    :  the PC architecture has several peculiarities that must be taken into account.
	       PF0 (BIOS data,system hardware configuration detected during POST(Power-On Self Test)).
	       0x000a0000 -- 0x000fffff are usually reserved to BIOS rountines and to map the internal memory of ISA graphics
	       cards.
	       additional page frames within the first megabyte may be reserved by specific computer models.

	in the early stage of the boot sequence,the kernel queries the BIOS and learns the size of the physical memory,
	later,kernel executes the machine_specific_memory_setup() rountine,which builds the physical address map.
	(such functions is named default_machine_specific_memory_setup() in arch/x86/kernel/e820.c)

	/*  kernel builds this table on the basis of the BIOS list,if this is available,otherwise the kernel builds the table
	 *  following the conservative default setup:
	 *    all page frames with numbers from 0x9f(LOWMEMSIZE()) to 0x100(HIGH_MEMORY) are marked as reserved.
	 */

	/*  POST stage,BIOS writes information about the system hardware devices into the proper page frames,
	 *  and initialization stage,kernel will copies such data into the suitable kernel data structures,
	 *  then consider these page frames usable.
	 *  BIOS may not provide information for some physical address ranges,in such case,linux kernel assumes
	 *  such ranges are not usable.
	 */

	 after machine_specific_memory_setup(),the function setup_memory() will be invoked,it analyzes the table
	 of physical memory regions and initializes a few variables that describe the kernel's physical memory
	 layout.
	   the vairables :  (thest variables are declared in *.c files under the directory mm/)
	     num_physpages      --  page frame number of the highest usable page frame
	     totalram_pages 	--  total number of usable page frames
	     min_low_pfn    	--  page frame number of the first usable page frame after the kernel image in RAM
	     max_pfn	    	--  page frame number of the last usable page frame
	     max_low_pfn    	--  page frame number of the last page frame directly mapped by the kernel(low memory)
	     totalhigh_pages	--  total number of page frames not directly mapped by the kernel(high memory)
	     highstart_pfn	--  page frame number of the first page frame not directly mapped by the kernel
	     highend_pfn	--  page frame number of the last page frame not directly mapped by the kernel

	 /*  under x86,function setup_arch()<kernel/setup.c> invokes setup_memory_map()<kernel/e820.c>,this function
	  *  will copies the e820 data structure object from &e820 to &e820_saved,and setup_arch() will updates 
	  *  some of the variables,another will be updated by the functions in the files under mm/ .
	  */
	     
	 /*  linux kernel prefers to skip the first megabyte of RAM to ensure it can never be loaded into groups of
	  *  noncontiguous page frames.
	  *  generally,kernel keeps initialized data structures right after kernel code,and the uninitialized data
	  *  structures follows it.
	  */

    Process Page Tables :
      two parts of the linear address space of a process :
	    1>  linear address 0x00000000 -- 0xbfffffff can be addressed either User or Kernel Mode.
	    2>  linear address 0xc0000000 -- 0xffffffff can only be addressed in Kernel Mode.

	macro PAGE_OFFSET yields value 0xc0000000,this is the offset in the linear address space of a process
	where the kernel lives.
	(in some cases,the process is running in Kernel Mode maybe need to access the linear address space of 
	 User Mode for retrieve or store data.)

	!  the content of the first entries of the Page Global Directory that map linear address lower than
	   0xc0000000(768 entries with PAE disabled,3 entries with PAE enabled),depends on the specific process.

    Kernel Page Tables :
      the kernel maintains a set of page tables for its own use,rooted at a so-called master kernel Page Global
	  Directory.
      after these page tables were initialized,they will never be directly accessed by any process or kernel thread.
      (the highest entries of the master kernel Page Global Directory are the reference model for the corresponding
      entries of the Page Global Directories of every regular process in the system.)

	kernel initializes these page tables with two-phase activity :
	  1>  the kernel creates a limited address space including the kernel's code and data segments,the initial
	      Page Tables,and 128KB for some dynamic data structures.
	      the minimal address space is just large enough to install the kernel in RAM and to initialize its core
	      data structures.
	  2>  the kernel takes advantage of all of the existing RAM and sets up the page tables properly.

	(right after kernel image loaded,CPU is stil running in real mode,thus,paging is not enabled)

	Provisional kernel Page Tables :
	  A provisional Page Global Directory is initialized statically during kernel compilation,while the provisonal
	  Page Tables are initialized by startup_32() assembly function defined in <arch/x86/kernel/head_32.S>.

	  the Provisional Page Global Directory is contained in swapper_pg_dir variable,the Provisional Page Tables
	  are stored starting from pg0.pg0 is the Page Frame which number is 0,it is the first Page Frame,right after
	  the end of the kernel's uninitialized data segments(symbol _end).

	  suppose all the limited address space fit in the first 8MB of RAM.there,kernel just required two Page Tables,
	  but each Page Table is points to a Page Frame,and Page Frame holds one Page,each Page Frame consisting with
	  a Page size is 4KB(1024(entries) * 2(Page Tables) * 4KB(Page Size) = 8MB).(at this time,PAE is off)

	  for easily addressed both in real mode and protected mode to the 8MB,kernel must create a mapping from
	  both the linera addresses [0x00000000 -- 0x007fffff] and the linera addresses [0xc0000000 -- 0xc07fffff]
	  into the physical address [0x00000000 -- 0x007fffff].
	    linear [0x00000000 -- 0x007fffff] -> [0x00000000 -- 0x007fffff] physical
	    linear [0xc0000000 -- 0xc07fffff] -> [0x00000000 -- 0x007fffff] physical

	  kernel create the desired mapping by filling all the swapper_pag_dir entries(1024) with zeroes,except for
	  entries 0, 1, 0x300(768), 0x301(769) . 
	  entries 0x300 and 0x301 will span all linear addresses between [0xc000000 -- 0xc07fffff].
	  /*  head_32.S defined swapper_pg_dir :
	   *    ENTRY(swapper_pg_dir)
	   *	.fill 1024,4,0	#  .fill repear,size(byte),value
	   */

	  initialization :
	    > the address field of entries 0 and 0x300 is set to the physical address of pg0,while the address field
	      of entries 1 and 0x301 is set to the physical address of the page frame following pg0(it is pg1).
	    > the Present, Read/Write, User/Supervisor flags are set in all four entries(on -> 1).
	    > the Accessed, Dirty, PCD, PWD, and Page Size flags are cleared in all four entries(off -> 0).

	  start_32() copies the address of swapper_pg_dir to cr3,and enables paging unit(PG flag of the cr0).
	  /*  A part of code  */
	    movl     $swapper_pg_dir-0xc0000000,%eax
	    movl     $eax,%cr3			#  set he page table pointer
	    movl     %cr0,%eax			#  get value of cr0
	    orl	     $0x80000000,%eax	#  open PG
	    movl     %eax,%cr0			#  write back

	    #  0xc0000000 is the __PAGE_OFFSET
	    #  addresses in [0x00000000, 0xc00000000) is used for User Mode.

    Final Kernel Page Table :
	  Final Kernel Page Table when RAM size is less than 896MB >
	    the final mapping provided by the kernel page tables must transform linear addresses starting
	    from 0xc0000000 into physical addresses starting from 0.

	    <arch/x86/include/asm/page.h>
	    #define __pa(x)	__phys_addr((unsigned long)(x))
	    /*  convert a linear address starting from PAGE_OFFSET to the corresponding physical address  */

	    #define __va(x)    ((void *)((unsigned long)(x) + PAGE_OFFSET))
	    /*  convert a physical address to the corresponding linear address starting from PAGE_OFFSET  */

	    the master kernel Page Global Directory is still stored in swapper_pg_dir,it is initialized by
	    the paging_init() which is declared in <arch/x86/include/asm/pgtable_32.h>,and defined in
	    <arch/x86/mm/init_32.c> with the prototype "void __init paging_init(void);" .
	    it executes these works :
	      invoke pagetable_init() to set up the Page Table entries properly;
	      writes the physical address of swapper_pg_dir in the cr3;
	      if the CPU supports PAE and if the kernel is compiled with PAE support,sets the PAE flag in
	      the cr4;
	      invokes __flush_tlb_all() to invalidate all TLB entries;

	    /*  body of it  */
	    void __init paging_init(void)
	    {
	        pagetable_init();
		    __flush_tlb_all();
		    kmap_init();
		    sparse_init();
		    zone_sizes_init();
	    }

	    /*  this routines also unmaps the page at virtual kernel address 0,so
	     *  that we can trap those pesky NULL-reference erros in the kernel.
	     */

	    the actions performed by pagetable_init() depend on both the amount of RAM  present and on the CPU
	    model.(suppose less than 896MB)
	    /*  the highest 128MB of linear address are left available for several kinds of mapping,the kernel
	     *  address space left for mapping the RAM is thus 1GB - 128MB = 896MB
	     */

	    the identity mapping of the first megabytes of physical memory(8MB,the supposed size) built by startup_32()
	    is required to complete the initialization phase of the kernel,when this mapping is no longer necessary,
	    the kernel clears the corresponding page table entries by invoking the zap_low_mappings() .

      Final Kernel Page Table when RAM size is between 896MB and 4096MB >
	    in this case,the RAM can not be mapped entirely into the kernel linear address space.
	    Linux does a mapping to map a RAM window of 896MB into the kernel linear address space,if a program
	    need to address other parts of the existing RAM,some other linear address interval must be mapped to
	    the required RAM,this implies changing the value of some page table entries.
	    (that is the remaining RAM(4096-896) is left unmapped status and handled by dynamic remapping)

	  Final Kernel Page Table when RAM size is more than 4096MB >
	    in this case,CPU supports PAE,and kernel is compiled with PAE support.
	    even PAE is on,linear address is till 32-bit,but physical address is 36-bit.
	    the main difference with the previous case is that,at this time,three-level paging model is used.
	    (pgd -> pmd -> pte)
	    /*  but kernel still directly maps 896MB RAM window  */

	    the setups :
	      > kernel initializes the first three entries(pgd_index(PAGE_OFFSET) = 3) in the Page Global Directory
	        corresponding to the user linear address space with the address of an empty page(empty_zero_page).
	      > kernel sets the fourth entry with the address of a Page Middle Directory(pmd) allocated by
	        invoking alloc_bootmem_low_pages().
	      > kernel sets the first 448 entries(896MB / 2MB(PAGE_SIZE)) in the Page Middle Directory(PAE on,512 entries)
	        are filled with the physical address of the first 896MB of RAM.
    		/*  phys_addr = 0x00000000;
    		 *  for(j = 0; j < PTRS_PER_PMD && phys_addr < max_low_pfn * PAGE_SIZE; ++j) {
    		 *          ...
    		 *	    phys_addr += PTRS_PER_PTE * PAGE_SIZE;  /*  PAE on,512  */
    		 *  }
    		 */
	      > kernel copies the fourth Page Global Directory entry into the first entry,so as to mirror the mapping
	      	of the low physical memory in the first 896MB of the linear address space.

    		/*  this mapping is required in order to complete the initialization of SMP  */
    		(if these page table entries is no longer neccesary,kernel will call zap_low_mappings() to clears them.)

      
      Fix-Mapped Linear Address :
        the initial part of the fourth gigabyte of kernel linear address maps the physical memory of the system,
    	however,at least 128MB of linear addresses are always left available because the kernel uses them to implement
    	noncontiguous memory allocation and fix-mapped linear addresses.
    	(noncontiguous memory allocation is just a special way to dynamically allocate and release pages of memory)

    	basically,a fix-mapped linear address is a constant linear address like 0xffffc000 whose corresponding physical
    	address does not have to be the linear address minus 0xc0000000,but rather a physical address set in an arbitrary
    	way.thus,each fix-mapped linear address maps one page frame of the physical memory.
    	fix-mapped linear address is similiar to the linear address that map the first 896MB conceptually,but it can map
    	any physical address,while the mapping established by the linear address in the initial portion of the fourth
    	gigabyte is linear.

    	each fix-mapped linear address is represented by a small integer index defined in the enum fixed_addresses 
    	data structure :
    	  <arch/x86/include/asm/fixmap.h>
    	  enum fixed_addresses {
    	          FIX_HOLE,
        		  FIX_VSYSCALL,
        		  FIX_APIC_BASE,
        		  FIX_IO_APIC_BASE_0,
        		  [...]
        		  __end_of_fixed_addresses
          };

    	  fix-mapped linear addresses are placed at the end of the fourth gigabyte of linear addresses,
    	  fix_to_virt() function computes the constant linear address starting from the index.
    	  <arch/x86/include/asm/fixmap.h>
    	    /*  fix_to_virt - computes the constant linear address starting from the index in fixed_addresses.
    	     *  @idx : the index.
    	     *  return - the constant linear address.
    	     *  #  if idx is not in fixed_addresses,then an error "undefined symbol __this_fixmap_does_not_exist"
    	     *	   will be reported by compiler.
    	     */
    	    static __always_inline unsigned long fix_to_virt(const unsigned int idx);

    	    /*  set_fixmap - associates a fix-mapped address with a physical address.
    	     *  @idx : the index in fixed_address.
    	     *  @phys : the physical address have to be associated.
    	     */
    	    #define set_fixmap(idx, phys)  __set_fixmap(idx, phys, PAGE_KERNEL)

    	    /*  set_fixmap_nocache - nocache version.
    	     *    this function will sets PCD flag of the Page Table entry,thus disabling the hardware cache when
    	     *    accessing the data in the page frame.
    	     */
    	    #define set_fixmap_nocache(idx, phys)  __set_fixmap(idx, phys, PAGE_KERNEL_NOCACHE)

    	    /*  clear_fixmap - clear fix-mapped,removes the linking between a fix-mapped linear address
    	     *		       and the physical address.
    	     *  @idx : the index of member in fixed_addresses.
    	     */
    	    #define clear_fixmap(idx)  __set_fixmap(idx, 0, __pgprot(0))

	
      Handling the Hardware Cache and the TLB :
        Handling the hardware cache >
	      macro L1_CACHE_BYTES yields the size of a cache line in bytes.
    	  <arch/x86/include/asm/cache.h>
    	    #define L1_CACHE_BYTES  (1 << L1_CACHE_SHIFT)

    	  to optimize the cahce hit rate,the kernel considers the architecture in making the following decisions :
    	    1>  the most frequently used fields of a data structure are placed at the low offset within the 
    	    	data structure,so they can be cached in the same line.
            2>  when allocating a large set of data structures,the kernel tries to store each of them in memory
    	    	in such a way that all cache lines are used uniformly.

                #  80x86 microprocessors does cache synchronization automatically,linux need not to care about anymore.
    	           the kernel does provide,however,cache flushing interfaces for processors that does not synchronize caches.

	Handling the TLB >
	  TLB is used keep records about mapping between linear addresses and physical addresses,
	  so processors can not synchronize their own TLB cache automatically.(kernel determines if the mapping is invalid)

	  the methods linux provides for TLB synchronization :
	    <arch/x86/include/asm/tlbflush.h>
          /*  flush_tlb_all - flushes all TLB entries even refer to global pages.
	       *  #  typically used when changing the kernel page table entries.
	       */
	      #define flush_tlb_all()  __flush_tlb_all()

	      /*  flush_tlb_kernel_range - flushes all TLB entries in a given range of linear addresses,
	       *  			               even refer to global pages.
	       *  @start : range start.
	       *  @end   : range end.
	       */
	      static inline void flush_tlb_kernel_range(unsigned long start, unsigned long end);

	      /*  flush_tlb - flushes all TLB entries of the non-global pages owned by the current process.
	       *  	          (current mm struct TLBs)
	       */
	      #define flush_tlb()  __flush_tlb()

	      /*  flush_tlb_mm - flushes all TLB entries of the non-global pages owned by a given process.
	       *  @mm : a pointer points to a mm_struct object.
	       *  #  typically used when forking a new process.
	       */
	      static inline void flush_tlb_mm(struct mm_struct *mm);

	      /*  flush_tlb_range - flushes the TLB entries corresponding to a linear address interval of a given process.
	       *  @vma : the virtual memory area of current process.
	       *  @start : range start.
	       *  @end : range end.
	       *  #  typically releasing a linear address interval of a process.
	       */
	      static inline void flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end);

	      /*  flush_tlb_pgtables - flushes the TLBs of a given contiguous subset of page tables of a given process.  */
	      flush_tlb_pgtables
	      !  some architecure does not offer such function,i.e. x86.
	      #  80x86 architecure nothing has to be done when a page table is unlinked from its parent table.

	      /*  flush_tlb_page - flushes the TLB of a single Page Table entry of a given process.
	       *  @vma : the virtual memory area of the process.
	       *  @addr : specified address.
	       *  #  typically used processing a Page Fault.
	       */
	      static inline void flush_tlb_page(struct vm_area_struct *vma, unsigned long addr);

          every microprocessor usually offers a far more restricted set of TLB-invalidating assembly language instructions,
	  Intel microprocessors offers only two TLB-invalidating techniques :
	    >  all Pentium models automatically flush the TLBs relative to non-global pages when a value is loaded into cr3.
	    >  in Pentium Pro and later models,the "invlpg" assembly language instruction invalidates a single TLB mapping a
	       given linear address.

	  Linux macros that exploit such hardware technique :
	    <arch/x86/include/asm/tlbflush.h>
	      /*  __flush_tlb - rewrites cr3 register back into itself.  */
	      #define __flush_tlb()  __native_flush_tlb()

	      /*  __flush_tlb_global - disables global pages by clearing the PGE flag of cr4,
	       *                       rewrites cr3 register back into itself,and sets again the PGE flag.
	       */
	      #define __flush_tlb_global()  __native_flush_tlb_global()

	      /*  __flush_tlb_single - executes "invlpg" assembly language instruction with parameter @addr.  */
	      #define __flush_tlb_single(addr)  __native_flush_tlb_single(addr)

	    #  for SMP : a processor sends a interprocessor interrupt to other to forces synchronizing.

	  kernel avoids TLB flushes :
	    >  when performing a process switch between two regular processes that use the same set of page tables.
	    >  when performing a process switch between a regular process and a kernel thread.

	    #  when the kernel assigns a page frame to a User Mode process and stores its physical address into Page Table
	       entry,it must flush any local TLB entry that refers to the corresponding linear address,on SMP,synchronization
	       have to be done between CPUs.

	  Lazy TLB mode : (kernel use this strategy to avoid useless TLB flushing in SMP)
	    the basica idea is :
	      if several CPUs are using same page tables and a TLB entry must be flushed on all of them,then TLB flushing
	      may,in some cases,be delayed on CPUs running kernel threads.

	    when some CPUs start running a kernel thread,the kernel sets it into lazy TLB mode.
	    each CPU in lazy TLB mode does not flush the corresponding entries;however,the CPU remembers that its current
	    process is running on a set of page tables whose TLBs for the User Mode addresses are invalid.
	    as soon as the CPU in lazy TLB mode switches to a regular process with a different set of page tables,the
	    hardware automatically flushes the TLBs,and the kernel sets the CPU back in non-lazy TLB mode.
	    but,if a CPU in lazy TLB mode switches to a regular process that owns the same set of page tables used by the
	    previously running kernel thread,then any deferred TLB invalidation must be effectively applied by the kernel.

	    data structures associated to lazy TLB mode :
	      @cpu_tlbstate variable is a static array of @NR_CPUS structures consisting of an @active_mm filed pointing to the
	      memory descriptor of the current process,and a @state flag that can assume only two values : TLBSTATE_OK | TLBSTATE_LAZY
	      each memory descriptor includes a @cpu_vm_mask field that stores the indices of the CPUs that should receive
	      Interprocessor Interrupts related to TLB flushing.(it is meaningful just for current process is executing)
	      (the CPU has relative to the active memory,in default,indices of all CPUs of the system will be stored into
	       @cpu_vm_mask,including the CPU is lazy TLB mode)

	    if a CPU recevied a Interprocess interrupt related to TLB flushing,kernel have to checks @state field of its
	    @cpu_tlbstate element is equal to TLBSTATE_LAZY,in this case,the kernel refuses to invalidate the TLBs and
	    removes the CPU index from the @cpu_vm_mask filed of the memory descriptor.
	    two consequences :
	      >  as long as the CPU remains in lazy TLB mode,it will note receive other Interprocessor Interrupts related to
	         TLB flushing.

	      >  if the CPU switches to another process that is using the same set of page tables as the kernel thread that
	         is being replaced,the kernel invokes __flush_tlb() to invalidate all non-global TLBs of the CPU.


/*  END OF CHAPTER2  */


Chapter 3 : Processes
    processes are often called "tasks" or "threads" in the Linux source code.

    Processes,Lightweight Processes,and Threads :
      a process is an intance of a program in execution!
      kernel's point of view :
        the purpose of a process is to act as an entity to which system resources are allocated.

      multithreaded applications :
        user programs having many relatively independent execution flows sharing a large portion of the application data
	    structures.
      kernel's point of view :
        a multithreaded application was just a normal process.

      "Linux uses lightweight processes to offer better support for multithreaded applications."
      Basically,two lightweight processes may share some resources,if they were associated.

      NPTL - Native POSIX Thread Library
      NGPT - Next Generation POSIX Threading Package

      thread groups :
        in Linux,a thread group is basically a set of lightweight processes that implement a multithreaded application
	    and act as a whole with regards to some system calls such as getpid(),kill(),and _exit().

    Process Descriptor :
      To manage processes,the kernel must have a clear picture of what each process is doing.
      <linux/sched.h>
        struct task_struct;
    	/*  task_struct - linux process descriptor whose fields contain all the information related to a single process.  */
    	/*  some important members :
    	 *    volatile long state;
    	 *    struct thread_info *thread_info;
    	 *    struct mm_struct *mm, *active_mm;
    	 *    struct tty_struct *tty;
    	 *    struct fs_struct *fs;
    	 *    struct files_struct *files;
    	 *    struct signal_struct *signal;
    	 */

    Process State :
      the @state field of the process descriptor describes what is currently happening to the process.
      it consists of an array of flags,each of which describes a possible process state.
      process states :
        TASK_RUNNING
    	  -  running on CPU or wating to be executed.
    	TASK_INTERRUPTIBLE
    	  -  suspended(sleeping) until some condition becomes true.
    	TASK_UNINTERRUPTIBLE
    	  -  like TASK_INTERRUPTIBLE,except that delivering a signal to the sleeping process leaves its state unchanged.
    	TASK_STOPPED
    	  -  execution has been stopped.
    	TASK_TRACED
    	  -  execution has been stopped by a debugger.
    	EXIT_ZOMBIE (@state, @exit_state)
    	  -  execution has been terminated,but the parent process has not yet issued a wait4() or waitpid() system call to
    	     return information about the dead process.(status have to be reported)
    	EXIT_DEAD   (@state, @exit_state)
    	  -  the final state : the process is being removed by the system because the parent process has just issued a wait4()
    	     or waitpid() system call for it.(status had been reported)

      <linux/sched.h>
        /*  set_task_state - set the task's state.
    	 *  @tsk : a pointer points to the task_struct.
    	 *  @state_value : state value.
    	 */
        #define set_task_state(tsk, state_value)  set_mb((tsk)->state, (state_value))

    	/*  set_current_state - set currently executing task's state.
    	 *  @state_value : state value.
    	 */
    	#define set_current_state(state_value)    set_mb(current->state, (state_value))

    	/*  set_mb - enable memory barrier before set value,disable it later.  */


    Identifying a Process :
      general rule : each execution context that can be independently scheduled must have its own process descriptor,
      	      	     even lightweight processes.
      Process ID : Unix-like operating systems allow users to identify processes by means of a number called PID.
                  (task_struct.pid)
         		  /*  by default,the maximum PID number is 32767(PID_MAX_DEFAULT - 1)[32-bit].
        		   *  	  	      	      	  	    4194303[64-bit]
        		   *  for change the maximum PID number dynamically,can write a new value into
        		   *  /proc/sys/kernel/pid_max
        		   */
                  the kernel uses the pidmap_array bitmap to manages PID numbers,which denotes which are the PIDs currently assigned
                  and which are the free ones.
                  /*  32-bit,a page frame contains 32768 bits,so such structure is stored in a single page.
                   *  64-bit,kernel can adds the additional pages to the bitmap,if the PID number is too large.
                   */

                  one process one Process ID !

      POSIX 1003.1c : all threads of a multithreaded application must have the same PID.
      thread groups : the identifier shared by the threads is the PID of the thread group leader,that is,the PID of the
      	     	      first lightweight process in the group.
		              (task_struct.tgid)[getpid() retrives the value of this field]

    Process descriptors handling :
      Processes are dynamic entities,Linux packs two different data structures in a single per-process memory area :
	    >  thread_info                      /*  the structure is defined in <arch/x86/include/asm/thread_info.h>  */
	    >  the Kernel Mode process stack

	  the length of this memory area is usually 8kB(2 pages),kernel stores the 8kB memory area in two consecutive page
	  frames with the first page frame aligned to a multiple of 2^13.(turn out to be a problem when littel dynamic memory
	  is available,but kernel could to be configured that use 4kB memory area to stores the stack and thread_info)

	  the thread_info structure resides at the begining of the memory area,and the stack grows downward from the end(the end
	  of the memory area) !
	  [  thread_info.task -> task_struct ; task_struct.thread_info -> thread_info  ]
	  /*  Linux task_struct is defined in <linux/sched.h>,it contains a field named "stack" which type is void* ,
	   *  kernel use this field to assocaited task_struct with thread_info object.
	   *  macro "#define task_thread_info(task) ((struct thread_info *)(task)->stack)" is used to retrive the
	   *  thread_info object which associated with current process.
	   */

	   /*  <linux/sched.h>
	    *    union thread_union {
        *            struct thread_info thread_info;
	    *            unsigned long stack[THREAD_SIZE/sizeof(long)];
	    *    };  /*  task_struct.stack will points to a thread_union object.  */
	    *        /*  <arch/x86/include/asm/page_32_types.h>:  #define THREAD_SIZE (PAGE_SIZE << THREAD_ORDER)  */
	    */

	   /*  because the thread_info structure is 52B long,the kernel stack can expand up to 8140B  */

	  the kernel uses the alloc_thread_info and free_thread_info macros to allocate and release the memory area storing a
	  thread_info structure and a kernel stack :
	  <kernel/fork.c>
	    /*  alloc_thread_info - sets thread_info field in struct task_struct.
	     *  @tsk : the process descriptor.
	     *  return - NULL or the address of the thread_info object former allocated.
	     */
	    static inline thread_info *alloc_thread_info(struct task_struct *tsk);

	    /*  free_thread_info - release the thread_info object.
	     *  @ti : the pointer points to a thread_info structure object.
	     */
	    static inline void free_thread_info(struct thread_info *ti);

    Identifying the current process :
      the kernel can easily obtain the address of the thread_info structure of the process currently running on a 
	  CPU from the value of the esp register.
	  8kB thread_union :
	    the kernel masks out the 13 least significant bits of esp to obtain the base address of the thread_info structure.
	  4kB thread_union :
	    the kernel masks out the 12 least significant bits of esp to obtain the base address of the thread_info structure.

	  <arch/x86/include/asm/thread_info.h>
	    /*  current_thread_info - retrive the address of the thread_info object which is owns to the running process.  */
	    static inline struct thread_info *current_thread_info(void)
	    {
	            return (struct thread_info *)(current_stack_pointer & ~(THREAD_SIZE - 1));
	    }

    	the kernel can easily obtain the address of the task_struct structure of the process currently running on a CPU from
    	the macro "current".
	    /*  this is can be simply achieved by thread_info.task  */
	    <arch/x86/include/asm/current.h>
	      /*  get_current - retrive the address of a task_struct object which is owns to the current running process.  */
	      static __always_inline struct task_struct *get_current(void);	
	      #define curren get_current()

        advantage of storing the process descriptor with the stack emerges on multiprocessor systems :
	      the correct current process for each hardware processor can be derived just by checking the stack.

    	  /*  earlier versions of Linux did not store the kernel stack and the process descriptor together,instead,they
    	   *  were forced to introduce a global static variable called current to identify the process descriptor of the
    	   *  running process.On multiprocessor systems,it was necessary to define current as an array -- one element for
    	   *  each available CPU.
    	   *  #  Linux 2.6 introduced percpu data,macro "current" will retrives the percpu data for running task.
    	   */

    Doubly linked lists :
      kernel data structure.
	  <linux/list.h>
	    struct list_head {
	            struct list_head *next, *prev;
	    };	
	    some methods :
	  <linux/list.h>
        list_add(n, p)	    inserts @n to @p's next.
        list_add_tail(n, p)	inserts @n to the tail of the list represented by @p.
        list_del(p)	   	    deletes an element pointed to by @p.
        list_empty(p)		checks if the list specified by the address @p of its head is empty.
        list_entry(p, t, m)	returns the address of the data structure of type @t in which the list_head field
              		   	    that has the name @m and the address @p is included.
    	list_for_each(p, h)	scans the elements of the list specified by the address @h of the head;in each
    	  		   	        iteration,a pointer to the list_head structure of the list element is returned in @p.
    	list_for_each_entry(p, h, m)
    	  			        similar to list_for_each,but returns the address of the data structure embedding the list_head
    				        structure rather than the address of the list_head structure itself.

    	usage :
    	  struct kobject {
    	  	  ...
    	          struct list_head list;
    		  ...
    	  };

    	  struct kobject kobj;
    	  INIT_LIST_HEAD(&kobj.list);

    	  struct kobject *new = kmalloc(sizeof(struct kobject), GFP_KERNEL);
    	  if (new) {
    	          list_add(&new->list, &kobj.list);
    	  }

    	  ...
    	  
    	  list_for_each_entry(new, &kobj.list, list) {
    	  	  printk(KERN_DEBUG "%p", new);
    	          ...
    	  }

    	  ...

    	  struct kobject *temp = NULL;
    	  list_for_each_entry_safe(new, temp, &kobj.list, list) {
    	          list_del(&new->list);
    		  kfree(new);
    	  }

    	  ...


      another doubly linked list : hlist.
	    <linux/list.h>
    	  struct hlist_node {
    	          struct hlist_node *next, **prev;
    	  };
    	  struct hlist_head {
    	          struct hlist_node *first;
    	  };

	    methods are similar to list_head's all defined in <linux/list.h>

    The process list :
      a list that links together all existing process descriptors.(task_struct.tasks)
	  the head of the process list is the init_task task_struct descriptor.

	  useful macros :
	    SET_LINKS and REMOVE_LINKS macros are used to insert and to remove a process descriptor in the process 
	    list.(but did not find such macros were defined in Linux 2.6)

	  <linux/sched.h>
	    #define for_each_process(p)  \
	            for (p = &init_task; (p = next_task(p)) != &init_task)
	    /*  @p must be the pointer which is type of task_strcut  */

      The lists of TASK_RUNNING processes :
        only the TASK_RUNNING process is could to be runned on a CPU.

	  #  earlier version :
	       all TASK_RUNNING processes are putted into runqueue,and scheduler have to scans the whole list in order
	       to select the "best" runnable process.(too costly to maintain the list ordered according to process priorities)
	
	  Linux 2.6 :
	    the aim is to allow the scheduler to select the best runnable process in constant time,independently of the number
	    of runnable processes.

	  principle :
	    split the runqueue in many lists of runnable processes,one list per process priority.
	    each task_struct has a field run_list is type of list_head.if the process priority is equal to k,the
	    run_list field links the process descriptor into the list of runnable processes having priority k.
	    on SMP,each CPU has its own runqueue.

	    #  to make scheduler operations more efficient,the runqueue list has been split into 140(0 -- 139) different lists.
	       kernel must preserve a lot of data for every runqueue in the system,however,the main data structures of a runqueue
	       are the lists of process descriptors belonging to the runqueue;all these lists are implemented by a single 
	       prio_array_t data structure.(Linux 2.6 no such data structure)
	       /*
    	    *  prio_array_t {
    		*          int nr_active;		        /*  the number of process descriptors linked into the lists  */
    		*	       unsigned long bitmap[5];	    /*  priority bitmap:each flag is set if and only if the correspoding
    		*                                           priority list is not empty.  */
    		*	       struct list_head queue[140]; /*  the 140 heads of the priority lists  */
    		*  };
    		*/

	  task_struct.prio stored the dynamic priority of the process.
	  task_struct.array is a pointer to the prio_array_t data structure of its current runqueue.(Linux 2.6.34.1 no such field)

	  <linux/sched.h>
	    void (*enqueue_task) (struct rq *rq, struct task_struct *p, int wakeup, bool head);
	    void (*dequeue_task) (struct rq *rq, struct task_struct *p, int sleep);

	    /*  struct sched_class members.
	     *  enqueue_task - inserts @p to @rq,called when a task enters a runnable state.
	     *  dequeue_task - removes @p from @rq,called when a task is no longer runnable.
	     */

    Relationships Among Processes :
      processes created by a program have a parent/child relationship.
	  and the children created by a program have sibling relationships.

	  task_struct.real_parent; /*  type task_struct*  */
	  task_struct.parent;	 /*  type task_struct*  */
	  task_struct.children;	 /*  type list_head     */
	  task_struct.sibling;	 /*  type list_head     */

	  real_parent : the process which has been created @this,or @init process.
	  parent : current parent,this is the process that must be signaled when the child process terminates.
               as usual,real_parent == parent,but it may occasionally differ,such as when another process issues a
		       ptrace() system call requesting that it be allowed to monitor @this process.
      children : @this process's children.
	  sibling : @this process's siblings.

	  task_struct.group_leader;  /*  type task_struct,thread group leader  */

	  #  a process can be a leader of a process group or of a login session,it can be a leader of a thread group,and
	     it can also trace the execution of other processes.

	  (task_struct.signal)->leader_pid;	   /*  PID of the group leader in the thread group  */
	  task_struct.pid				       /*  Process ID  */
	  task_struct.tgid;			           /*  PID of the thread group leader  */
	  tasK_struct.sessionid;			   /*  ID of session associated now  */
	  task_struct.ptrace_children;		   /*  the head of a list containing all children being traced by a debugger  */
						                   /*  Linux 2.6 no such field  */
	  task_struct.ptraced;			       /*  a list of tasks this task is using ptrace on  */
						                   /*  Linux 2.6 no ptrace_list field  */

    The pidhash table and chained lists :
      kernel must be able to derive the process descriptor pointer corresponding to a PID.
	  scanning the process list sequentially and checking the @pid fields of the process descriptors is feasible but rather
	  inefficient.
      four hash tables are used to speed up such operation :
        /*  the reason for multiple hash tables :
    	 *    the process descriptor includes fields that represent different types of PID.
    	 *    each type of PID requires its own hash table.
    	 */

    	task_struct.pids[PIDTYPE_MAX];	/*  type pid_link  */

        [type]         [field]  [introduce]
    	PIDTYPE_PID    pid      PID of the process
    	PIDTYPE_TGID 	 tgid     PID of thread group leader process  /*  Linux 2.6 no such PIDTYPE,but has this field  */
    	PIDTYPE_PGID	 pgrp	  PID of the group leader process	
    	PIDTYPE_SID    session  PID of the session leader process	
    	/*  Linux 2.6 does not exist @pgrp and @session fields in task_struct,there is a field named 'pids' which type
    	 *  is array of struct pid_link and represents the four type pid hashlist.
    	 */
    	/*  Linux 2.6,for retrive group leader's PID,use function task_pgrp(struct task_struct *) ,
    	 *  for retrive session leader's PID,use function task_session(struct task_struct *) .
    	 */

	    <linux/pid.h>
	      enum pid_type {
	            PIDTYPE_PID,
		        PIDTYPE_PGID,
		        PIDTYPE_SID,
		        PIDTYPE_MAX
	      };  /*  Linux 2.6 only has three types of pid.  */

	    task_struct.pid;  /*  this field has type pid_t,such type from typedef __kernel_pid_t,
	  		               *  and __kernel_pid_t is type of int.
			               */
	    task_struct.pids; /*  an array of pid_link.
	  		               *  struct pid_link {
			               *          struct hlist_node node;
			               *          struct pid *pid;
			               *  };
			               */

        these four hash tables are dynamically allocated during the kernel initialization phase,the size of 
	    a single hash table depends on the amount of available RAM.

	  Linux 2.6 use find_pid_ns() and find_vpid() to get the pid object.
	  <linux/pid.h>
	    /*  find_pid_ns - find the pid in a specified pid_namespace.
	     *  @nr : pid value.
	     *  @second-arg : a pointer points to the pid_namespace which is used to find the pid.
	     *  return - struct pid *,or NULL.
	     */
	    extern struct pid *find_pid_ns(int nr, struct pid_namespace *);

	    /*  find_vpid - find the pid in current pid_namespace.  */
	    extern struct pid *find_vpid(int nr);

	    #define pid_hashfn(x)  hash_long((unsigned long)x, pidhash_shift)
	    /*  Linux 2.6 : defined in <kernel/pid.c>
	     *  #define pid_hashfn(nr, ns)  hash_long((unsigned long)nr + (unsigned long)ns, pidhash_shift)
	     *  this macro is used to transform PID into a table index.
	     *  @pidhash_shift stores the length in bits of a table index.
	     */

	    /*  hash_long() based on a multiplication of the index by a suitable large number.
	     *  the magic constant is 0x9e370001(2654404609).
	     *  unsigned long hash = val * 0x9e370001;
	     *  0x9e370001 is a prime near to (2^32) * ((square_root(5) - 1) / 2) that can also
	     *  easily multiplied by additions and bit shifts,because it is equal to 2^31 + 2^29 - 2^25 + 2^22 - 2^19 - 2^16 + 1
	     */

	  Linux uses chaining to handle colliding PIDs;each table entry is the head of a doubly linked list of colliding
	  process descriptors.(as usual,the number of processes in the system is far below 32768)

	  the data structures used in the PID hash tables are quite sophisticated,because they must keep track of the 
	  relationships between the processes.
	    >  if kernel wants to retrive all processes in a specified thread group,it must finds out all the processes
	       each tgid field == @tgid_value.
	       but use @tgid_value to find a process just returns one process descritpor,the thread group leader.
	       so kernel have to maintains a list of processes for each thread group!

	       the fields of the pid structure :
	         int nr;  /*  PID number  */
		     struct hlist_node pid_chain;	/*  hash chain list  */
		     struct list_head pid_list;	/*  the head of the per-PID list  */

	       Linux 2.6 use another definition of pid structure :
	         <linux/pid.h>
		       struct upid {
		               int nr;
			           struct pid_namespace	*ns;
			           struct hlist_node pid_chain;
		       };  /*  this structure represented the Identifier for the pid structure.  */
		       struct pid {
		               atomic_t count;
			           unsigned int level;
			           struct hlist_head tasks[PIDTYPE_MAX];  /*  tasks that use this pid  */
			           struct rcu_head rcu;
			           struct upid numbers[1];
		       };

      pid handling functions :
	    <linux/pid.h>
	      /*  do_each_pid_task - do-while loop head.  */
	      #define do_each_pid_task(pid, type, task)

	      /*  @pid : the pid structure pointer.
	       *  @type : pid type.
	       *  @task : task_struct pointer used to iterate all tasks in the same pid.
	       */

	      #define while_each_pid_task(pid, type, task)
	      /*  while_each_pid_task - do-while loop end.  */

	      /*  Linux 2.6 no such functions  */
	      #define find_task_by_pid_type(type, nr)
	      #define find_task_by_pid(nr)

	      /*  Linux 2.6 has these :
	       *    <linux/sched.h>
	       *      extern struct task_struct *find_task_by_vpid(pid_t nr);
	       *      extern struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns);
	       *      /*  use pid value or pid value with namespace to find the corresponding task.  */
	       */

	      /*  attach_pid - attach task with pid.
	       *  @task : the task pointer.
	       *  @type : pid type.
	       *  @pid : the pid attach to.
	       */
	      extern void attach_pid(struct task_struct *task, enum pid_type type, struct pid *pid);

	      /*  detach_pid - detach task with pid.
	       *  @task : the task pointer.
	       *  @second-arg : the pid type.
	       *  #  @task will attach to NULL pid structure.
	       *     and if pid_link[PIDTYPE].pid->tasks[ALL] is empty,then free_pid(pid).
	       */
	      extern void detach_pid(struct task_struct *task, enum pid_type);

	    <linux/sched.h>
	      /*  next_thread - retrive the next thread.
		   *  @p : the task in the specified thread group.
		   *  return - next task pointer in the thread group or @p.
		   */
	      static inline struct task_struct *next_thread(const struct task_struct *p);

    How Processes Are Organized :
      runqueue lists group all processes in a TASK_RUNNING state.

	  processes in a TASK_STOPPED,EXIT_ZOMBIE,EXIT_DEAD state are not linked in specific lists.
	  there is no need to group processes in any of these three states.

	  processes in a TASK_INTERRUPTIBLE,TASK_UNINTERRUPTIBLE state are subdivided into many classes,
	  each of which corresponds to a specific event.in this case,the process state does not provide enough
	  information to retrive the process quickly,so it is necessary to introduce additional lists of processes,
	  there are called wait queues.

	  Wait queues :
	    wait queues used in kernel particularly for interrupt handling,process synchronization,timing.

	    conditional waits on events :
	      a process wishing to wait for a specific event places itself in the proper wait queue and
	      relinquishes control.
	      therefore,a wait queue represents a set of sleeping processes,which are woken up by the kernel
	      when some condition becomes true.

	    <linux/wait.h>
	      typedef struct __wait_queue wait_queue_t;
	      typedef int (*wait_queue_func_t)(wait_queue_t *wait, unsigned mode, int flags, void *key);
	      struct __wait_queue {
	              unsigned int flags;
                  #define WQ_FLAG_EXCLUSIVE	0x01
		          void *private;			/*  private data,generally stored task_struct address */
		          wait_queue_func_t func;
		          struct list_head task_list;
	      };

	      struct __wait_queue_head {
	              spinlock_t lock;
		          struct list_head task_list;
	      };
	      typedef struct __wait_queue_head wait_queue_head_t;

	      wait_queue_head_t {
	              ... -> wait_queue_t.task_list - > task_list -> wait_queue_t.task_list {
		                  ... -> wait_queue_t.task_list -> wait_queue_t.task_list -> wait_queue_t.task_list -> ...
		          };
	      };

	    there are two kinds of sleeping processes :
	      exclusive processes - wait_queue_t.flags == 1 are selectively woken up by the kernel;
	      nonexlusive processes - wait_queue_t.flags == 0 are always woken up by the kernel when the event occurs.

	      #  two kinds to prevent race for a resource accessing just allow one process on it.
	         a process waiting for a resource that can be granted to just one process at a time is a typical
	         exclusive process.
	         processes waiting for an event that may concern any of them are nonexclusive.

	  Handling wait queues :
	    <linux/wait.h>
	      !  use these two macro to initialize a wait queue head object which is declared statically or dynamically.

	      /*  DECLARE_WAIT_QUEUE_HEAD - declare a wait_queue_head_t object statically.  */	    
	      #define DECLARE_WAIT_QUEUE_HEAD(name)  \
	              wait_queue_head_t name = __WAIT_QUEUE_HEAD_INITIALIZER(name);

	      extern void __init_waitqueue_head(wait_queue_head_t *q, struct lock_class_key *);
	      /*  init_waitqueue_head - initialize a wait_queue_head_t object which is dynamically allocated.  */
	      #define init_waitqueue_head(q) \
	              do {		     \
		              static struct lock_class_key __key;	\
			          __init_waitqueue_head((q), &__key);	\
		          } while (0)


	      !  use these two functions to initialize a wait queue entry with @task or with @wake_up_func.

	      /*  init_waitqueue_entry - initialize a wait_queue element with task @p.
	       *  @q : the target to be initialized.
	       *  @p : task pointer.
	       *  #  @q->flags = 0;
	       *     @q->private = @p;
	       *     @q->func = default_wake_function;	/*  for nonexclusive process  */
	       */
	      static inline void init_waitqueue_entry(wait_queue_t *q, struct task_struct *p);

	      /*  init_waitqueue_func_entry - initialize @q with @func.
	       *  @q : the wait_queue_t object's address.
	       *  @func : the wake up function.
	       *  #  @q->flags = 0;
	       *     @q->private = NULL;
	       *     @q->func = func;
	       */
	      static inline void init_waitqueue_func_entry(wait_queue_t *q, wait_queue_func_t func);


	      !  use these two macros to put "current" into a wait queue and automatically remove it later.

	      /*  DEFINE_WAIT_FUNC - declare a wait_queue_t object @name and initialize it with @function,
	       *                     this object's private field will be initialized to "current".
	       */
	      #define DEFINE_WAIT_FUNC(name, function)
	      /*  DEFINE_WAIT - put "current" process into wait queue and automatically remove it at the time
	       *                it is woken up.
	       *  #  autoremove_wake_function() will invokes default_wake_function() at first,then remove this
	       *     element from the wait queue.
	       */
	      #define DEFINE_WAIT(name)  DEFINE_WAIT_FUNC(name, autoremove_wake_function)


	      !  use these three functions to complete INSERT | INSERT INTO EXCLUSIVE | REMOVE operations.

	      /*  add_wait_queue - insert @wait to @q.
	       *  @q : the head.
	       *  @wait : the element.
	       *  #  for nonexclusive processes.
	       */
	      extern void add_wait_queue(wait_queue_head_t *q, wait_queue_t *wait);

	      /*  add_wait_queue_exclusive - insert @wait to @q.
	       *  #  for exclusive processes.
	       */
	      extern void add_wait_queue_exclusive(wait_queue_head_t *q, wait_queue_t *wait);

	      /*  remove_wait_queue - remove @wait from @q.
	       *  #  this function does not use the @q parameter,but it as an identifier.
	       */
	      extern void remove_wait_queue(wait_queue_head_t *q, wait_queue_t *wait);

	      !  use this function to check if the wait queue is active.

	      /*  waitqueue_active - check if @q is activing(it is not empty) now.  */
	      static inline int waitqueue_active(wait_queue_head_t @q);

      Process wishing to wait :
	    <linux/wait.h>
	      /*  sleep_on - let "current" sleep on @q and it will enter TASK_UNINTERRUPTIBLE state.  */
	      extern void sleep_on(wait_queue_head_t *q);
	      /*  interruptible_sleep_on - "current" will enter TASK_INTERRUPTIBLE state.  */
	      extern void interruptible_sleep_on(wait_queue_head_t *q);

	      /*  sleep_on_timeout - timer version,@timeout is the maximum time to sleep.
	       *                     "current" will enter TASK_UNINTERRUPTIBLE state.
	       *                     if "current" is woken up before timer expire,then
	       *                     the left time will be returned.
	       */
	      extern long sleep_on_timeout(wait_queue_head_t *q, signed long timeout);
	      /*  interruptible_sleep_on - TASK_INTERRUPTIBLE version.  */
	      extern long interruptible_sleep_on_timeout(wait_queue_head_t *q, signed long timeout);

	      !  the sleep_on()-like functions cannot be used in the common situation where one has to
	         test a condition and atomatically put the process to sleep when the condition is not
		     verified.
		     they are a well-known source of race conditions,their use is discouraged.
	         #  sleep_on()-like functions were defined in <kernel/sched.c>.
		        for sleep_on(),it calls to sleep_on_common(),that function sets "current"'s state to
    		    TASK_UNINTERRUPTIBLE,initializes a wait entry with "current",and insert it into @q,
    		    calls schedule_timeout() with MAX_SCHEDULE_TIMEOUT left current process sleeping.

	      /*  prepare_to_wait - does the prepare works for "current" is going to wait.
	       *  @q : the wait queue head.
	       *  @wait : the wait entry.
	       *  @state : the state "current" will be.
	       *  #  this function will set "current"'s state to @state at first,then insert @wait
	       *     into @q.
	       *  #  this version is defined for nonexclusive process.
	       */
	      void prepare_to_wait(wait_queue_head_t *q, wait_queue_t *wait, int state);

	      /*  prepare_to_wait - exclusive version.  */
	      void prepare_to_wait_exclusive(wait_queue_head_t *q, wait_queue_t *wait, int state);

	      /*  finish_wait - finish "current" waiting.
	       *  @q : the wait queue head.
	       *  @wait : the wait entry.
	       *  #  this function will removes @wait from @q,and sets "current"'s state to
	       *     TASK_RUNNING(this will happens before removing).
	       */
	      void finish_wait(wait_queue_head_t *q, wait_queue_t *wait);

	      Usage for prepare_to_wait_*() and finish_wait() :
	        #define __wait_event(wq, condition)					                \
		    do {			 		      				                        \
		            DEFINE_WAIT(__wait);		      			                \
							      				                                \
			        for (;;) {			      				                    \
			                prepare_to_wait(wq, &__wait, TASK_UNINTERRUPTIBLE);	\
				            if (condition)	    	     				        \
				                    break;		     				            \
				            schedule();		     				                \
			        }   	 			      				                    \
			        finish_wait(wq, &__wait);	      				            \
		    } while (0)
		  

	      /*  wait_event - "current" waiting for @condition gets TRUE.
	       *  @wq : the wait queue head pointer.
	       *  @condition : the condition is a C expression.
	       *  #  "current" will enter TASK_UNINTERRUPTIBLE state.
	       *     @condition will be checked each time @wq is woken up.
	       *  #  function wake_up() is used to wake a wait_queue up.
	       */	      
	      #define wait_event(wq, condition)		\
	      do {					                \
	              if (condition)			    \
	                      break;			    \
		          __wait_event(wq, condition);	\
	      } while (0)

	      /*  wait_event_timeout - timer version.
	       *                       if "current" is woken up before timer expired,
	       *                       the left time will be returned.
	       */
          #define wait_event_timeout(wq, condition, timeout)
	      
	      /*  wait_event_interruptible - TASK_INTERRUPTIBLE version.
	       *  return - interrupted,returns -ERESTARTSYS;
	       *           condition got TRUE,returns 0.
	       */
	      #define wait_event_interruptible(wq, condition)


      Kernel wake up the waiting processes :
	    <linux/wait.h>
	      /*  __wake_up* - the main procedure to wake up processes.
	       *               defined in <kernel/sched.c>
	       */	    
	      void __wake_up(wait_queue_head_t *q, unsigned int mode, int nr, void *key);
	      void __wake_up_locked(wait_queue_head_t *q, unsigned int mode);
	      void __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr);

	      /*  TASK_UNINTERRUPTIBLE processes.  */
	      #define wake_up(x)  __wake_up(x, TASK_NORMAL, 1, NULL)
	      #define wake_up_nr(x, nr)  __wake_up(x, TASK_NORMAL, nr, NULL)
	      #define wake_up_all(x)  __wake_up(x, TASK_NORMAL, 0, NULL)
	      #define wake_up_locked(x)  __wake_up_locked((x), TASK_NORMAL)

	      /*  TASK_INTERRUPTIBLE processes.  */
	      #define wake_up_interruptible(x)  __wake_up(x, TASK_INTERRUPTIBLE, 1, NULL)
	      #define wake_up_interruptible_nr(x, nr)  __wake_up(x, TASK_INTERRUPTIBLE, nr, NULL)
	      #define wake_up_interruptible_all(x)  __wake_up(x, TASK_INTERRUPTIBLE, 0, NULL)
	      #define wake_up_interruptible_sync(x)  __wake_up_sync((x), TASK_INTERRUPTIBLE, 1)

	      !  all macros wakeup all nonexclusive processes.
	      	 that is the parameter @nr to __wake_up*() functions is 0,just wake up everything;
		    (includes all nonexclusive processes and all exclusive processes)
    		 if @nr == small + venumber,then wake up all nonexclusive processes and one
    		 exclusive process.(that is what wake_up() to do)
    		 e.g. (code)
    		   if (curr->func(curr, mode, wake_flags, key) &&
    		           (flags & WQ_FLAG_EXCLUSIVE) && !--nr_exclusive)
    	                   break;
    			                                  /*  negative number also is TRUE  */

	      !  TASK_NORMAL is used to wake up TASK_UNINTERRUPTIBLE processes;
	         TASK_INTERRUPTIBLE is used to wake up TASK_INTERRUPTIBLE processes.
	      !  '_nr' suffix macros are used to wake up exclusive processes with the given @nr.
	      	 @nr => @nr_exclusive.
	      !  '_all' suffix macros will wake up all exclusive processes.
	      !  '_sync' suffix macro check whether the priority of any of the woken processes is
	      	 higher than that of the processes currently running in the systems and incoke
    		 schedule() if necessary.(these checks is not made by this macro)
	      !  '_locked' suffix macro requires the wait_queue_head_t.lock has been held.
	      
      
    Process Resource Limits :
      each process has an associated set of resource limits,which specify the amount of system resources
	  it can use.

	  <linux/sched.h>
	    struct signal_struct {
	            ...
		        struct rlimit rlim[RLIM_NLIMITS];
		        ...
	    };

	    task_struct.signal->rlim;

	  <linux/resource.h>
	    struct rlimit {
	            unsigned long rlim_cur;  /*  the current resource limit  */
		        unsigned long rlim_max;  /*  the maximum resource limit  */
	    };

	  !  only the superuser(or,more precisely,a user who has the CAP_SYS_RESOURCE capability) can increase the 
	     @rlim_max or set the @rlim_cur to a value greater than the corresponding @rlim_max field.

	  Kernel use the @index of @rlim member to identify the type of resource-limit.
	  Toltal number of resource-limits in Linux 2.6 is 16,they are defined in <include/asm-generic/resource.h>.

	  #define RLIMIT_CPU  0		        /*  if cpu time exceeds,kernel will send SIGXCPU to the process,  */
	    /*  CPU time in sec  */		    /*  then,if the process does not terminate,SIGKILL will be sent.  */
	  #define RLIMIT_FSIZE  1			/*  if process wish to enlarge filesize greater than this limit,  */
	    /*  maximum filesize  */		/*  kernel will send SIGXFSZ  signal.  */
	  #define RLIMIT_DATA  2			/*  heap size in bytes  */
	    /*  max data size  */
	  #define RLIMIT_STACK  3
	    /*  max stack size  */
	  #define RLIMIT_CORE  4			/*  if limit == 0,kernel does not creates core dump file  */
	    /*  max core file size  */

	  #ifndef ...
	  #define RLIMIT_RSS  5
	    /*  max resident set size  */
	  #define RLIMIT_NPROC  6
	    /*  max number of processes  */
	  #define RLIMIT_NOFILE  7
	    /*  max number of open files  */
	  #define RLIMIT_MEMLOCK  8		/*  size of nonswappable memory in bytes  */
	    /*  max locked-in-memory address space  */
	  #define RLIMIR_AS  9	   	        /*  kernel checks this limit when malloc() was called  */
	    /*  address space limit  */
	  #define RLIMIT_LOCKS  10
	    /*  maximum file locks held  */
	  #define RLIMIT_SIGPENDING  11
	    /*  max number of pending signals  */
	  #define RLIMIT_MSGQUEUE  12
	    /*  maximum bytes in POSIX mqueues  */
	  #define RLIMIT_NICE  13
	    /*  max nice prio allowed to raise to  0-39 for nice level 19 .. -20  */
	  #define RLIMIT_RTPRIO  14
	    /*  maximum realtime priority  */
	  #define RLIMIT_RTTIME  15
	    /*  timeout for RT tasks in us  */
	  #endif 

	  #define RLIMIT_NLIMITS  16

	  /*  resource limit value  */
	  #ifndef RLIM_INFINITY
	  #define RLIM_INFINITY  (~0UL)
	    /*  no user limit is imposed on the corresponding resource  */
	  #endif


    Process Switch :
      kernel suspends the executing of the process that is running on the CPU and resume it later.
	  kernel suspends a process and pick up another process to be executing.

	  these different names all refers to the process switch : process switch, task switch, context switch

	  !  Process Switch occurs only in Kernel Mode.

	  Hardware Context :
	    the set of data that must be loaded into the registers before the process resumes its execution on the
	    CPU is called the "hardware context".it is the subset of the process execution context,which includes all
	    information needed for the process execution.

	    Linux,a part of hardware context is stored in process descriptor,while the remaining part is saved in the
	    Kernel Mode stack.

	    !  because process switches occur quite often,it is important to minimize the time spent in saving and 
	       loading hardware contexts.

	    /*  Old versions of Linux took advantage of the hardware support offered by the 80x86 architecture and
	     *  performed a process switch through a "far jmp" instruction to the selector of the 
	     *  Task State Segment Descriptor of the next process.
	     */

	    Linux 2.6 uses software to perform a process switch for the following reasons :
	      >  Step-by-step switching performed through a sequence of "mov" instructions allows better control
	         over the validity of the data being loaded.
	         (it is possible to check the values of the ds and es segmentation registers)

	      >  the amount of time required by the old approach and the new approach is about the same.
	         However,it is not possible to optimize a hardware context switch,while there might be room
	         for improving the current switching code.

	  Linux stores the contents of all registers used by a process in User Mode into the Kernel Mode
	  stack before performing process switching.(includes ss esp .etc)

      Task State Segment :
	    80x86 architecture includes a specific segment type called Task State Segment(TSS) to store hardware
	    contexts.Linux does not use hardware context switching,but it is still set up TSS for each CPU in the
	    system.
	    the reasons :
	      >  when an 80x86 CPU switches from User Mode to Kernel Mode,it fetches the address of the Kernel Mode
	         stack from the TSS.
	      >  when a User Mode process attempts to access an I/O port by means of an "in" or "out" instruction,
	         the CPU may need to access an I/O Permission Bitmap stored in the TSS to verify whether the process
	         is allowed to address the port.

	    #  a process executes an "in" or "out" I/O instruction in User Mode :
	       the control unit performs the following operations >
		     1>  checks the 2-bit IOPL field in the "eflags" register.
		         IOPL == 3, executes I/O instructions,
		         Otherwise, performs the next check.
	         2>  accesses the "tr" register to determine the current TSS,and thus the proper
	   	         I/O Permission Bitmap.
	         3>  checks the bit of the I/O Permission Bitmap corresponding to the I/O port
		         specified in the I/O instruction.
			     cleared => instruction is executed,
			     setted  => raises a "General protection" exception.

        the tss_struct structure describes the format of the TSS :
	      <arch/x86/include/asm/processor.h>
	        struct tss_struct {
	                struct x86_hw_tss	x86_tss;
		            /*  extra 1 is there because CPU will access an
		             *  additional byte,and the extra byte must be all 1 bits.
		             */
		             unsigned long io_bitmap[IO_BITMAP_LONGS + 1];
		             unsigned long stack[64];  /*  another 0x100 bytes for emergency kernel stack  */
	        } ____cachingline_aligned;

	    the init_tss array stores one TSS for each CPU on the system :
	      <arch/x86/include/asm/processor.h>
	        DECLARE_PER_CPU_SHARED_ALIGNED(struct tss_struct, init_tss);
	        /*  the invoked macro is defined in <linux/percpu-defs.h>  */
        !  at each process switch,the kernel updates some fields of the TSS so that the corresponding
	       CPU's control unit may safely retrive the information it needs.
	       (TSS reflects the privilege of the current process on the CPU,but there is no need to maintain
	        TSSs for processes when they're not running.)

	    TSS <=> TSSD (Task State Segment Descriptor)
	    /*  in the Intel's original design,each process in the system should refer to its own TSS;
	     *  the second least significant bit of the Type field is called the Busy bit;
	     *  it is set to 1 if the process is being executed by a CPU,and to 0 otherwise.
	     *  in Linux design,there is just one TSS for each CPU,so the Busy bit is always set to 1.
	     */

	    TSSDs stored in GDT,whose base address is stored in the gdtr register of each CPU.
	      the tr register of each CPU contains the TSSD Selector of the corresponding TSS.
	      the register also includes two hidden,nonprogrammable fields :
	      the Base field of the TSSD
	      the Limit field of the TSSD
	  
	  The thread field :
	    at every process switch,the hardware context of the process being replaced must be saved in
	    somewhere,but it can not be stored in TSS,because in Linux Design,one TSS for one CPU.

	    /*  thread - task_struct member which type is thread_struct  */
	    task_struct.thread;	 /*  CPU-specific state of this task  */

	    <arch/x86/include/asm/processor.h>
	      struct thread_struct {
	              ...
	      };
	      /*  this structure represents the CPU-specific state for a task,
	       *  Linux saves hardware context in such object whenever the process is being switched out.
	       *  this structure contains fields for most of the CPU registers,except the general-purpose
	       *  registers such as eax,ebx, etc.,which are stored in the Kernel Mode stack.
	       */


      Performing the Process Switch :
	    A process switch may occur at just one well-defined point :
	      the schedule() function.(<include/linux/sched.h>, <kernel/sched.c>)
	    
	    every process switch consists of two steps :
	      1>  switching the Page Global Directory to install a new address space.
	      2>  switching the Kernel Mode stack and the hardware context,which provides all the
	    	  information needed by the kernel to execute the new process,including the CPU registers.

        @prev -> the process been replaced.
	    @next -> the process being activated.

	    The switch_to macro :
	      <include/asm-generic/system.h>
            /*  switch_to - switch previous process to next process.
	         *  @prev : the previous process,it is often got by "current".
	         *  @next : the next process switch to.
	         *  @last : it is an output parameter that specifies a memory location
	         *  	      in which the macro writes the descriptor address of process C.
	         *    	  (this is done after A resumes its execution)
	         *  #  before the process switching,the macro saves in the eax CPU register
    	     *	   the content of the variable identified by the first input parameter @prev,
    	     *	   after the process switching,when A has resumed its execution,the macro
    	     *	   writes the content of the eax CPU register in the memory location of A
    	     *	   identified by the third output parameter @last.
    	     *  #  this function will call to the architecture based __switch_to()
    	     *     function to accomplishes the primary works,that function is
    	     *     defined in <arch/"model"/asm/process_(32 | 64).h>
    	     */
	        #define switch_to(prev, next, last)			\
	              do {						\
		              ((last) = __switch_to((prev), (next)));	\
		          } while (0)

	      !  there is another switch_to() function is defined in <arch/x86/include/asm/system.h>,
	      	 which has introduced the detail for how process switching be executed.
		     the switch_to() in <asm/system.h> is the architecture based switch_to() function,
		     not the asm-generic version.
		     for x86,this switch_to() will be called by context_switch() function which is defined
		     in <kernel/sched.c>.(because <linux/sched.h> includes <asm/systemd.h>)
		     the primary assembly :
		       pushfl			#  save eflags
		       pushl %%ebp			#  save base stack pointer
		       movl	 %%esp, %[prev_sp]	#  save  stack pointer
		       movl	 %[next_sp], %%esp	#  restore stack pointer
		       movl	 $1f, %[prev_ip]	#  save ip
		       pushl %[next_ip]		#  push ip into stack for ret instruction
		       __switch_canary		#  macro defined in <asm/system.h>
		       jmp   __switch_to		#  jump to __switch_to() function
		       1:	 			#  symbol
		       popl	 %%ebp			#  restore base stack pointer
		       popfl 			#  restore eflags


	      figure :
	        switch_to(A, B, A) {
		      A {
		              prev = A
		              next = B
		              eax = A
		              last = A
		      }

		      B {
		              prev = B
		              next = other
		              eax = A	/*  this register will be updated after function invocation completed
		    	  	             *  or process switching was occurred.
				                 */
	                  last = A
		      }
		    }
		    /*  there just one kernel existed,so the code for context switching is same between
		     *  processes.
		     */
		    switch_to(C, A, C) {
		      C {
		              prev = C
		              next = A
		              eax = C
		              last = C
		      }

		      A {
		              prev = A
		              next = other
		              eax = C	/*  this register will be updated after function invocation completed
		    	  	             *  or process switching was occurred.
				                 */
		              last = C
		      }
		    }

		!  the process has been switched at the time that @next->thread.esp was loadded into
		   esp register.
		   (this operation is take affect when arch_end_context_switch(@next) was called)
		   the kernel stack of previous process is saved in @prev->thread.esp.
		   (this operation is accomplished when arch_start_context_switch(@prev) was called)
	   

	    The __switch_to() function :
	      <arch/x86/include/asm/system.h>
	      <arch/x86/kernel/process_(32 | 64).c>

	        /*  __switch_to - does the bulk of the process switch started by the switch_to() macro.
	         *  @prev_p : previous task pointer.
	         *  @next_p : next task pointer.
	         *  return -  @prev_p.
	         *  	      switch_to() macro will replaces esp register(ebp was not replaced,it was pushed
	         *            into the stack of @prev and popped up later) before jmp to __switch_to().
	         *            but the arguments of __switch_to() are stored in CPU generic-purpose registers
	         *            that is eax(@prev_p) and edx(@next_p),finally,it returns the value in eax register,
	         *	          so it is @prev_p.
	         *  #  __attribute__(regparm(3)) should be attached to __switch_to(),but it did not detect such
	         *     GCC attribute is used.
	         *     regparm(number) : this attribute just take affect only if x86-32 targers,it tell compiler
	         *     		             that,store the parameter from number one to @number in CPU registers
	         *		                 eax,edx,ecx(so the maximum @number is 3) to instead store them on stack.
	         */
	        __notrace_funcgraph struct task_struct *
	        __switch_to(struct task_struct *prev_p, struct task_struct *next_p);

	        the works this function does :
	          /*  @prev_p -> previous task pointer.
		       *  @prev   -> previous task's thread structure.
		       *  @next_p -> next task pointer.
		       *  @next   -> next task's thread structure.
		       */
	          1>  get local CPU id and local tss.
		      2>  check if the task @next_p is used math function,if it used and
		          @next_p->fpu_counter > 5,then set @preload_fpu to true.
		      3>  call to "__unlazy_fpu(prev_p);" this macro optionally save the contents of the FPU,MMX,XMM of
		          @prev_p.
		      4>  if @preload_fpu is T => prefetch(@next->xstate) .
		      5>  call to "load_sp0(@tss, @next);",load @next->esp0 into @tss->esp0.
		          any future privilege level change from User Mode to Kernel Mode raised by a sysenter assembly
		          instruction will copy this address in the esp register.
		      6>  call to "lazy_save_gs(@prev->gs);",this macro is defined through savesegment(gs, (v)),it stores
		          gs register in the @prev->gs.
		      7>  call to "load_TLS(@next, @cpu);",loads in the Global Descriptor Table of the local CPU the 
		          Thread-Local Storage segments used by the @next_p process,the Segment Selectors are stored in
		          @next->tls_array member.
		      8>  restore IOPL if needed.
		          in normal use,the flags restore in the switch assembly will handle this,but if the kernel
		          is running virtualized at a non-zero CPL,the popf will not restore flags,so it must be done
		          in a separate step.
		      9>  handle debug registers and/or IO bitmaps.
		          if this is necessary,call to "__switch_to_xtra(@prev_p, @next_p, @tss);".
		      10> if @preload_fpu is T => execute clts instruction.
		      11> call to "arch_end_context_switch(@next_p);" to ensure context switching has been completed.
		      12> if @preload_fpu is T => call to "__math_stat_restore();" restore math registers.
		      13> restore gs if needed(if (@prev->gs || @next->gs) lazy_load_gs(@next->gs); ).
		      14> update percpu data via "percpu_write(current_task, @next_p);").
		      15> return @prev_p.


        Saving and Loading the FPU,MMX,XMM registers :
	      from Intel 80486DX,the arithmetic floating-point unit(FPU) has been integrated into the CPU.the name
	      'mathematical coprocessor' continues to be used in memory of the days when floating-point computations
	      were executed by an expensive special-purpose chip.
	      ESCAPE instructions(for compatible with older models) are instructions with a prefix byte ranging
	      between 0xd8 -- 0xdf,these instructions act on the set of floating-point registers included in the CPU.
	      !  if a process is using ESCAPE instructions,the contents of the FPU registers belong to its hardware
	         context,so they are should be saved and restored later.

	      MMX : new instructions were introduced on Pentium models,supposed to speed up the execution of multimedia
	            applications.
		  MMX instructions act on the FPU registers.
		  disadvantage : programmers can not mix FPU instructions and MMX instructions.
		  advantage    : for OS designer,save the FPU state is to save MMX state.
		  MMX introduced SIMD(single-instruction multiple-data) pipeline inside the processor.

		  !  Pentium III model extends that SIMD capability :
		       it introduces the SSE extensions(Streaming SIMD Extensions),which adds facilities for handling
		       floating-point values caontained in eight 128-bit registers called the XMM registers.
		       (XMM0 -- XMM7)
		       XMM registers do not overlap the FPU and MMX registers.(it is able to mix SSE and FPU/MMX)
		  !  Pentium 4 model introduces yet another feature : SSE2 Extensions.
		       which is basically an extension of SSE supporting higher-precision floating-point values,
		       it uses the same set of XMM registers as SSE.

            80x86 model do not save the FPU,MMX,XMM registers in the TSS automatically,but it enables kernel to do
	        that if necessary.

	      cr0.TS flag : TS(Task-Switching)
	        which obeys the following rules :
			  >  every time a hardware context switch is performed,the TS flag is set.
			  >  every time an ESCAPE,MMX,SSE,SSE2 instruction is executed when the TS flag is set,
			     the control unit raises a "Device not available" exception.

	      figure :
	        A is using mathematical coprocessor;
		    switch occurs from A to B,cr0.TS = 1,saves floating-point registers to A.tss;
		    B is not using mathmetical coprocessor => kernel do not need to restore floating-point registers;
		    B try to use mathmetical coprocessor -> cr0.TS has been setted -> "Device not available" exception;
		    kernel handle the exception => restore the floating-point registers from B.tss;

          FPU,MMX,XMM structures :
	        <arch/x86/include/asm/processor.h>
	          struct i387_fsave_struct;	/*  FPU,MMX state  */
		      struct i387_fxsave_struct;	/*  SSE,SSE2 state */
		      struct i387_soft_struct;	/*  older compatibility  */
		       				            /*  it is used for the older CPU model which is no
						                 *  mathmetical coprocessor.
						                 */
		      union thread_xstate {
		        struct i387_fsave_struct fsave;
			    struct i387_fxsave_struct fxsave;
			    struct i387_soft_struct soft;
			    struct xsave_struct xsave;
		      };  /*  thread_struct.xstate (pointer type)  */

            the process descriptor includes two additional flags :
	        task_struct.thread_info.status { TS_USEDFPU }
	        task_struct.flags { PF_USED_MATH }

	        TS_USEDFPU : it specifies whether the process used the FPU,MMX,XMM registers in the current execution run.
	        PF_USED_MATH : it specifies whether the contents of the thread_struct.xstate are significant,the flag is
	      		           cleared in two cases :
			                 1>  when the process starts executing a new program by invoking an execve() system call,
			       	             because the control will never return to the former program,the data currently stored
				                 in thread_struct.xstate is never used again.
			                 2>  when a process that was executing a program in User Mode starts executing a signal
			       	             handler procedure,because signal handlers are asynchronous with respect to the program
				                 execution flow,the floating-point registers could be meaningless to the signal handler.
				                 however,the kernel saves the floating-point registers in thread_struct.xstate before
				                 starting the handler and restores them after the handler terminates.(that is the signal
				                 handler is allowed to use floating-point features)

          Saving the FPU registers :
	        <arch/x86/include/asm/i387.h>
	          /*  __unlazy_fpu - save fpu state.
		       *  @tsk : the target,which often is @prev in __switch_to().
		       *  return - none.
		       *  #  this function checks if TS_USEDFPU flag of @tsk's thread_info.status is set,
		       *     TS_USEDFPU == 1,then call to __save_init_fpu(@tsk),and call to stts().
		       *     TS_USEDFPU == 0,then @tsk->fpu_counter = 0.
		       */
	          static inline void __unlazy_fpu(struct task_struct *tsk);

		      /*  __save_init_fpu - save fpu state and then initializes them.
		       *  @tsk : the target.
		       *  return - none.
		       *  #  this function maybe call to either xsave(@tsk) or fxsave(@tsk),that is determined by
		       *     task_thread_info(@tsk)->status & TS_XSAVE.
		       *     then call to clear_fpu_state(@tsk) to initializes fpu state to fixed values,
		       *     and clear TS_USEDFPU in the @tsk's thread_info.status.
		       */
		      static inline void __save_init_fpu(struct task_struct *tsk);

            <arch/x86/include/asm/system.h>
	          /*  stts - a macro sets cr0.TS flag.  */
	          #define stts() write_cr0(read_cr0() | X86_CR0_TS)

          Loading the FPU registers :
	        the contents of the floating-point registers are not restored right after the @next process
	        resumes execution.(but __switch_to() restored it if @preload_fpu is TRUE)
	        however,the TS flag of cr0 has been set by __unlazy_fpu(),thus,the first time the @next process
	        tries to execute an ESCAPE,MMX,SSE/SSE2 instruction will traps an exception,then handler calls to
	        math_state_restore() to restore the contents.

	        <arch/x86/include/asm/i387.h>
	          /*  math_state_resotre - exception handler to deal with use mathematical coprocessor when TS == 1.
		       *  #  this function checks @task is used math at first(PF_USED_MATH flag),
		       *     if it is not,then call to init_fpu() to initializes FPU(PF_USED_MATH set to 1) before
		       *     next execution;
		       *     call to clts() to clear cr0.TS,then invoke __math_state_restore() to do primary works.
		       *     (if TS == 1,execute ESCAPE,MMX,SSE/SSE2 instruction will traps exception)
		       */
	          extern asmlinkage void math_state_restore(void);

		      /*  __math_state_restore - restores fpu for @tsk and set TS_USEDFPU.
		       *  #  @tsk = thread->task;  =>
		       *     @thread = current_thread_info();
		       *     call to restore_fpu_checking(@tsk),(this function execute "fxrstor" instruction)
		       *     set TS_USEDFPU,
		       *     @tsk->fpu_counter++.
		       */
		      extern void __math_state_restore(void);

          Using the FPU,MMX,and SSE/SSE2 units in Kernel Mode :
	        !  IF IT IS NOT NECESSARY,DO NOT USE x87 IN KERNEL MODE.
	        use x87 in Kernel Mode is more expensive than User Mode.
	      
	        if kernel use FPU,it should avoid interfering with any computation carried on by the current 
	        User Mode process.

	        <arch/x86/include/asm/i387.h>
	          /*  kernel_fpu_begin - kernel ready to use FPU.
		       *  #  disable preempt,
		       *     checks if current thread is used FPU(TS_USEDFPU),then save the state,
		       *     if it is not,just clts().
		       */
	          static inline void kernel_fpu_begin(void);

		      /*  kernel_fpu_end - kernel end use FPU.
		       *  #  set cr0.TS by stts(),
		       *     enable preempt.
		       */
		      static inline void kernel_fpu_end(void);

            because the FPU state of User Mode process has been saved,so math_state_restore() will be called
	        later when the process tries to execute an ESCAPE,MMX,SSE/SSE2 instruction.

	        !  the kernel uses FPU only in a few places,typically when moving or clearing large memory areas
	      	   or when computing checksum functions.


    Creating Processes :
      Traditional Unix systems treat all processes in the same way :
	    resources owned by the parent process are duplicated in the child process.
	    !  this approach makes process creation very slow and inefficient.

	  Modern Unix kernels solve this problem by introducing three different mechanisms :
	    1>  Copy-On-Write
	    2>  Lightweight processes allow both the parent and the child to share many perprocess kernel data
	        structures,such as the paging tables,the open file tables,and the signal dispositions.
	    3>  the vfork() system call creates a process that shares the memory address space of its parent,
	        to prevent the parent from overwriting data needed by the child,the parent's execution is blocked
	        until the child exits or executes a new program.

	  The clone(),fork(),and vfork() System Calls :
	    Lightweight processes are created in Linux by using a function named clone().
	    <linux/sched.h>
	      /*  clone - Linux system call,create a lightweight process.
	       *  @fn : the function to be executed.
	       *  @child_stack : User Mode stack pointer was assigned to esp register.
	       *  @flags : flags,the low byte specifies the signal number to be sent to the parent process when
	       *           child terminates,the SIGCHLD signal is generally selected;
	       *           remaining three bytes encode a group of clone flags.
	       *  @arg : arguments to @fn.
	       *  @ptid : address of a User Mode variable of the parent process that will hold the PID of the 
	       *          new lightweight process.meaningful only if the CLONE_PARENT_SETTID flag is set.
	       *  @newtls : address of a data structure that defines a Thread Local Storage segment for the new
	       *            lightweight process,meaningful only if the CLONET_SETTLS flag is set.
	       *  @ctid : address of a User Mode variable of the new lightweight process that will hold the PID
	       *          of such process,meaningful only if the CLONE_CHILD_SETTID flag is set.
	       *  return - lighetweight process's thread ID will be returned,if succeed.
	       *           Otherwise,-1 will be returned,and no lightweight process has been created.
	       *		 error value will be set appropriately.
	       */
	      int clone(int (*fn)(void *), void *child_stack, int flags, void *arg,
	                /*  pid_t *ptid, void *newtls, pid_t *ctid  */ ...);
          /*  System-Call  */

	      clone flags :
	        CLONE_VM - shares the memory descriptor and all Page Tables.
	        CLONE_FS - shares the table that identifies the root directory and the current working directory,
	                   as well as the value of the bitmask used to mask the initial file permissions of a new
			           file.
	        CLONE_FILES - shares the table that identifies the open files.
	        CLONE_SIGHAND - shares the tables that identify the signal handlers and the blocked and pending signals.
	      	                if this flag is true,the CLONE_VM flag must also be set.
	        CLONE_PTRACE - if traced,the parent wants the child to be traced too,furthermore,the debugger may want
	      		           to trace the child on its own,in this case,the kernel forces the flag to 1.
	        CLONE_VFORK - set when the system call issued is a vfork().
	        CLONE_PARENT - set the parent of the child to the parent of the calling process.
	        CLONE_THREAD - inserts the child to the same thread group of the parent,and forces the child to share
	      		           the signal descriptor of the parent,the child's tgid and group_leader fields are set
			               accordingly.if the flag is true,the CLONE_SIGHAND flag must also be set.
	        CLONE_NEWNS - set if the clone needs its own namespace,that is,its own view of the mounted filesystems;
	      	              it is not possible to specify both CLONE_NEWNS and CLONE_FS.
	        CLONE_SYSVSEM - shares the SystemV IPC undoable semaphore operations.
	        CLONE_SETTLS - creates a new Thread Local Storage segment for the lightweight process.
	        CLONE_PARENT_SETTID - writes the PID of the child into the User Mode variable of the parent pointed to
	      	                      by the @ptid parameter.
	        CLONE_CHILD_CLEARTID - when set,the kernel sets up a mechanism to be triggered when process will exit or
	      			     when it will start executing a new program.in these cases,the kernel will clear the
			     	     User Mode variable pointed to by the @ctid parameter and will awaken any process
				         waiting for this event.
	        CLONE_DETACHED - a legacy flag ignored by the kernel.
	        CLONE_UNTRACED - set by the kernel to overried the value of the CLONE_PTRACE flag.
	        CLONE_CHILD_SETTID - writes the PID of the child into the User Mode Variable of the child pointed by the
	                             @ctid parameter.
	        CLONE_STOPPED - forces the child to start in the TASK_STOPPED state.

	      !  the clone flags were defined in kernel have more values,these values were used by kernel routine.

	      !  the clone() in C library is actually a wrapper of the sys_clone() defined in <arch/x86/kernel/process.c>.
	         and sys_clone() will call to do_fork() function.
	         sys_clone() does not have the @fn and @arg parameters,in fact,the wrapper function saves the pointer @fn
	         into the child's stack position corresponding to the return address of the wrapper function itself;
	         the pointer @arg is saved on the child'stack right below @fn.

	      !  sys_fork() similar to sys_clone(),but flag only the SIGCHLD was set and all clone flags are cleared,
	         stack pointer is point to the parent's stack,remaining arguments set to NULL.

	      !  sys_vfork() similar to sys_clone(),but flag is set to CLONE_VFORK | CLONE_VM | SIGCHLD combination,
	         stack pointer is point to the parent's stack,remaining arguments set to NULL.


      The do_fork() function :
	    <linux/sched.h> <kernel/fork.c>
	      /*  do_fork - the main fork routine.
	       *  @clone_flags : same as the @flags parameter of clone().
	       *  @stack_start : the stack's start point,same as the @child_stack parameter of clone().
	       *  @regs : pointer to the values of the general purpose registers saved into the Kernel Mode stack
	       *          when switching from User Mode to Kernel Mode.
	       *  @stack_size : unused parameter,always set to 0.
	       *  @parent_tidptr : same as the @ptid parameter of the clone().
	       *  @child_tidptr : same as the @ctid parameter of the clone().
	       *  return - pid of the forked process returned on successful,otherwise returns error code.
	       *           return from fork is different between parent and child!(but do_fork() always called 
	       *           by kernel in parent's context)
	       */
	      extern long do_fork(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs,
	    	   	              unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr);

	    the primary works that do_fork() do :
	      /*  do_fork() call to copy_process() to finish process copying,and copy_process() call to copy_thread()
	       *  to finish thread copying.
	       */
	      1>  allocates a new PID for the child by looking in the @pidmap_array bitmap.

	      2>  checks the ptrace field of the parent(current->ptrace) :
	          ptrace != 0 => the parent process is being traced by another process,thus do_fork() checks whether
		      the debugger wants to trace the child on its own(independently of the value of the CLONE_PTRACE
		      flag specified by the parent),in this case,if the child is not a kernel thread(CLONE_UNTRACED
		      flag cleared),the function sets the CLONE_PTRACE flag.

          3>  invokes copy_process() to make a copy of the process descriptor.

	      4>  if either the CLONE_STOPPED flag is set or the child process must be traced,that is,the PT_PTRACED flag
	          is set in @p->ptrace,do_fork() set the state of the child to TASK_STOPPED and adds a pending SIGSTOP
		      signal to it.
		
          5>  if the CLONE_STOPPED flag is not set,it invokes the wake_up_new_task() function,which performs the following
	    	  operations :
		        >  adjusts the scheduling parameters of both the parent and the child.

		        >  if the child will run on the same CPU as the parent,and parent and child do not share the same set of
		           page tables(CLONE_VM flag cleared),it then forces the child to run before the parent by inserting it 
		           into the parent's runqueue right before the parent.(if child flushes its address space and executes a new
		           program right after the forking,this way will prevent unnecessary cost for COPY-ON-WRITE)
		           otherwise(child run on the same CPU as parent,or CLONE_VM flag set),it inserts the child in the last
		           position of the parent's runqueue.

	      6>  CLONE_STOPPED == 1 => put @child -> TASK_STOPPED.

	      7>  if the parent process is being traced,it stores the PID of the child in the current->ptrace_message,
	    	  and invokes ptrace_notify().(this function was called by ptrace_event()<linux/ptrace.h>,and ptrace_event() was
		      called by tracehook_report_clone_complete()<linux/tracehook.h>)
		      ptrace_notify() stops the current process and sends a SIGCHLD signal to its parent,the "grandparent" of the child
		      is the debugger that is tracing the parent;the SIGCHLD signal notifies the debugger that current has forked a child,
		      whose PID can be retrieved by looking into the  current->ptrace_message field.
		      /*  Linux 2.6,ptrace_notify() was called in ptrace_event() with ((event << 8) | SIGTRAP),
		       *  a siginfo_t structure was allocated in ptrace_notify() and @info.si_signo set to SIGTRAP,ptrace_notify() then
		       *  call to ptrace_stop(),which set current->last_siginfo = @info,and put current into TASK_TRACED(let debugger run).
		       *  I DID NOT FIND OUT THE SIGCHLD WAS SENT TO THE @current's PARENT FROM THE SOURCE CODE!
		       *  ptrace_notify() JUST CALLED WITH THE PARAMETER 100000101 BY ptrace_event()(SIGTRAP == 5,PTRACE_EVENT_FORK == 1).
		       */

          8>  if the CLONE_VFORK flag is specified,it inserts the parent process in a wait queue and suspends it until the child
	          releases its memory address space.

          9>  terminates by returning the PID of the child.


      The copy_process() function :
	    the copy_process() function sets up the process descriptor and any other kernel data structure required for a child's
	    execution.
	    <kernel/fork.c>
	      /*  copy_process - create a new process as a copy of the old one,but does not actually start it yet.
	       *  @clone_flag:   clone flags same as do_fork().
	       *  @stack_start:  same as do_fork() @stack_start.
	       *  @regs:	     same as do_fork() @regs.
	       *  @stack_size:   same as do_fork() @stack_size,it is unused.
	       *  @child_tidptr: same as do_fork() @child_tidptr.
	       *  @pid:	         a pointer points to an object which type is struct pid,this parameter is used
	       *		         to save child's pid.
	       *  @trace:	     for ptrace mechanism.
	       *  return -       the task_struct pointer of the child process,ERR_PTR would be returned if 
	       *	       	     any error occurred.
	       */
	      static struct task_struct *copy_process(unsigned long clone_flag, unsigned long stack_start,
	    	   	  	      		                  struct pt_regs *regs, unsigned long stack_size, 
						                          int __user *child_tidptr, struct pid *pid, int trace);

        the primary works of copy_process() :
	      1>  checks whether the flags passed in the clone_flags parameter are compatible.
	    	  in particular,it returns an error code in the following cases :
		        <  CLONE_NEWNS == 1 AND CLONE_FS == 1
		        <  CLONE_THREAD == 1 AND CLONE_SIGHAND == 0
		        <  CLONE_SIGHAND == 1 AND CLONE_VM == 0
	    
	      2>  performs any additional security checks by invoking security_task_create(),this function call to
	    	  security_ops->task_create().

          3>  invokes dup_task_struct() to get the process descriptor for the child.
	          this function performs the following actions :
		        <  invokes __unlazy_fpu() on the current process to save,if necessary.
		           later,dup_task_struct() will copy these values in the thread_info structure of the child.
		        <  executes the alloc_task_struct() macro to get a process descriptor for the new process,and
		           stores its address in the @tsk local variable.
		        <  executes the alloc_thread_info macro to get a free memory area to store the thread_info structure
		           and the Kernel Mode stack of the new process,and saves its address in the @ti local variable.
		        <  copies the contents of the @current's process descriptor into @tsk,then sets @tsk->thread_info
		           to @ti.
		        <  copies the contents of the @current's thread_info descriptor into @ti,then sets @ti->task to @tsk.
		        <  sets the usage counter of the new process descriptor(@tsk->usage) to 2 to specify that the process
		           descriptor is in use and that the corresponding process is alive.
		        <  returns the process descriptor pointer of the new process(@tsk).

          4>  checks whether the value stored in @current->signal->rlim[RLIMIT_NPROC].rlim_cur is smaller than the
	    	  current number of process owned by the user.
		      if it is not true,an error code is returned,unless 'capable(CAP_SYS_ADMIN) OR capable(CAP_SYS_RESOURCE) OR
		      @p->real_cred->user-> == INIT_USER)'.
		      this function gets the current number of processes owned by the user from a per-user data structure named
		      user_struct,this data structure can be found through a pointer in the user field of the process descriptor.
		      (task_struct->real_cred->user->processes)

          5>  increase the usage counter of the user_struct structure(user_struct.__count) and the counter of the process
	    	  owned by the user(user_struct.processes).

          6>  checks that the number of processes in the system does not exceed the value of the max_threads variable.
	          /*  write a new value into /proc/sys/kernel/threads-max file is able to change this limit dynamically.  */

          7>  if the kernel functions implementing the execution domain and the executable format of the new process
	          are included in the kernel modules,it increase their usage counters.

          8>  sets a few crucial fields related to the process state :
	            <  @tsk->lock_depth = -1 	    (no lock hold)
		        <  @tsk->did_exec = 0 	        (no exec did)
		        <  @tsk->flags = @current->flags & ~PF_SUPERPRIV | PF_FORKNOEXEC

          9>  @tsk->pid = pid_nr(pid)  /*  @pid is allocated by alloc_pid()  */
	    
	      10> if @clone_flags & CLONE_PARENT_SETTID => *@parent_tidptr = @tsk->pid
	      	  this work is did by do_fork() through put_user(Linux 2.6)

          11> initializes the list_head data structures and the spin locks included in the child's process descriptor,
	          and sets up several other fields related to pending signals,timers,and time statistics.

          12> invokes copy_semundo(),copy_files(),copy_fs(),copy_sighand(),copy_signal(),copy_mm(),copy_namespace()
	          to create new data structures and copy into them the values of the corresponding parent process
		      data structures unless specified differently by the @clone_flags.

	      13> invokes copy_thread() to initialize the Kernel Mode stack of the child process with the values contained
	    	  in the CPU registers when the clone() system call was issued.(these values have been saved in the Kernel
		      Mode stack of parent)
		      However,the function forces the value 0 into the field corresponding to the eax register(child process
		      fork() return or clone() system-call).
		      @thread.esp = the base address of the child's Kernel Mode stack
		      @thread.eip = address of ret_from_fork()  /*  an assembly function  */
		      if parent makes use of an I/O Permission Bitmap,the child gets a copy of such bitmap.
		      if @clone_flags & CLONE_SETTLS => child gets the TLS segment specified by the User Mode data structure
		      pointed to by the @tls parameter of the clone() system-call.

	      14> if @clone_flags & CLONE_CHILD_SETTID => @tsk->set_child_tid = @child_tidptr
	          if @clone_flags & CLONE_CHLID_CLEARTID => @tsk->clear_child_tid = @child_tidptr
		      these flags specify that the value of the variable pointed to by @child_tidptr in the User Mode address
		      space of the child has to be changed,although the actual write operations will be done later.

          15> turns off the TIF_SYSCALL_TRACE flag in the thread_info structure of the child.(ret_from_fork() will not
	    	  notify the debugging process about the system-call termination)
		      (system-call tracing is controled by PTRACE_SYSCALL flag in @tsk->ptrace)

	      16> @tsk->exit_signal = (@clone_flags & CLONE_THREAD) ? -1 : (@clone_flags & CSIGNAL)
	    	  only the death of the last member of a thread group(usually,the thread group leader) causes a signal
		      notifying the parent of the thread group leader.

	      17> invokes sched_fork() to complete the initialization of the scheduler data structure of the new process.
	    	  the function also sets the state of the new process to TASK_RUNNING and sets the preempt_count field
		      of the thread_info structure to 1,thus disabling kernel preemption.
		      Moreover,in order to keep process scheduling fair,the function shares the remaining timeslice of the 
		      parent between the parent and the child.

	      18> sets the field in the thread_info structure of @tsk to the number of the local CPU returned by
	    	  smp_processor_id().

	      19> initializes the fields that specify the parenthood relationships.
	    	  if @clone_flags & (CLONE_PARENT | CLONE_THREAD) =>
	            @tsk->real_parent = @tsk->parent = @current->real_parent
		      else
		        @tsk->real_parent = @tsk->parent = @current
		      /*  ! I DID NOT FIND OUT THE CODE SETS @TSK->PARENT = @CURRENT->REAL_PAREN,
		       *    DUP_TASK_STRUCT() DID @TSK = @CURRENT.
		       */

	      20> if the child does not need to be traced(@clone_flags & ~CLONE_PTRACE),it sets the @tsk->ptrace to 0.

	      21> executes the SET_LINKS macro to insert the new process descriptor in the process list.

	      22> if the child must be traced(PT_PTRACED),it sets @tsk->parent to @current->parent and inserts the child
	    	  into the trace list of the debugger.
		      this work is accomplished by tracehook_finish_clone().

	      23> invokes attach_pid() to insert the PID of the new process descriptor in the @tsk->pids[PIDTYPE_PID] hash table.

	      24> if the child is a thread group leader(@clone_flags & ~CLONE_THREAD) :
	            <  @tsk->tgid = @tsk->pid
		        <  @tsk->group_leader = @tsk
		        <  invokes three times attach_pid() to insert the child in the PID hash tables of type
		           PIDTYPE_TGID,PIDTYPE_PGID,PIDTYPE_SID.
		           /*  !  I DID NOT FIND OUT CODE THAT ATTACHED PIDTYPE_TGID IN COPY_PROCESS(),BECAUSE LINUX 2.6
		            *     NO SUCH PIDTYPE HAD BEEN DEFINED.
		            */

          25> otherwise,if the child belongs to the thread group of its parent(@clone_flags & CLONE_THREAD) :
	    	    <  @tsk->tgid = @current->tgid
		        <  @tsk->group_leader = @current->group_leader
		        <  invokes attach_pid() to insert the child in the PIDTYPE_TGID hash table
		           (more specifically,in the per-PID list of the @current->group_leader process)

	      26> a new process has now been added to the set of processes : ++nr_threads

	      27> ++total_forks to keep trace of the number of forked processes.

	      28> terminated by returning the child's process descriptor pointer(@tsk).
	

    Kernel Threads :
      What is the Kernel Thread :
	    the system process running only in Kernel Mode and deal with some critical tasks such flash cache,swap pages,serving
	    network connections,modern operating systems delegate their functions to Kernel threads.
	    such Kernel Thread are not encumbered with the unnecessary User Mode context.

	  Differ to regular process :
	    >  Kernel threads run only in Kernel Mode,while regular processes run alternatively in Kernel Mode and in User Mode.
	    >  Because kernel threads run only in Kernel Mode,they use only linear addresses greater than PAGE_OFFSET(as above,
	       PAGE_OFFSET is 0xc0000000).
	       Regular processes,on the other hand,use all four gigabytes of linear addresses,in either User Mode or Kernel Mode.

	  Creating a kernel thread :
	    <arch/x86/kernel/process.c>
	      /*  kernel_thread - this is the kernel thread create function depends on architecture.
	       *  @fn:	      	  the function to execute.
	       *  @arg:	      	  the argument of @fn.
	       *  @flags:	      the clone_flags,because this function call to do_fork().
	       *  return -        returns what the do_fork() return.
	       */
	      int kernel_thread(int (*fn)(void *), void *arg, unsigned long flags) EXPORT_SYMBOL(kernel_thread);

	      /*  !  this is the artecture depending function,so when developer developing kernel at the part it is not
	       *	   depend on architecture should use function kthread_create() to instead invocation of kernel_thread().
	       */

	    <linux/kthread.h>
	      /*  kthread_create - kthread helper used to create a kernel thread,the kernel thread will be stopped,
	       *	               use wake_up_process() to start it.
	       *  @threadfn:	   the function to execute.
	       *  @data:		   argument of @threadfn.
	       *  @namefmt:	       const char pointer point to a printf-style string.
	       *  @additional:	   parameters used to resolve @namefmt.
	       *  return -	       task_struct pointer points to the kthread or ERR_PTR(-ENOMEM).
	       */
	      struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...);

	      !  @threadfn can either call do_exit() directly if it is a standalone thread for which noone will call
	         kthread_stop(),or return when 'kthread_should_stop()' is true(means kthread_stop() has been called)
	         its return value should be a zero value or a negative error code,kthread_stop() will returns what
	         @threadfn returned.

	      /*  kthread_run - macro used to create a kernel thread and start it.  */
	      #define kthread_run(threadfn, data, namefmt, ...)

	    kernel_thread() call to do_fork() with (@clone_flags | CLONE_VM | CLONE_UNTRACED),avoids duplicate page tables
	    and ensure no process is able to trace the new kernel thread(even if the calling process is being traced).
	    @regs to do_fork() is the initial value of CPU registers for a new thread(copy_thread() function sets the
	    CPU registers with this initial value for new thread,too)
	    /*  kernel_thread() builds up this stack area so that :
	     *    >  ebx and edx will be set by copy_thread() to the values of the parameters @fn and @arg,respectively.
	     *    >  eip wii be set to the address of the following assembly language fragment :
	     *         movl  %edx,%eax
	     *	       pushl %edx
	     *	       call  %ebx
	     *	       pushl %eax
	     *	       call  do_exit
	     *	       #  Linux 2.6,regs.ip = (unsigned long)kernel_thread_helper,so kernel_thread_helper() will run before
	     *	       	  @fn.
	     */

    Process 0 :
	  ancestor of all process called "process 0",the "idle process",or,for historical reasons,the "swapper process",is a 
	  kernel thread created from scratch during the initialization phase of Linux.
	  the statically allocated data structured used by process 0 :
	    >  a process descriptor stored in the init_task variable,which is initialized by the INIT_TASK macro.
	    >  a thread_info descriptor and a Kernel Mode stack stored in the init_thread_union variable and initialized
	       by the INIT_THREAD_INFO macro.
	    >  the following tables,which the process descriptor points to :
	         init_mm     		  (INIT_MM)   	/*  initialization macro  */
		     init_fs		  (INIT_FS)
		     init_files		  (INIT_FILES)
		     init_signals		  (INIT_SIGNALS)
		     init_sighand		  (INIT_SIGHAND)
	    >  the master kernel Page Global Directory stored in swapper_pg_dir.

	  <linux/start_kernel.h> <init/main.c>
	    /*  start_kernel - architecture indepening kernel starting routine.
	     *  #  on x86_64 platform,this function is called by x86_64_start_kernel_reservations()<arch/x86/kernel/head64.c>.
	     */
	    extern asmlinkage void __init start_kernel(void);

	    start_kernel() initializes all the data structures needed by the kernel,then call to rest_init(),which create 
	    a kernel thread named "kernel_init" via kernel_thread(),@clone_flags = CLONE_FS | CLONE_SIGHAND.
	    "kthreadadd" kernel thread also created by rest_init(),which deal with new kthread add into system,finally,
	    rest_init() enable preempt without resched,next call to schedule() let the process 1 get CPU.
	    if rest_init() get CPU later by scheduler assigned,it just call to cpu_idle() without preempt enabled,
	    cpu_idle() is a function depends on architecture,on x86 platform,it defined in <kernel/process_64.c>.

	    /*  process 0 selected by scheduler only when there are no other processes in the TASK_RUNNING state.
	     *  and for SMP,there is a process 0 for each CPU.
	     */

	    kernel_init() defined in <init/main.c> as a static function,which initializes SMP and SMP Scheduler,does some
	    basic works,then open /dev/console(sys_dup(0) called twice for set up STDOUT and STDERR),finally call to
	    init_post()<init/main.c>.
	    init_post() execute call to run_init_process()<init/main.c> on one of @ramdisk_execute_command,@execute_command,"/sbin/init",
	    "/etc/init","/bin/init","/bin/sh",at least one of these commands must be succeed,otherwise,kernel panic.
	    run_init_process() call to kernel_execve()<arch/x86/kernel/sys_i386_32.c>,which do a system call(execve) from kernel
	    instead of calling sys_execve.

	    !  console maybe open six "tty"s(on my computer,this is default).

    Process 1 :
	  Has descripted above.
	  as a result,the init kernel thread becomes a regular process(kernel_execve() called) having its own per-process
	  kernel data structure.
	  the process started by run_init_process() will stays alive until the system is shut down.

	Other kernel Threads :
	  Linux uses many other kernel threads,some of them are created in the initialization phase and run until shutdown;
	  others are created "on demand",when the kernel must execute a task that is better performed in its own execution
	  context.
	  >
	    keventd(also called events)
	      executes the functions in the @keventd_wq workqueue.
	    
	    kapmd
	      handles the events related to the Advanced Power Management(APM).
	      /*  the newer OS use APIC to manages computer power.  */

	    kswapd
	      reclaims memory.

	    pdflush
	      flushes "dirty" buffers to disk to reclaim memory.
	      
	    kblockd
	      executes the function in the @kblockd_workqueue workqueue,essentially,it periodically activates the block
	      device drivers.

	    ksoftirqd
	      runs the tasklets(bottom of interrupt);there is one of these kernel threads for each CPU in the system.
	      /*  for example,get informations through the shell command :
	       *    ps ax | grep -E '\[.*\]' | grep ksoftirqd
	       */

    Destroying Processes :
      process "die" is the process terminates executing the code suppose it run.
      when this occurs,the kernel must be notified so that it can release the resources owned by the process.
      The usual way for a process to terminate is to invoke the exit() C library function.
      this function can be called explicitly by programmer or be called implicitly by compiler.

      Alternaitively,the kernel may force a whole thread group to die,this typically occurs when a process in the
      group has received a signal that it cannot handle or ignore or when an unrecoverable CPU exception has been
      raised in Kernel Mode while the kernel was running on behalf of the process.

      Process Termination :
        In Linux 2.6 there are two system calls that terminate a User Mode application :
          >  <linux/syscalls.h> /*  Kernel code tree  */
               asmlinkage long sys_exit_group(int error_code);
             <linux/unistd.h>   /*  C Library encapsulate  */
               void exit_group(int status);

             the function terminates a full thread group,that is,a whole multithreaded application.
             the main kernel function that implements this system call is called do_group_exit().
             and this system call should be called by exit().

          >  <linux/syscalls.h>
               asmlinkage long sys_exit(int error_code);
             <linux/unistd.h>
               void _exit(int status);
             <stdlib.h>
               void exit(int status);

             the _exit() system call,while terminates a single process,regardless of any other process in the
             thread group of the victim.
             the main kernel function that implements this system call is called do_exit().
             for example,this system call invoked by the pthread_exit() function of the Linux POSIX Thread Library.

        The do_group_exit() function :
          <linux/sched.h> <kernel/exit.c>
            /*  do_group_exit - terminates all threads belong to the thread group of "current".
             *  @exit_code:     the exit code will pass to do_exit(),its value maybe changed in some case.
             *                  the value is passed by exit_group() system call,or an error code supplied by the kernel.
             *                  (abnormal termination)
             *  #  before call to do_exit(),it will sets SIGNAL_GROUP_EXIT up in signal_struct.flags.(if no this flag had
             *     been setted up before)
             */    
            extern NORET_TYPE do_group_exit(int exit_code);

            The function executes the following operations :
              1>  checks whether the SIGNAL_GROUP_EXI flag of current->signal->flags has been setted up.
                  which means that the kernel already started an exit procedure for this thread group,in this case,
                    exit_code = current->signal->group_exit_code;
                    goto invoke do_exit(exit_code);
              
              2>  if signal_group_sig(current->signal) == F
                    sets SIGNAL_GROUP_EXIT flag
                    current->signal->group_exit_code = exit_code

              3>  invokes the zap_other_threads() function to kill the other processes in the thread group of current,
                  if any.
                  in order to do this,the function scans the per-PID list in the PIDTYPE_TGID hash table corresponding
                  to current->tgid,for each process in the list different from current,it sends a SIGKILL signal to it.
                  as a result,all such processes will eventually execute the do_exit() function.
                  /*  because Linux 2.6 no PIDTYPE_TGID was existed,so this function call to next_thread() to retrive
                   *  the next thread in the thread group.
                   */

              4>  invokes the do_exit() function passing to it the process termination code(@exit_code).
                  do_exit() terminates the process and call to schedule().  /*  no return  */

        The do_exit() function :
          <linux/kernel.h> <kernel/exit.c>
            /*  do_exit - terminates the current task.
             *  @error_code:  the exit code return to User Mode or an error code reported by kernel.
             *  #  do_exit() do not return,and @tsk->exit_code will be setted up with the value @error_code /*  code  */.
             *     (schedule() will be called,so this routine no return,and process switching will be executed by scheduler.)
             */
            NORET_TYPE do_exit(long error_code /*  long code  */) ATTRIB_NORET;

            /*  The C Library function exit() is call to this function via sys_exit() system call  */

            the essential actions are executed as the following :
              1>  sets the PF_EXITING flag in the @flag field of the process descriptor to indicate that the process is being
                  eliminated.
                  if PF_EXITING have being setted up in @flags of current when do_exit() is executing,do_exit() will fix
                  recursive fault and sets up PF_EXITDONE in @flags,then put process state to TASK_UNINTERRUPTIBLE.
                  (in this case,reboot is needed)

              2>  removes,if necessary,the process descriptor from a dynamic timer queue via the del_timer_sync() function.

              3>  detaches from the process descriptor the data structures related to paging,semaphores,filesystem,open file
                  descriptors,namespaces,and I/O Permission Bitmap,respectivly,with the exit_mm(),exit_sem(),exit_files(),
                  exit_fs(),exit_namespace(),and exit_thread() functions.
                  these functions also remove each of these data structures if no other processes are sharing them.

              4>  if the kernel functions implementing the execution domain and the executable format of the process being killed
                  are included in kernel modules,the function decreases their usage counters.
              
              5>  sets the @exit_code of the process descriptor to the process termination code.

              6>  invokes the exit_notify() function to perform the following operations :
                    a>  updates the parenthood relationships of both the parent process and the child processes.
                        all child processes created by the terminating process become children of another process in the
                        same thread group,if any is running,or otherwise of the "init" process.

                    b>  checks whether the @exit_signal process descriptor field of the process being terminated is different
                        from -1,and whether the process is the last member of its thread group.
                        in this case,the function sends a signal(usually SIGCHLD) to the parent of the process being terminated
                        to notify the parent about a child's death.
        
                    c>  otherwise,if the @exit_signal field is equal to -1 or the thread group includes other processes,the
                        function sends a SIGCHLD signal to the parent only if the process is being traced.
                        (informed of the death of the lightweight process)

                    d>  if the @exit_signal process descriptor field is equal to -1 and the process is not being traced,
                        it sets the @exit_state field of the process descriptor to EXIT_DEAD,and invokes release_task()
                        to reclaim the memory of the remaining process data structures and to decrease the usage counter
                        of the process descriptor.
                        the usage counter becomes equal to 1,so that the process descriptor itself is not released right
                        away.

                    e>  otherwise,if the @exit_signal process descriptor field is not equal to -1 or the process is being
                        traced,it sets the @exit_state field to EXIT_ZOMBIE.
                
                    f>  sets the PF_DEAD flag in the @flags field of the process descriptor.

              7>  invokes the schedule() function to select a new process to run.
                  because a process in an EXIT_ZOMBIE state is ignored by the scheduler,the process stops executing right after
                  the switch_to macro in schedule() is invoked.
                  the scheduler will check the PF_DEAD flag and will decrease the usage counter in the descriptor of the
                  zombie process being replaced to denote the fact that the process is no longer alive.
              
    Process Removal :
      The Unix operating system allows a process to query the kernel to obtain the PID of its parent process or the execution
      state of any of its children.
      Unix kernels are not allowed to discard data included in a process descriptor field right after the process terminates.
      They are allowed to do so only after the parent process has issued a wait()-like system call that refers to the 
      terminated process.

      EXIT_ZOMBIE : although the process is technically dead,its descriptor must be saved until the parent process is notified.
      
      If parent dead before children,then system forcing all orphan processes to become children of the init process.
      init process issues wait()-like system call period.

      The release_task() function detaches the last data structures from the descriptor of a zombie process,it is applied on a
      zombie process in two possible ways :
        1>  by the do_exit() function if the parent is not interested in receiving signals from the child(SIGCHLD).
        2>  by the wait4() or waitpid() system calls after a signal has been sent to the parent.

        #   the default action was taken by a process for the signal SIGCHLD is ignores it,but this signal is able to be handled.

        FOR 1> : the memory reclaiming will be done by the scheduler.
        FOR 2> : the memory reclaiming will be progressed immediately.
                 /*  libc wait system call wrapper call to system call wait4(),which is defined in <kernel/exit.c>,
                  *  wait4() call to do_wait() complete the primary recycle routine.

        <linux/sched.h>
          /*  release_task - recycle the resources have holden by @p.
           *  @p:            the task to be released.
           */
          extern void release_task(struct task_struct *p);

          This function executes the following steps :
            1>  decreases the number of processes belonging to the user owner of the terminated process.
                (in user_struct)

            2>  if the process is being traced,the function removes it from the debugger's ptrace_children list and
                assigns the process back to its original parent.

            3>  invokes __exit_signal() to cancel any pending signal and to release the signal_struct descriptor of the 
                process.
                if the descriptor is no longer used by other lightweight processes,the function also removes this data
                structure.
                Moreover,the function invokes exit_itimers() to detach any POSIX interval timer from the process.

            4>  invokes __exit_sighand() to get rid of the signal handlers.

            5>  invokes __unhash_process(),which in turn :
                  a>  decreases by 1 the nr_threads variable.
                  b>  invokes detach_pid() twice to remove the process descriptor from the pidhash hash tables of type
                      PIDTYPE_PID and PIDTYPE_TGID.
                  c>  if the process is a thread group leader,invokes again detach_pid() twice to remove the process
                      descriptor from the PIDTYPE_PGID and PIDTYPE_SID hash tables.
                  d>  use the REMOVE_LINKS macro to unlink the process descriptor from the process list.

                  /*  __unhash_process() is called by __exit_signal(),and timer detaching also have done by it.  */
                  /*  Linux 2.6 have no PIDTYPE_TGID,so __unhash_proces() call to detach_pid() thrice.  */

            6>  if the process is not a thread group leader,the leader is a zombie,and the process is the last member
                of the thread group,the function sends a signal to the parent of the leader to notify it of the death
                of the process.(via do_notify_patent())

            7>  invokes the sched_exit() function to adjust the timeslice of the parent process.
                (similar to copy_process() where sched_fork() was called)

            8>  invokes pus_task_struct() to decrease the process descriptor's usage counter(via call_rcu());
                if the counter becomes zero,the function drops any remaining reference to the process :
                  a>  decreases the usage counter(@__count field) of the user_struct data structure of the user that owns
                      the process,and release that data structure if the usage counter becomes zero.
                  b>  releases the process descriptor and the memory area used to contain the thread_info descriptor and
                      the Kernel Mode stack.
                

/*  END OF CHAPTER3  */
            

Chapter 4 : Interrupts and Exceptions
    An interrupt is usually defined as an event that alters the sequence of instructions executed by a processor,
    such events correspond to electrical signals generated by hardware circuits both inside and outside the CPU chip.

    The type of interrupts :
      Synchronous interrupts : 
        produced by the CPU control unit while executing instructions and are called synchronous because the control
        unit issues them only after terminating the execution of an instruction.(int $0x80)
      
      Asynchronous interrupts :
        generated by other hardware devices at arbitrary times with respect to the CPU clock signals.

    #  Intel microprocessor manuals designate synchronous and asynchronous interrupts as exceptions and interrupts,
       respectively.

    The Role of Interrupt Signals :
      interrupt signals provide a way to divert the processor to code outside the normal flow of control.
      when an interrupt signal arrives,the CPU must stop what it is currently doing and switch to a new activity;
      it does this by saving the current value of the program counter in the Kernel Mode stack and by placing an
      address related to the interrupt type into the program counter.

      difference between interrupt handling and process switching :
        the code executed by an interrupt or by an exception handler is not a process.

      interrupt handling is one of the most sensitive tasks performed by the kernel,because it must satisfy the following
      constraints :
        >  interrupts can come anytime,when the kernel may want to finish something else it was trying to do.the kernel's
           goal is therefore to get the interrupt out of the way as soon as possible and defer as much processing as it can.
           so,an interrupt is divided into a critical urgent part that the kernel executes right away and a deferrable part
           that is left for later.(Linux,interrupt top half part and bottom half part)

        >  an interrupt maybe come when kernel is handling another interrupt.this should be allowed as much as possible,
           because it keeps the I/O devices busy.
           the interrupt handlers must be coded so that the corresponding kernel control paths can be executed in a nested
           manner.when the last kernel control path terminates,the kernel must be able to resume execution of the interrupted
           process or switch to another process if the interrupt signal has caused a rescheduling activity.

        >  although,the kernel may accept a new interrupt signal while handling a previous one,some critical regions exist
           inside the kernel code where interrupts must be disabled,such critical regions must be limited as much as possible,
           because according to the previous requirement,the kernel,and particularly the interrupt handlers,should run most of
           the time with the interrupts enabled.

    Interrupts and Exceptions :
      the Intel documentation classifies interrupts and exceptions as follows :
        Interrupts >
          Maskable interrupts :
            all Interrupt Requests(IRQs) issued by I/O devices give rise to maskable interrupts.
            a maskable interrupt can be in two states :
              masked or unmasked
                a masked interrupt is ignored by the control unit as long as it remains masked

          Nonmaskable interrupts :
            only a few critical events(such hardware failures) give rise to nonmaskable interrupts.
            nonmaskable interrupts are always recognized by the CPU.

        Exceptions >
          Processor-detected exceptions :
            Generated when the CPU detects an anomalous condition while executing an instruction.
            there are further divided into three groups,depending on the value of the eip register
            that is saved on the Kernel Mode stack when the CPU control unit raises the exception.
            
            Faults :
              can generally be corrected;once corrected,the program is allowed to restart with no loss of continuity.
              the saved value of eip is the address of the instruction that caused the fault,and hence that instruction
              can be resumed when the exception handler terminates.

            Traps :
              reported immediately following the execution of the trapping instruction;after the kernel returns control
              to the program,it is allowed to continue its execution with no loss of continuity.
              the saved value of eip is the address of the instruction that should be executed after the one that caused
              the trap.
              a trap is triggered only when there is no need to reexecute the instruction that terminated.the main use of 
              traps is for debugging purpose.the role of the interrupt signal in this case is to notify the debugger that
              a specific instruction has been executed.(such breakpoint feature)

            Aborts :
              a serious error occurred;the control unit is in trouble,and it may be unable to store in the eip register
              the precise location of the instruction causing the exection.
              aborts are used to report severe errors,such as hardware failures and invalid or inconsistent values in
              system tables.
              the interrupt signal sent by the control unit is an emergency signal used to switch control to the corresponding
              abort exception handler.this handler has no choice but to force the affected process to terminate.

        Programmed exceptions >
          occur at the request of the programmer.they are triggered by 'int' or 'int3' instructions;the 'into'(check for overflow)
          and 'bound'(check on address bound) instructions also give rise to a programmed exception when the condition they are
          checking is not true.
          programmed exceptions are handled by the control unit as traps;they are often called "software interrupts",such
          exceptions have two common uses:
            to implement system calls
            to notify a debugger of a specific event.

        #  each interrupt or exception is identified by a number ranging from 0 -- 255,Intel calls this 8-bit unsigned number
           a vector.the vectors of nonmaskable interrupts and exceptions are fixed,while those of maskable interrupts can be
           altered by programming the Interrupt Controller.

    IRQs and Interrupts :
      (PCI,Peripheral Component Interconnect)

      each hardware device controller capable of issuing interrupt requests usually has a single output line designated as
      the Interrupt ReQuest(IRQ) line(more sophisticated devices use several IRQ lines,i.e. PCI card).
      all existing IRQ lines are connected to the input pins of a hardware circuit called the Programmable Interrupt Controller.
      the actions that Programmable Interrupt Controller takes :
        1>  Monitors the IRQ lines,checking for raised signals.If two or more IRQ lines are raised,selects the one having the
            lower pin number.
        2>  If a raised signal occurs on an IRQ line :
              >  Converts the raised signal received into a corresponding vector.(IRQ vector)
              >  Stores the vector in an Interrupt Controller I/O port,thus allowing the CPU to read it via the data bus.
              >  Sends a raised signal to the processor INTR pin--that is,issues an interrupt.
              >  Waits until the CPU acknowledges the interrupt signal by writing into one of the Programmable Interrupt Controllers
                 (PIC) I/O ports;when this occurs,clears the INTR line.
        3>  Goes back to step 1.

      IRQ lines start from 0,therefore,the first IRQ line is usually denoted as IRQ0.
      Intel's default vector associated with IRQn is n+32,but such mapping can be modified by issuing suitable I/O instructions
      to the Interrupt Controller ports!(i.e. IRQ7 <=> vector 81)

      IRQ lines is selectively disabled/enabled via PIC,then that IRQ line will no longer issues interrupts.
      Disable interrupts are not lost;the PIC sends them to the CPU as soon as they are enabled again.

      !  Selectively enabling/disabling of IRQs is not the same as global masking/unmasking of maskable interrupts.
         eflags.IF flag controls that CPU whether ignores the maskable interrupt.

      !  Traditional PICs are implemented by connecting "in cascade" two 8259A-style external chips,each chip can handle up to
         eight different IRQ input lines.because the INT output line of the slave PIC is connected to the IRQ2 pin of the master
         PIC,the number of available IRQ lines is limited to 15.
         e.g.
           A{ IRQ0 ... IRQ7 }-(INT output line)-->{B.IRQ2 B{ IRQ0 IRQ1 IRQ3 ... IRQ7 }}-(INT output line)-->CPU INTR pin

    The Advanced Programmable Interrupt Controller(APIC) :
      INT output line straightforward connect to INTR pin of the CPU is only valid on a single CPU platform.
      Being able to deliver interrupts to each CPU in the system is crucial for fully exploiting the parallelism of the SMP
      architecture.

      I/O Advanced Programmable Interrupt Controller(I/O APIC) introduced from Intel Pentium III.
      80x86 microprocessors include a local APIC which has 32-bit registers,an internal clock,a local timer device,and two
      additional IRQ lines LINT0,LINT1 reserved for APIC interrupts.
      All local APICs are connected to an external I/O APIC,giving rise to a multi-APIC system.
      scheme :
        CPU0.local APIC{local IRQs : LINT0, LINT1}          CPU1.local APIC{local IRQs : LINT0, LINT1}  ...
                |                                                   |
            -------------Interrupt Controller Communication(ICC) bus----------
                                        |
                                    I/O APIC
                                        ^
                                        |
                                    external IRQs(IRQs from hardware)

      The I/O APIC consists of a set of 24 IRQ lines,a 24-entry Interrupt Redirection Table,programmable registers,and a 
      message unit for sending and receiving APIC messages over the APIC bus.
      interrupt priority is not related to pin number(8259A relating to pin number) :
        each entry in the Redirection Table can be individually programmed to indicate the interrupt vector and priority,
        the destination processor,and how the processor is selected.
        the information in the Redirection Table is used to translate each external IRQ signal into a message to one or
        more local APIC units via the APIC bus.

      external IRQs distributing :
        static distribution >
          the IRQ signal is delivered to the local APICs listed in the corresponding Redirection Table entry,the interrupt
          is delivered to one specific CPU,to a subset of CPUs,or to all CPUs at once(broadcast mode).

        dynamic distribution >
          the IRQ signal is delivered to the local APIC of the processor that is executing the process with the lowest
          priority.

          #  every local APIC has a programmable task priority register(TPR),which is used to compute the priority of the
             currently running process.(it is modified when process switch occurred,kernel modifies it)

          if two or more CPUs share the lowest priority,the load is distributed between them using a technique called
          "arbitration" :
            each CPU is assigned a different arbitration priority ranging from 0(lowest) to 15(highest) in the arbitration
            priority register of the local APIC.
            each time an interrupt is delivered to a CPU,its corresponding arbitration priority is automatically set to 0,
            while the arbitration priority of any other CPU is increased.when the arbitration priority register becomes
            greater than 15,it is set to the previous arbitration priority of the winning CPU increased by 1.
                previous_priority := WINNING_CPU.priority
                if ++(this.priority) > 15
                then
                    this.priority := ++previous_priority
          
          !  Pentium 4 local APIC does not have an arbitration priority register,the mechanism is hidden in the bus
             arbitration circuitry.

      the multi-APIC system allows CPUs to generate "interprocessor interrupts" :
        when a CPU wishes to send an interrupt to another CPU,it stores the interrupt vector and the identifier of the
        target's local APIC in the Interrupt Command Register(ICR) of its own local APIC,a message is then sent via the
        APIC bus to the target's local APIC,which therefore issues a corresponding interrupt to its own CPU.

        !  IPIs are actively used by Linux to exchange messages among CPUs.

      multi-APIC for uniprocessor system :
        it include an I/O APIC chip,which may be configured in two distinct ways :
          1>  as a standard 8259A-style external PIC connected to the CPU.
              the local APIC is disabled and the two LINT0 and LINT1 local IRQ lines
              are configured,respectively,as the INTR and NMI pins.
          2>  as a standard external I/O APIC.
              the local APIC is enabled,and all external interrupts are received through the I/O APIC.

    Exceptions :
      80x86 microprocessor introduced 20 different exceptions,kernel must provide a dedicated exception handler for each
      exception type.
      sometimes,a hardware error code is generated by CPU and stored in Kernel Mode stack before start the exception handler.

      About exceptions :
        0  -  Divide error (fault) : integer division by 0
        1  -  Debug (trap or fault) : Raised when the eflags.TF == 1 or when the address of an instruction or operand falls
                                      within the range of an active debug register.
        2  -  Not used : reserved for nonmaskable interrupts(NMI pin).
        3  -  Breakpoint (trap) : caused by an "int3(breakpoint)" instruction.
        4  -  Overflow (trap) : an "into" instruction has been executed while the eflags.OF == 1.
        5  -  Bounds check (fault) : a "bound" instruction is executed with the operand outside of the valid address bounds.
        6  -  Invalid opcode (fault) : CPU execution unit has detected an invalid opcode.
        7  -  Device not avaiable (fault) : an ESCAPE,MMX,or SSE/SSE2 instruction has been executed with the cr0.TS == 1.
        8  -  Double fault (abort) : raised when processor failed to handle exceptions serially.
                                     normally,when the CPU detects an exception while trying to call the handler for a prior
                                     exception,the two exceptions can be handled serially.
        9  -  Coprocessor segment overrun (abort) : problems with the external mathmeatical coprocessor.
        10 -  Invalid TSS (fault) : CPU has attempted a context switch to a process having an invalid Task State Segment.
        11 -  Segment not present (fault) : a reference was made to a segment not present in memory.
        12 -  Stack segment fault (fault) : the instruction attempted to exceed the stack segment limit,or the segment 
                                            identified by "ss" is not present in memory.
        13 -  General protection (fault) : one of the protection rules in the protected mode of the 80x86 has been violated.
        14 -  Page Fault (fault) : the addressed page is not present in memory,the corresponding Page Table entry is null,or
                                   a violation of the paging protection mechanism has occurred.
        15 -  Reserved by Intel
        16 -  Floating-point error (fault) : floating-point unit integrated into the CPU chip has signaled an error condition,
                                             such as numeric overflow or division by 0.
        17 -  Alignment check (fault) : the address of an operand is not correctly aligned.
        18 -  Machine check (abort) : a machine-check mechanism has detected a CPU or bus error.
        19 -  SIMD floating point exception (fault) : the SSE or SSE2 unit integrated in the CPU chip has signaled an error 
                                                      condition on a floating-point operation.

        #  value 20 -- 31 reserved for future development.

      Signals and Exception handlers on Linux :
        0       Divide error                divide_error()                  SIGFPE
        1       Debug                       debug()                         SIGTRAP
        2       NMI                         nmi()                           None
        3       Breakpoint                  int3()                          SIGTRAP
        4       Overflow                    overflow()                      SIGSEGV
        5       Bounds check                bounds()                        SIGSEGV
        6       Invalid opcode              invalid_op()                    SIGILL
        7       Device not available        device_not_available()          None
        8       Double fault                doublefault_fn()                None
        9       Coprocessor segment overrun coprocessor_segment_overrun()   SIGFPE
        10      Invalid TSS                 invalid_TSS()                   SIGSEGV
        11      Segment not present         segment_not_present()           SIGBUS
        12      Stack segment fault         stack_segment()                 SIGBUS
        13      General protection          general_protection()            SIGSEGV
        14      Page Fault                  page_fault()                    SIGSEGV
        15      Intel-reserved              None                            None
        16      Floating-point error        coprocessor_error()             SIGFPE
        17      Alignment check             alignment_check()               SIGBUS
        18      Machine check               machine_check()                 None
        19      SIMD floating point         simd_coprocessor_error()        SIGFPE

        #  Linux exceptions relating code is defined in <arch/x86/include/asm/traps.h>,and implemented in
           <arch/x86/kernel/traps.c>.

    Interrupt Descriptor Table :
      a system table called Interrupt Descriptor Table(IDT) associates each interrupt or exception vector with the address of 
      the corresponding interrupt or exception handler.it must be properly initialized before kernel enables interrupt.
      
      IDT is similar to GDT and LDT,each entry is a 8-byte descriptor,thus,a maximum of 256 * 8 = 2048 bytes are required to
      store IDT.

      idtr register allows the IDT to be located anywhere in memory :
        it specifies both the IDT base linear address and its limit(maximum length).
        this register must be initialized before enabling interrupts by using the "lidt" assembly language instruction.

      Three types of descriptors may included by IDT :
        1>  Task gate
              includes the TSS selector of the process that must replace the current one when an interrupt signal occurs.
              [0, 15] : RESERVED
              [16, 31] : TSS SEGMENT SELECTOR
              [32, 39] : RESERVED
              40 : 1
              41 : 0
              42 : 1
              43 : 0
              44 : 0
              [45, 46] : DPL
              47 : P
              [48, 63] : RESERVED

        2>  Interrupt gate
              includes the segment selector and the offset inside the segment of an interrupt or exception handler.
              while transferring control to the proper segment,the proprocessor clears the eflags.IF flag,thus disabling
              further maskable interrupts.
              [0, 15] : OFFSET (0--15)
              [16, 31] : SEGMENT SELECTOR
              [32, 36] : RESERVED
              37 : 0
              38 : 0
              39 : 0
              40 : 0
              41 : 1
              42 : 1
              43 : 1
              44 : 0
              [45, 46] : DPL
              47 : P
              [48, 63] : OFFSET(16--31)

        3>  Trap gate
              similar to an interrupt gate,except that while transferring control to the proper segment,the processor 
              does not modify the IF flag.
              [0, 15] : OFFSET(0--15)
              [16, 31] : SEGMENT SELECTOR
              [32, 36] : RESERVED
              37 : 0
              38 : 0
              39 : 0
              40 : 1
              41 : 1
              42 : 1
              43 : 1
              44 : 0
              [45, 46] : DPL
              47 : P
              [48, 63] : OFFSET(16--31)

        #  In particular,the value of the Type field encoded in the bits 40-43 identifies the descriptor type.
        #  Linux use interrupt gate to handle interrupts,and use trap gate to handle exceptions.

    Hardware Handling of Interrupts and Exceptions :
      /*  Suppose Kernel has been initialized,and CPU running on protected mode  */

      Before CPU executes the next instruction,it checks if an interrupt or an exception occurred while it executed the
      previous instruction.if it is,then CPU control unit does the following :
        1>  determines the vector i(0 <= i <= 255) associated with the interrupt or the exception.(Send by PIC)
        2>  reads the i_th entry in IDT through idtr.
        3>  gets the base address of the GDT from the gdtr register and looks in the GDT to read the Segment Descriptor
            identified by the selector in the IDT entry.this descriptor specifies the base address of the segment that
            includes the interrupt or exception handler.
        4>  makes sure the interrupt was issued by an authorized source.
            first
              compares the CPL which is stored in the two least significant bits of the cs register with the DPL of the
              Segment Descriptor included in the GDT.
              if cs.CPL < GDT.Segd.DPL
                    Raises a "General protection" exception     /*  interrupt handler cannot have a lower privilege than  */
                                                                /*  the program that caused the interrupt.  */
            second (for programmed exceptions)
              makes a further security check :
                compares the CPL with the DPL of the gate descriptor included in the IDT.
              if cs.CPL > IDT.entry.DPL
                    Raises a "General protection" exception
              
              !  prevent access by user applications to specific trap of interrupt gates.
        5>  checks whether a change of privilege level is taking place -- if CPL is different from the selected
            Segment Descriptor's DPL.(selected Segd,but cs.CPL has changed)
            if cs.CPL != GDT.Segd.DPL
              start using the stack that is associated with the new privilege level
              {
                a>  reads the tr register to access the TSS segment of the running process.
                b>  loads the ss and esp registers with the proper values for the stack segment and stack pointer
                    associated with the new privilege level.these values are found in the TSS.
                c>  in the new stack,it saves the privous values of ss and esp,which define the logical address of the
                    stack associated with the old privilege level.
              }
        6>  if a fault has occurred,it loads cs and eip with the logical address of the instruction that caused the 
            exception so that is can be executed agian.
        7>  saves the contents of eflags,cs,and eip in the stack.
        8>  if the exception carries a hardware error code,it saves it on the stack.
        9>  loads cs and eip,respectively,with the Segment Selector and the Offset fields of the Gate Descriptor stroed
            in the i_th entry of the IDT.these values define the logical address of the first instruction of the 
            interrupt or exception handler.

      After the interrupt or exception is processed,the corresponding handler must relinquish control to the interrupted
      process by using the "iret" instruction.
      "iret" forces the CPU control unit to does :
        1>  load the cs,eip,and eflags registers with the values saved on the stack.
            if a hardware error code has been pushed in the stack on top of the eip contents,it must be popped
            before executing iret.
        2>  check whether the CPL(cs.CPL) of the handler is equal to the value contained in the two least significant bits of
            cs(the content of cs is saved on the stack).
            if cs.CPL == stack.cs.CPL
              the interrupted process was running at the same privilege level as the handler,
              "iret" concludes execution.
            else
              load the ss and esp registers from the stack and return to the stack associated with the old privilege level.
              examine the contents of the ds,es,fs,and gs segment registers :
                if any of them contains a selector that refers to a Segment Descriptor whose DPL values is lower than CPL,
                clear the corresponding segment register.
                /*  The CPU control unit does this to forbid User Mode programs that run with a CPL equal to 3 from using
                 *  segment registers previously used by Kernel routines(with a DPL equal to 0).
                 */

    Nested Execution of Exception and Interrupt Handlers :
      Kernel control paths may be arbitrarily nested;an interrupt handler may be interrupted by another interrupt handler.
      the last instructions of a kernel control path that is taking care of an interrupt do not always put the current
      process back into User Mode :
        if the level of nesting is greater than 1,these instructions will put into execution the kernel control path that
        was interrupted last,and the CPU will continue to run in Kernel Mode.

      For kernel control path is able to nested,an interrupt handler must never block !
      all the data needed to resume a nested kernel control path is stored in the Kernel Mode stack,which is tightly bound
      to the current process.(interrupt handler shares stack to interrupted process)

      An interrupt handler may preempt both other interrupt handlers and exception handlers,Conversely,an exception handler
      never preempts an interrupt handler !

      !  THE ONLY EXCEPTION THAT CAN BE TRIGGEED IN KERNEL MODE IS "Page Fault".
      !  Interrupt handlers never perform operations that can induce page faults,and thus,potentially,a process switch.
      !  In contrast to exceptions,interrupts issued by I/O devices do not refer to data structures specific to the 
         current process.

      Linux interleaves kernel control paths for two major reasons :
        1>  to improve the throughput of programmable interrupt controllers and device controllers.
            /*  device controller issues a signal on an IRQ line,
             *  PIC transforms it into an external interrupt,
             *  both PIC and device controller wait for CPU send an acknowledgment.
             *  interleaves kernel control paths can let kernel send the acknowledgment while it is 
             *  handling the previous interrupt.
             */
        2>  to implement an interrupt model without priority levels.
            /*  no longer some predefined levels between interrupts are necessary.  */

      !  On multiprocessor systems,several kernel control paths may execute concurrently,moreover,a kernel control
         path associated with an exception may start executing on a CPU and, due to a process switch,migrate to
         another CPU.

    Initializing the Interrupt Descriptor Table :
      before kernel enables interrupts,it must load the initial address of IDT into idtr register and initializes all
      entries of IDT.
      "int" instruction allows a User Mode process to issue an interrupt signal that has an arbitrary vector ranging
      from 0 to 255,kernel must prevent illegal interrupts and exceptions simulated by User Mode process via "int".
      /*  set DPL of gate descriptor up to 0,cs.CPL == 3 for User Mode process.  */

      !  in a few cases,a User Mode process must be able to issue a programmed exception,for this,must set the
         corresponding gate descriptor's DPL to 3.(that is as high as possible)

      Interrupt,Trap,and System Gates :
        Linux uses a slightly different breakdown and terminology from Intel when classifying the interrupt
        descriptors included in the Interrupt Descriptor Table :
          >  Interrupt gate
               an Intel interrupt gate that cannot be accessed by a User Mode process.(DPL = 0)
               all Linux interrupt handlers are activated by means of Interrupt gates,and all are
               restricted to Kernel Mode.

          >  System gate
               an Intel trap gate that can be accessed by a User Mode process.(DPL = 3)
               the three Linux exception handlers associated with the vectors 4,5,128 are activated by means of
               System gates,so the three assembly language instructions "into","bound",and "int $0x80" can be
               issued in User Mode.

          >  System interrupt gate
               an Intel interrupt gate that can be accessed by a User Mode process.(DPL = 3)
               the exception handler associated with the vector 3 is activated by means of a System interrupt gate,
               so the assembly language instruction "int3" can be issued in User Mode.

          >  Trap gate
               an Intel trap gate that cannot be accessed by a User Mode process.(DPL = 0)
               most Linux exception handlers are activated by means of Trap gates.

          >  Task gate
               an Intel task gate that cannot be accessed by a User Mode process.(DPL = 0)
               the Linux handler for the "Double fault" exception is activated by means of a Task gate.

      Architecture-dependent functions(just a little) were used to manipulate IDT :
        the gate entity is defined in <arch/x86/include/asm/desc_defs.h> !
        <arch/x86/include/asm/desc.h>
          /*  set_intr_gate - insert an Interrupt gate entry into IDT.
           *  @n:             index of IDT.
           *  @addr:          address of interrupt handler.
           */
          static inline void set_intr_gate(unsigned int n, void *addr);

          /*  set_system_trap_gate - insert a System trap gate entry into IDT.
           *  @n:                    index of IDT.
           *  @addr:                 trap handler address.
           */
          static inline void set_system_trap_gate(unsigned int n, void *addr);

          /*  set_system_intr_gate - insert a System interrupt gate entry into IDT.
          static inline void set_system_intr_gate(unsigned int n, void *addr);

          /*  set_trap_gate - insert a Trap gate entry into IDT.
          static inline void set_trap_gate(unsigned int n, void *addr);

          /*  set_task_gate - insert a Task gate entry into IDT.
           *  @n:             index of IDT.
           *  @gdt_entry:     the index of TSS which is contained in GDT and the function
           *                  to be activated is inside this TSS.
           *                  TSSD can appear only in GDT,when this gate is called,use the
           *                  index to pick the corresponding TSSD from GDT,and access to the TSS.
           *                  the Segment Selector inside Task gate stores the index value.
           *  #  I FOUND OUT Linux 2.6 ONLY USE TASK GATE TO DEAL WITH "Double fault" EXCEPTION,
           *     AND "GDT_ENTRY_DOUBLEFAULT_TSS" IS DEFINED WITH VALUE 31.
           *     OBJECT "doublefault_tss" IS DEFINED IN <arch/x86/kernel/doublefault_32.c>,IP
           *     REGISTER IS POINT TO "doublefault_fn"(DEFINED IN SAME FILE).
           *     THE GATE IS PLACED IN IDT WITH INDEX 8,AND THE SEGMENT DESCRIPTOR IS PLACED IN THE
           *     32nd ENTRY IN GDT.
           */
          static inline void set_task_gate(unsigned int n, unsigned int gdt_entry);

        #  all gate can be accessed only in Kernel Mode is attached __KERNEL_CS as the 
           Segment Selector.

      Preliminary Initialization of the IDT :
        IDT is initialized and used by the BIOS routines while the computer still operates in Real Mode.
        However,the IDT is moved to another area of RAM and initialized a second time after Linux take over
        control.(because Linux does not use any BIOS routine)

        IDT is stored in the @idt_table table,which includes 256 entries,the 6-byte @idt_descr variable stores
        both the size of the IDT and its address and is used in the system initialization phase when the kernel
        sets up the idtr register with the lidt assembly language instruction.

        assembly language function setup_idt() is used to initializes @idt_table,the 256 entries are filled with
        ignore_int and the corresponding interrupt gate.
        which function is defined in <arch/x86/kernel/head_32.S> :
          setup_idt:
                lea ignore_int,%edx                 #  load address of ignore_int into edx
                movl $(__KERNEL_CS << 16),%eax      #  kernel code segment
                movw %dx,%ax                        #  move the content in dx to ax
                movw $0x8E00,%dx                    #  interrupt gate - dpl = 0,present

                lea idt_table,%edi                  #  load address of idt_table into edi
                mov $256,%ecx                       #  set up counter

          rp_sidt:                                  #  repeat setup idt
                movl %eax,(%edi)                    #  the 4-byte content from 0--31
                movl %edx,4(%edi)                   #  the 4-byte content from 32--63
                addl $8,%edi                        #  iterating
                dec %ecx
                jne rp_sidt

          ...

          ignore_int:
                cld
                iret 

        ignore_int() :
          a null handler.
          #ifdef  CONFIG_PRINTK
            ignore_int saves the content of some registers in the stack ->
            invokes printk() to print an "Unknown interrupt" system message ->
            restores the register contents from the stack ->
            executes an "iret" instruction to restart the interrupted program.

          !  the ignore_int() handler should never be executed.if it is executed,that denotes either a 
             hardware problem(such an I/O devices is issuing unforeseen interrupts) or a kernel problem
             (such an interrupt or exception is not being handled properly).

        kernel replaces some of the null handlers with meaningful trap and interrupt handlers at the second
        phase to set up IDT.

        !  once this is done,the IDT includes a specialized interrupt,trap,or system gate for each different
           exception issued by the control unit and for each IRQ recognized by the interrupt controller.

    Exception Handling :
      most exceptions issued by the CPU are interpreted by Linux as error conditions.
      for example,CPU raises a "Divide error" exception,and the corresponding exception handler sends
      a SIGFPE signal to the process caused this exception,then it takes the necessary steps to recover or abort.

      Linux exploits CPU exceptions to manage hardware resources more efficiently :
        >  Linux use "Device not available" exception and cr0.TS flag give rise to load the floating point registers
           of the CPU with new values.
        >  Linux use "Page Fault" exception to defer allocating new page frames to the process until the last
           possible moment.(that is,schduler will take a place in the case)
           !  "Page Fault" exception handler is very complex,because this exception may or may not denote an
              error condition.

      Standard structure of steps that exception handler takes :
        1>  save the contents of most registers in the Kernel Mode stack(coded in assembly language)
        2>  handle the exception by means of a high-level C function.
        3>  exit from the handler by means of the ret_from_exception() function.

      trap_init() :
        Linux use this function to setup IDT entries that refer to nonmaskable interrupts and exceptions.

        <arch/x86/kernel/traps.c>
          /*  trap_init -  the x86 architecture specific trap initialization routine.
           *  #  this function is call to set_trap_gate(),set_intr_gate(),set_system_gate(),
           *     set_system_intr_gate(),set_task_gate() .etc to accomplishes trap initialization.
           *     finally,call to x86_init_irqs.trap_init() to finishes the architecture dependent
           *     trap initializing works.
           */
          void __init trap_init(void);

          !  "Double fault" exception handler is set up by cpu_init() function and which is called by trap_init().
             the "Double fault" exception is handled by means of a task gate instead of a trap or system gate,
             because it denotes a serious kernel misbehavior.thus,the exception handler that tries to print out the
             register values does not trust the current value of the esp register.
             when this exception occurred,CPU executes the doublefault_fn() exception handler on its own private stack
             (specified by TSS)

      Saving the Registers for the Exception Handler : 
        each exception handler starts with the following assembly language instructions : (defined in <arch/x86/kernel/entry_32.S>)
          @handler_name:
                pushl $0                    #  pad stack with null value,if control unit is not insert a hardware error code
                                            #  on the stack automatically when the exception occurs.
                pushl $do_handler_name      #  address of high-level C function
                jmp error_code              #  the assembly code of "error_code" label will call to the function "do_##name()".
        
        the assembly language fragment labeled as "error_code" is the same for all exception handlers except the one for 
        the "Device not available" exception.(Linux 2.6,it is same as others)
        the code performs the following steps : (these are the default actions in Linux 2.6 for all exception handlers)
          1>  saves the registers that might be used by the high-level C function on the stack.
          2>  execute "cld".
          3>  copied the hardware error code saved in the stack at location esp+36 in edx.
              stores the value -1 in the same stack location,this value is used to separate 0x80 exceptions
              from other exceptions.
          4>  loads edi with the address of the high-level "do_##name()" C function saved in the stack at the
              location esp+32,writes the contents of es in that stack location.
          5>  loads in the eax register the current top location of the Kernel Mode stack.
              this address identifies the memory cell containing the last register value saved in step1.
          6>  loads the user data Segment Selector into the ds and es registers.
          7>  invokes the high-level C function whose address is now stored in edi.

        #  the invoked function receives its arguments from the eax and edx registers rather than from the stack.
        #  all "do_##name()" high-level handlers are call to do_trap() function,which is defined in 
           <arch/x86/kernel/traps.c>

      Entering and Leaving the Exception Handler :
        Kernel enters an exception handler through IDT,and then the correpsonding assembly function
        is going to invoke "do_##name()" the high-level C function,it finally call to do_trap() function.

        do_trap() :
          <arch/x86/kernel/traps.c>
            /*  do_trap - generic exception handling interface.
             *  @trapnr:  number of excpetion.
             *  @signr:   the signal must send to the process which cause the exception.
             *  @str:     information.
             *  @regs:    registers contents.
             *  @error_code:  error code.
             *  @info:    signal information.
             *  #  @regs is passed by the exception handler which is in assembly language.
             *  #  DO_ERROR() and DO_ERROR_INFO() macros are used to define "do_##name()" the
             *     high-level C functions.
             */
            static void __kprobes do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
                                          long error_code, siginfo_t *info);
  
          do_trap() will does :
            1>  retrive current process's task_struct object.
            2>  @tsk->thread.error_code = @error_code;
                @tsk->thread.trap_no = @trapnr;
                if !@info
                      force_sig(@signr, @tsk);
                else
                      force_sig_info(@signr, @info, @tsk);
                the signal will be handled either in User Mode by the process's own signal handler or
                in Kernel Mode(default action).
            3>  it is always checks whether the exception occurred in User Mode or in Kernel Mode.
                in the Kernel Mode,have to checks whether it was due to an invalid argument passed to
                a system call.(different system call deal with invalid argument is difference)
                any other exception raised in Kernel Mode is due to a kernel bug,this denote kernel
                is misbehaving,then call to die() function to prevent data corruption and prints the 
                contents of all CPU registers on the console(this dump is called kernel oops),
                the current process have to be terminated by calling do_exit().
  
          #  when the C function that implements the exception handling terminates,the code performs a
             "jmp" instruction to the ret_from_exception() function.(return to the interrupted control path)
               
    Interrupt Handling :
      Interrupt handling is different to Exception Handling,so it would make no sense to send a Unix signal to the 
      current process.

      Interrupt handling depends on the type of interrupt :
        I/O interrupts :
          An I/O device requires attenton;the corresponding interrupt handler must query the device to determine the
          proper course of action.

        Timer interrupts :
          some timer,either a local APIC timer or an external timer,has issued an interrupt;this kind of interrupt
          tells the kernel that a fixed-time interval has elapsed.

        Interprocessor interrupts :
          A CPU issued an interrupt to another CPU of a multiprocessor system.

      I/O Interrupt Handling :
        in general,an I/O interrupt handler must be flexible enough to service several devices at the same time.
        some devices might share a vector and a IRQ line.(vector 43 for USB port and Sound Card)

        Interrupt handler flexibility is achieved in two distinct ways :
          1>  IRQ sharing
                the interrupt handler executes several interrupt service routines(ISRs).
                each ISR is a function related to a single device sharing the IRQ line.
                it is not possible to know in advance which particular device issued the IRQ,each ISR is
                executed to verify whether its device needs attention;if so,the ISR performs all the operations
                that need to be executed when the device raises an interrupt.

          2>  IRQ dynamica allocation
                An IRQ line is associated with a device driver at the last possible moment.
                that is IRQ line is allocated on demand(the time need to access the device).
                in this way,the same IRQ vector may be used by several hardware devices even if they cannot
                share the IRQ line;of course,the hardware devices cannot be used at the same time.

        not all actions to be performed when an interrupt occurs have the same urgency.
        when an interrupt is handling,the signals on the corresponding IRQ line are temporarily ignored,
        the interrupted process stay in the TASK_RUNNING state,a system freeze is possible to occur.

        Long noncritical operations should be deferred,blocking procedure must to be prevented.

        Actions for interrupt on Linux:
          1>  Critical
                actions such as acknowledging an interrupt to the PIC,reprogramming the PIC or the device controller,
                or updating data structures accessed by both the device and the processor.
                such actions must be performed as soon as possible(these can be executed quickly and are critical).
                critical actions are executed within the interrupt handler immediately,with maskable interrupts disabled.

          2>  Noncritical
                actions such as updating data structures that are accessed only by the processor.
                these actions can also finish quickly,so they are executed by the interrupt handler immediately,with
                the interrupts enabled.

          3>  Noncritical deferrable
                actions such as copying a buffer's contents into the address space of a process.
                these may be delayed for a long time interval without affecting the kernel operations;
                the interested process will just keep waiting for the data.

        Four basic actions all I/O interrupt handlers do :
          1>  save the IRQ value and the register's contents on the Kernel Mode stack.
          2>  send an acknowledgment to the PIC that is servicing the IRQ line,thus allowing it to issue
              further interrupts.
          3>  execute the interrupt service routines(ISRs) associated with all the devices that share the IRQ.
          4>  terminate by jumping to the ret_from_intr() address. 

      Interrupt vectors :
        physical IRQs may be assigned any vector in the range 32-238.however,Linux uses vector 128 to implement
        system calls.

        #  IBM-compatible PC architecture requires that some devices be statically connected to specific IRQ lines.
           in particular :
             interval timer device --> IRQ 0 line
             slave 8259A PIC --> IRQ 2 line
             external mathematical coprocessor --> IRQ 13 line
             an I/O device can be connected to a limited number of IRQ lines.

        interrupt vectors in Linux :
          vector range                      use
          [0, 19](0x0 - 0x13)               nonmaskable interrupts and exceptions
          [20, 31](0x14 - 0x1f)             intel-reserved
          [32, 127](0x20 - 0x7f)            external interrupts (IRQs)
          [128](0x80)                       programmed exception for system calls
          [129, 238](0x81 - 0xee)           external interrupts (IRQs)
          [239](0Xef)                       local APIC timer interrupt
          [240](0xf0)                       local APIC thermal interrupt
          [241, 250](0xf1 - 0xfa)           reserved by Linux for future use
          [251, 253](0xfb - 0xfd)           interprocessor interrupts
          [254](0xfe)                       local APIC error interrupt
          [255](0xff)                       local APIC spurious interrupt

        three ways to select a line for an IRQ-configurable device :
          1>  by setting hardware jumpers
          2>  by a utility program shipped with the device and executed when installing it.
              such a program may either ask the user to select an available IRQ number or probe the
              system to determine an available number by itself.
          3>  by a hardware protocol executed at system startup.
              peripheral devices declare which interrupt lines they are ready to use;the final values
              are then negotiated to reduce conflicts as much as possible.
              once this is done,each interrupt handler can read the assigned IRQ by using a function
              that accesses some I/O ports of the device.

        !  kernel must discover which I/O device corresponding to the IRQ number before enabling interrupts.

      IRQ data structures :
        <linux/irq.h>
          typedef (*irq_flow_handler_t)(unsigned int irq, struct irq_desc *desc);

          /*  struct irq_desc - the irq descriptor structure represents an interrupt.
           *  @irq:             interrupt number for this descriptor.
           *  @handler_irq:     high-level irq-events handler [if NULL, __do_IRQ()].
           *  @action:          the irq action chain.
           *  @status:          status information.
           */
          struct irq_desc {
                unsigned int irq;
                ...
                irq_flow_handler_t handler_irq;
                ...
                struct irqaction *action;
                unsigned int status;
                ...                
          };
        <kernel/irq/handle.c>
          /*  irq_desc - the irq_desc structure array used to establishes relationship
           *             between IRQ vector and IRQ descriptor.
           *  @NR_IRQS:  number of IRQs in the system,architecture dependent,
           *             if undefined,then it is defined with 64.
           *  #  the @handler_irq field for per-irq_desc is setup to "handle_bad_irq",
           *     and @status field is setup to "IRQ_DISABLED".
           */
          struct irq_desc irq_desc[NR_IRQS];

          /*  Linux 2.6 NO "irq_desc_t" DEFINITION.  */

        An interrupt is "unexpected" if it is not handled by the kernel,that is,either if there is
        no ISR associated with the IRQ line,or if no ISR associated with the line recognizes the interrupt
        as raised by its own hardware device.
        in this case,kernel checks the IRQ line number which raised "unexpected" interrupt and disable the line.
        (prevent a faulty hardware device keeps raising an interrupt)
        /*  because the IRQ line can be shared among several devices,the kernel does not disable the line as soon as
         *  it detects a single unhandled interrupt,rather,the kernel stores in the @irq_count and @irqs_unhandled fields
         *  of the "irq_desc" structure the total number of interrupts and the number of unexpected interrupts,respectively.
         *  #  kernel checks these fields,if the value exceed the threshold,kernel disable the IRQ line.
         */

        sample figure :
          (dev1)   (dev2)
          IRQ0     IRQ0 IRQ1  (external devices' IRQ lines,physical circuit)
          |        |    |
          |        ======
          |        |
          V        V
          PIC      PIC        (hardware Programmable Interrupt Controller)
          |        |          (INT output line)
          ===I/O APIC==== 
               |
               V
          ====ICC=======
          |        |
          CPU1     CPU2
          |        
          ==========
          |        |   
          |        |   
          V        V
          37       82    (dev1.IRQ0 <=> vector 82, dev2.IRQ0 <=> vector 82, dev2.IRQ1 <=> vector 37)
          |        |
          irqd_37   irqd_82
          |           |
          ISR9     =======      (ISR9 handles vector = 37 from dev2)
                   |     |
                  ISR4   IRS7   (ISR4 handles vector = 82 from dev1, ISR7 handles vector = 82 from dev2)

          #  the mapping between IRQ line number and the vector is able to be altered via issue an
             I/O instruction to PIC.
          #  the vector assignable in the scope [32, 238] is because some nonmaskable interrupts and exceptions
             have the fixed vector.
        
        Status of an IRQ line :
          IRQ_INPROGRESS                a handler for the IRQ is being executed
          IRQ_DISABLED                  the IRQ line has been deliberately disbled by a device driver
          IRQ_PENDING                   an IRQ has occurred on the line,its occurrence has been acknowledged to the PIC,
                                        but it has not yet been serviced by the kernel
          IRQ_REPLAY                    the IRQ line has been disabled but the previous IRQ occurrence has not yet been
                                        acknowledged to the PIC
          IRQ_AUTODETECT                the kernel is using the IRQ line while performing a hardware device probe
          IRQ_WAITING                   the kernel is using the IRQ line while performing a hardware device probe,
                                        moreover,the corresponding interrupt has not been raised
          IRQ_LEVEL                     not used on the 80x86 architecture(IRQ level triggered)
          IRQ_MASKED                    not used(IRQ masked - should not be seen again)
          IRQ_PER_CPU                   not used on the 80x86 architectur(IRQ is per-cpu)
                                        /*  if an interrupt request is per CPU type,then disable it is only
                                         *  disabled on local cpu,another were not affected.
                                         */

          @depth field and IRQ_DISABLED specify whether the IRQ line is enabled or disabled.
          <linux/interrupt.h>
            /*  disable_irq - disable IRQ line,wait until all interrupt handlers for IRQ_irq
             *                have completed before running.
             *  @irq:         the IRQ line number.
             */
            extern void disable_irq(unsigned int irq);

            /*  disable_irq_nosync - asynchronous version.  */
            extern void disable_irq_nosync(unsigned int irq);

            #  these two functions are let @depth increase,if @depth == 0,the functions disable theIRQ line
               and set its IRQ_DISABLED flag(this is give rise before @depth increase). 

            /*  enable_irq - enable a IRQ line.
             *  #  this function decrease @depth,if @depth == 0,then enable the IRQ line and clean IRQ_DISABLED flag.
             */
            extern void enable_irq(unsigned int irq);

          @status of each element in irq_desc array is initialized to IRQ_DISABLED during system initializing,this is
          happens in "init_IRQ()" it is defined in <arch/x86/kernel/irqinit.c>(this function also initializes IDT).

        Linux supports several PIC,so kernel designer have used object-oriented approach to encapsulate PIC object.
        In older kernel,it is named "hw_interrupt_type",but in Linux 2.6,it is named "irq_chip".
        <linux/irq.h>
          /*  struct irq_chip - hardware interrup chip descriptor.
           *  @name:            name for /proc/interrupts .
           *  @startup:         start up the interrupt.
           *  @shutdown:        shut down the interrupt.
           *  @enable:          enable the interrupt.
           *  @disable:         disable the interrupt.
           *  @ack:             start of a new interrupt.
           *  ...
           *  @typename:        obsoleted by name,kept as migration helper. 
           */
          struct irq_chip {
                const char *name;
                unsigned int (*startup)(unsigned int irq);
                void (*shutdown)(unsigned int irq);
                void (*enable)(unsigned int irq);
                void (*disable)(unsigned int irq);
                void (*ack)(unsigned int irq);
                ...
                const char *typename;
          };  /*  each irq_desc.chip is points to a irq_chip object.  */
          /*  if @startup is nullptr,then @startup = @enable,
           *  if @shutdown is nullptr,then @shutdown = @disable
           */

        Multiple devices can share a single IRQ,so kernel maintains "irqaction" structure for a
        specific hardware device and a specific interrupt.
        <linux/interrupt.h>
          typedef irqreturn_t (*irq_handler_t)(int, void *);

          /*  struct irqaction - per interrupt action descriptor.
           *  @handler:          interrupt handler function.
           *  @flags:            flags(IRQF_*).
           *  @name:             name of the device.
           *  @dev_id:           cookie to identify the device.
           *  @next:             next irqaction for shared interrupts.
           *  @irq:              interrupt number.
           *  @dir:              pointer to the /proc/irq/NN/name entry.
           *  @thread_fn:        interrupt handler function for threaded interrupts.
           *  @thread:           thread pointer for threaded interrupts.
           *  @thread_flags:     flags related to @thread.
           *  #  Linux use this descriptor to represents an ISR.
           *     the devices sharing the single IRQ line,every interrupt handler
           *     for the device is encapsulated in an "irqaction" object.
           */
          struct irqaction {
                irq_handler_t handler;
                unsigned long flags;
                const char *name;
                void *dev_id;
                struct irqaction *next;
                int irq;
                struct proc_dir_entry *dir;
                irq_handler_t thread_fn;
                struct task_struct *thread;
                unsigned long thread_flags;
          };

          some values for irqaction.flags :
            IRQF_DISABLED           keep irqs disabled when calling the action handler
            IRQF_SHARED             allow sharing the irq among several devices
            IRQF_SAMPLE_RANDOM      irq is used to feed the random generator

        Kernel use a structure named "irq_cpustat_t" to keep track of what each CPU is currently doing,
        and an array named "irq_stat" save "irq_cpustat_t" structure object the size is consistent to NR_CPUS.
        <arch/x86/include/asm/hardirq.h>
          /*  struct irq_cpustat_t - structure used by kernel to keep track of CPU in the system.
           *  @__softirq_pending:    whether there is a softirq is pending.
           *  @__nmi_count:          number of occurrences of NMI interrupts.
           *  @irq0_irqs:            nmi watchdog.
           *  @apci_timer_irqs:      number of occurrences of local APIC timer interrupts.
           *  ...
           */
          typedef struct {
                unsigned int __softirq_pending;  /*  per-CPU 32-bit mask describing the pending softirqs  */
                unsigned int __nmi_count;
                unsigned int irq0_irqs;
                unsigned int apic_timer_irqs;  /*  #ifdef CONFIG_X86_LOCAL_APIC  */
                ...
          } ____cacheline_aligned irq_cpustat_t;

        <kernel/softirq.c>  <linux/irq_cpustat.h>
        #ifndef __ARCH_IRQ_STAT
          /*  irq_stat - irq_cpustat_t array for per-cpu.  */
          irq_cpustat_t irq_stat[NR_CPUS] ____cacheline_aligned;
          EXPORT_SYMBOL(irq_stat);
        #endif

      IRQ distribution in multiprocessor systems :
        when a hardware device raises an IRQ signal,the multi-APIC system selects one of the CPUs
        and delivers the signal to the corresponding local APIC,which in turn interrupts its CPU,no other
        CPUs are notified of the event.

        during system bootstrap,the booting CPU executes the "static void __init setup_IO_APIC_irqs(void)"
        which is defined in <arch/x86/kernel/apic/io_apic.c>,this function initializes the I/O APIC chip,
        the Interrupt Redirection Table of the chip is filled(24-entry).
        
        during system bootstrap,after I/O APIC chip had initialized,all CPUs execute the
        "void __cpu_init setup_local_APIC(void)" which is defined in <arch/x86/kernel/apic/apic.c>,
        this function initializes the local APICs.the task priority register(TPR) of each chip is 
        initialized to a fixed value,the CPU is willing to handle every kind of IRQ signal,regardless of 
        its priority,and the linux kernel never modifies the value after its initialization.

        #  all of these works are done by the hardware.
           but in some cases,the IRQs is distributed in a unfair way to the CPUs by hardware.
           Linux 2.6 makes use of a special kernel thread called kirqd to correct,if necessary,the 
           automatic assignment of IRQs to CPUs.

        <arch/x86/kernel/apic/io_apic.c>
          /*  set_ioapic_affinity_irq - set affinity for a specific irq.
           *  @irq:                     irq vector.
           *  @mask:                    the CPUs that can receive the IRQ.
           *  #  system administrator is able to change the irq affinity through write a 
           *     new CPU bitmap mask into the "/proc/irq/@vector/smp_affinity" file.
           */
          static int set_ioapic_affinity_irq(unsigned int irq, const struct cpumask *mask);

        #  kirqd periodically executes the "do_irq_balance()" function,which keep track of the
           number of interrupt occurrences received by every CPU.
           if imbalance has detected,then "move" IRQ from one CPU to another least loaded CPU,
           or rotates all IRQs among all existing CPUs.

      Multiple Kernel Mode stacks :
        task_struct.stack -> thread_union := { thread_info, stack }(4kB or 8kB)
        task_struct.thread_info => points to the thread_info object associated to current task_struct

        if the size of the thread_union union is 8kB,the Kernel Mode stack of the current process
        is used for every type of kernel control path :
          exceptions, interrupts, deferrable functions

        if the size of the thread_union union is 4kB,the kernel makes use of three types of Kernel Mode
        stacks :
          >  the exception stack is used when handling exceptions(including system call).
             different process has different thread_union,and the stack is contained in it,thus
             kernel makes use of a different exception stack for each process in the system.

          >  the hard IRQ stack is used when handling interrupts.
             there is one hard IRQ stack for each CPU in the system,and each stack is contained in a
             single page frame.

          >  the soft IRQ stack is used when handling deferrable functions.
             there is one soft IRQ stack for each CPU in the system,and each stack is contained in a 
             single page frame.

        #  the per-cpu data @hardirq_stack is type of "union irq_ctx",the union is defined in
           <arch/x86/kernel/irq_32.c>
             union irq_ctx {
                    struct thread_info tinfo;               /*  higher address  */
                    u32 stack[THREAD_SIZE / sizeof(u32)];   /*  lower address  */
             } __attribute__((aligned(PAGE_SIZE)));
           and per-cpu data @softirq_stack also is type of "union irq_ctx".
           @hardirq_stack is used for hard IRQ,and @softirq is used for deferrable functions.
           stack grows towards lower address.

      Saving the registers for the interrupt handler :
        saving registers is the first task of the interrupt handler.
        the address of the interrupt handler for IRQn is initially stored in the @interrupt[n] entry and
        then copied into the interrupt gate included in the proper IDT entry.

        the @interrupt array is build through assembly language instructions and which is defined in
        <arch/x86/kernel/entry_32.S>.
        the array contains NR_IRQS elements(Linux 2.6,NR_VECTORS = 256,FIRST_EXTERNAL_VECTOR = 32,so NR_IRQS = 256 - 32).
        the element at index @n in the array stores the address of the following two assembly language instructions :
          pushl $n-256
          jmp common_interrupt

          /*  Linux 2.6 constructs such entries via a more complex way :
           *  <linux/linkage.h>
           *    #define ENTRY(name)  \
           *        .global name;
           *        ALIGN;
           *        name:
           *
           *    #ifndef END
           *    #define END(name)    \
           *        .size name, .-name
           *    #endif
           *
           *    ----------------------
           *
           *  <arch/x86/kernel/entry_32.S>
           *    .section .init.rodata,"a"
           *    ENTRY(interrupt)
           *    .text
           *        ...             #  now in .init.text subsection
           *    ENTRY(irq_entries_start)
           *      ...
           *      vector=FIRST_EXTERNAL_VECTOR      #  vector = FIRST_EXTERNAL_VECTOR = 32
           *      .rept (NR_VECTORS-FIRST_EXTERNAL_VECTOR+6)/7  #  int(result) = 32
           *        .balign 32      #  position counter forwards to next address @p | 32
           *        .rept 7         #  repeat sequence of code line beween next ".endr" 7 times
           *          ...
           *    1:    pushl $(~vector+0x80)     #  vector number
           *          .if ((vector-FIRST_EXTERNAL_VECTOR)%7) <> 6   #  if (vector-32)%7 != 6 ?
           *            jmp 2f      #  '2' is a label,and suffix 'f' means 'f'orward search '2'
           *                        #  immediate value 2 => $2
           *                        #  address 2 => 0x02
           *                        #  near jump
           *          .endif
           *          .previous     #  continues processing of the previous section.
           *            .long 1b    #  'b'ackward search '1','1' is a label.
           *                        #  now in .init.rodata subsection
           *          .text         #  .text subsection
           *            vector=vector+1     #  update vector for next entry
           *                                #  now in .init.text subsection
           *          ...
           *        .endr
           *    2:      jmp common_interrupt    #  jump to common_interrupt program
           *      .endr
           *   END(irq_entries_start)
           *   .previous            #  now in .init.text subsection
           *   END(interrupt)
           *   #  pack 7 stubs into a single 32-byte chunk,and the pointer points to the handler
           *      for the chunk is attached right after it("jmp common_interrupt").
           *   #  .init.rodata has an array :
           *        [index0] := label 1  (an address of an opcode)  #  now @vector = 32
           *        [index1] := label 1  #  the opcode been compiled and @vector is updated.    
           *        ...                  #  the total number of elements in this array is 224.
           *                             #  elements in vector range 0--31 has been initialized by
           *                             #  trap_init().
           *   #  .init.text :
           *        irq_entries_start:  #  a symbol
           *          pushl $(~vector+0x80)     #  the first stub in the 32-byte chunk
           *          jmp 2f                    #  the first stub in the 32-byte chunk
           *          ...                       #  repeat 5 times
           *          pushl $(~vector+0x80)     #  the seventh stub in the 32-byte chunk
           *          jmp common_interrupt      #  the secenth stub in the 32-byte chunk
           *                                    #  ! AND 2f IS THE ADDRESS OF THIS OPCODE
           *        #  all 224 stubs.the exception special stubs had been initialized by trap_init()
           #        #  only external interrupts are placed there.
           */

        Linux use positive number to identify a system call,so the negative number is used to identify
        an interrupt.

        common_interrupt:
          addl $-0x80,(%esp)
          SAVE_ALL
          TRACE_IRQS_OFF
          movl %esp,%eax
          call do_IRQ
          jmp ret_from_intr
        ENDPROC(common_interrupt)   #  a macro function is defined in <linux/linkage.h>,
                                    #  it will have expended to 
                                    #    .type common_interrupt,@function
                                    #    END(common_interrupt) =>
                                    #      .size common_interrupt,.-common_interrupt
          SAVE_ALL :
            an assembly language macro.

            saves the contents of all registers that the interrupt handler maybe use into stack.

            movl $(__USER_DS),%edx  #  user data segment
            movl %edx,%ds
            movl %edx,%es
            movl $(__KERNEL_PERCPU),%edx
            movl %edx,%fs
            SET_KERNEL_GS %edx      #  movl $(__KERNEL_STACK_CANARY),%edx
                                    #  movl %edx,%gs

            !  eflags,cs,eip,ss,and esp would not be saved,which are already saved automatically by the
               control unit.

          after SAVE_ALL accomplished,the stack be like :
            [contents of registers]     <=  esp
            [interrupt vector]
            [former contents]
            /*  [eip] if @common_interrupt is executed through "call" instruction,but it is not  */
            ...

      do_IRQ() function :
        <arch/x86/include/asm/irq.h> <arch/x86/kernel/irq.c>
          /*  do_IRQ - do interrupt request,@common_interrupt call to this function.
           *  @regs:   pointer points to pt_regs object,the structure saveing the
           *           contents of registers.
           *  return:  always return 1.
           *  #  because this function is called by @common_interrupt,thus,the content of eax
           *     is the content of esp,which is pointing the saved contents of registers by
           *     @SAVE_ALL.
           *     the top element on the stack is content of ebx,and the first member in pt_regs
           *     is named @bx with type of unsigned long.
           *     the member @orig_ax saved the vector of current irq,because its content is the 
           *     content of esp before @SAVE_ALL had called.
           */
          extern unsigned int __irq_entry do_IRQ(struct pt_regs *regs);

        the high-level IRQ handler enter point :
          1>  save the old registers in @old_regs.

          2>  get @vector from @orig_ax.

          3>  get @irq from a per-cpu data which is an array named @vector_irq,the elements in it
              is the @irq,and index is @vector.
              @vector_irq is initialized by "__setup_vector_irq()",it use a "for" cycle to initializes
              this array for a specific cpu.
              macro "for_each_irq_desc" is defined in <linux/irqnr.h>.
              @irq is start from 0 to NR_IRQS,but @vector maybe not,because the value of @vector as
              an index for @vector_irq is got from desc->chip_data,which is type of void pointer,and
              it will points to the device PIC cfg data.(through PIC,the vector is mutable)
              #  the vector is able to be used by devices is in the range [32, 238].(local APIC enabled)

          4>  call to "irq_enter()" start tracing.
              a counter representing the number of nested interrupt handles was increased.
              the counter is stored in the @preempt_count filed of the thread_info structure of 
              current process.

          5>  call to "handle_irq(@irq, @regs)" which is defined in <arch/x86/kernel/irq_32.c>.

          6>  if function "handle_irq()" was failed to retrive irq descriptor via @irq,then returns
              "false",in this case,"ack_APIC_irq()" was called to acknowledge the @irq(it is not
              be handled,because no irq descriptor was find out).
              error message is printed.
          
          7>  call to "irq_exit()" stop tracing.
              decrease the interrupt counter and checks whether deferrable kernel functions are waiting
              to be executed.

          8>  restore registers.

          9>  return control to @common_interrupt,and "ret_from_intr()" will be called.

          #  if "handle_irq()" is succed to handles,the @irq must been acknowledged.
          #  "handle_irq()" checks whether on an interrupt stack now,if current stack is a IRQ stack,
             then keep using this IRQ stack,and call to desc->handle_irq(@irq, @desc);
             otherwise,switch to the IRQ stack for current CPU and then exchange ebx and esp,call to
             desc->handle_irq(@irq, @desc),exchange ebx and esp again after "handle_irq()" is completed.
             
             /*  it is on an interrupt stack now,that is,a hardirq handler is interrupted.  */
             /*  the current task is stored in @irqctx->tinfo.task
              *  the previous stack is stored in @irqctx->tinfo.previous_esp
              *  and the softirq bits in @preempt_count was copied,thus,the softirq checks work in
              *  the hardirq context
              */

          #  there is some difference for x86_64 platform about "handle_irq()" function.
             on x86_64,"handle_irq()" will calls to "generic_handle_irq_desc()" function which
             is defined in <linux/irq.h> as a static inline function.
             that function checks whether desc->handle_irq is NULL,if it is,then call to "__do_IRQ()"
             function;otherwise call to desc->handle_irq.
          #  the function "__do_IRQ()" is the original all in one high-level IRQ handler.
             but this function is deprecated.
             this function is existed only CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ is off.                

        /*  The actions to take while desc->handle_irq is NULL :
         *    x86_32:  do nothing except to acknowledge PIC.
         *    x86_64:  call to __do_IRQ().
         */

      __do_IRQ() function : (Effectively with CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ off)
        <linux/irq.h> <kernel/irq/handle.c>
          #ifndef CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ
          /*  __do_IRQ - the generic hardware interrupt request handler.
           *  @irq:      IRQ number.
           *  return:    always return 1.
           */
          extern unsigned int __do_IRQ(unsigned int irq);
          #endif

        the works "__do_IRQ()" does as the following :
          1>  retrive the corresponding interrupt descriptor via @irq.and increase the cpu_usage_stat.irq of current
              CPU via call to kstat_incr_irqs_this_cpu()<linux/kernel_stat.h>.

          2>  if this @irq is IRQ_PER_CPU and current CPU has not disabled it,then handles it through
              "handle_IRQ_event()"<kernel/irq/handle.c>.
              acknowledge maybe occurs before handle if desc->chip->ack is not NULL,otherwise it occurs after
              handle via desc->chip->end.
              finally return 1.

          3>  if this @irq is not IRQ_PER_CPU,that means the interrupt is global.
              then ready to handles it.

          4>  acquires spin lock of interrupt descriptor at first,
              if desc->chip->ack is not NULL,acknowledge it.
              clear IRQ_REPLAY | IRQ_WAITING in the @desc->status.
                IRQ_REPLAY is when Linux resends an IRQ that was dropped earlier.
                IRQ_WAITING is used by probe to mark irqs that are being tested.
              set IRQ_PENDING,ready to handle.

          5>  checks whether IRQ_DISABLED | IRQ_INPROGRESS is setted.
              if it is,then do not handle this @irq;
              otherwise,get ISR,clear IRQ_PENDING and set IRQ_INPROGRESS,that is,the @irq is ready to be
              serviced.

          6>  enter a loop to process ISR.
              before "handle_IRQ_event()" is called with the ISR,spin lock of the interrupt descriptor must be
              released.
              this allows the second @irq is occurred while in handler or in "do_IRQ()",so the second @irq will
              be serviced after the previous @irq is handled completely.
              BUT THIS LOOP ONLY HANDLE THE SECOND INSTANCE,NEITHER THE THIRD,NOR THE FOURTH...
              after "handle_IRQ_event()" returned,the kernel control path acquire the spin lock and check if
              IRQ_PENDING is setted,if it is,that means the SECOND came in,then continue to handles it.(clear
              IRQ_PENDING again)
              if there is no more @irq came in,loop will ends.

          7>  call to desc->chip->end to end an interrupt request.
              release spin lock.
              return 1.

        #  "handle_IRQ_event()" is run with local cpu irq disabled,that is "__do_IRQ()" is run with local cpu irq
           disabled.
           the CPU control unit automatically clears eflags.IF because the interrupt handler is invoked through an
           IDT's interrupt gate.(IF indicates if CPU receives maskable interrupt)
           but after "handle_IRQ_event()" finished,the local cpu irq will be enabled again.

        #  why not service the third or the fourth?
           because the acknowledge is deferred before __do_IRQ() exit.(no ack() was called while ISR running)
           so the local APIC of current CPU would not accept further interrupts.(I/O APIC)
           although further occurrences of this type of interrupt may be accepted by other CPU.
        #  everytime "handle_IRQ_event()" returned,the function "note_interrupt()" is called if @noirqdebug is false.
           that function updates some counter in the interrupt descriptor,and if the bad irq exceeded the threshold
           on this IRQ line,the kernel control path will disable the IRQ line.
           /*  <kernel/irq/spurious.c>  */

      Reviving a lost interrupt :
        an interrupt lost :
          CPU0 received an @irq,on IRQ56 =>
          CPU1 disabled IRQ56 before CPU0 acknowledge to the PIC the @irq from =>
          CPU0 call to "do_IRQ()",but it finds IRQ_DISABLED is setted =>
          "do_IRQ()" returned with nothing have done except acknowledge the @irq =>
          the interrupt request @irq lost.

        <linux/irq.h> <kernel/irq/manage.c>
          /*  enable_irq - enable an IRQ line which corresponding to the @irq.
           *  @irq:        IRQ number.
           *  #  this function call to __enable_irq(irq_to_desc(irq), irq, false) with held
           *     chip_bus_lock and raw_spin_lock_irqsave,and release them before exit.
           *  #  if desc is NULL,then nothing to do.
           */
          extern void enable_irq(unsigned int irq);  /*  exported  */

          /*  __enable_irq - internal routine for enable an irq.
           *  @desc:         interrupt descriptor.
           *  @irq:          irq number.
           *  @resume:       bool value indicates whether resume from suspended before enable.
           */
          void __enable_irq(struct irq_desc *desc, unsigned int irq, bool resume);  /*  unexported  */

          #  before enable,the @irq can not been suspended,and the @irq is only able to be enabled 
             when desc->depth == 1.
             if desc->depth > 1 => decrease it
             else if desc->depth < 1 => error
             if desc->depth == 1 => function "check_irq_resend()" enable @irq.

        <linux/irq.h> <kernel/irq/resend.c>
          /*  check_irq_resend - enable @irq,if any lost interrupt was found out,
           *                     revive it.
           *  @desc:             interrupt descriptor.
           *  @irq:              irq number.
           */
          void check_irq_resend(struct irq_desc *desc, unsigned int irq);

          the function detects that an interrupt was lost by checking the value of the IRQ_PENDING flag.
          because IRQ_PENDING is always cleared when leaving the interrupt handler,if the IRQ line is
          disabled but IRQ_PENDING is set,then an interrupt occurrence has been acknowledged but not
          yet serviced.
          thus,it call to desc->chip->enable to enables @irq.
          next,clear IRQ_PENDING and set IRQ_REPLAY,put @irq to the bits @irqs_resend,and schedule
          a tasklet which is named @resend_tasklet.@resend_tasklet is associated to a worker "resend_irqs()"
          which is static defined in "resend.c".
          the function "resend_irqs()" enter a loop until the bitmap @irqs_resend is null,for each @irq
          in the bitmap,it disable local irq and call to irq_to_desc(irq)->handle_irq,after returned
          from handler,it enable local irq then enter next cycle.

          #  IRQ_REPLAY : IRQ has been replayed but not acked yet.
             "__do_IRQ()" always clear it before handling,and it also clear IRQ_PENDING before exit.
          #  tasklet is a kind of softirq,and softirq is interprocessor interrupt.
          #  "check_irq_resend()" resend irqs must met the condition that desc->chip->retrigger is NULL or
             desc->chip->retrigger(irq) is false.
             retrigger is the hardware relative primitive for resend an IRQ to CPU.
             /*  subsection - PIC :
              *    Disable interrups are not lost;the PIC sends them to the CPU as soon as they are
              *    enabled again.
              */

      Interrupt Service Routines :
        the actions relate to an interrupt the handler have to takes named ISRs,and these actions are executed
        by the function "handle_IRQ_event()".ISR just specific to one type of device.

        <linux/irqreturn.h>
          enum irqreturn {
                IRQ_NONE,           /*  interrupt was not from this device  */
                IRQ_HANDLED,        /*  interrupt was handled by this device  */
                IRQ_WAKE_THREAD     /*  handler requests to wake the handler thread  */
          };
          typedef enum irqreturn irqreturn_t;

          /*  IRQ_RETVAL - if the interrupt is handled  */
          #define IRQ_RETVAL(X)  ((x) != IRQ_NONE)

        <linux/irq.h>
          typedef void (*irq_flow_handler_t)(unsgned int irq, struct irq_desc *desc);
          
          /*  handle_IRQ_event - the primary worker deal with a specific interrupt.
           *                     this function call to the actions associated to the IRQ line,
           *                     until one of ISR handled it.
           *  @irq:              IRQ number.
           *  @action:           ISRs.
           *  return:            a value is type of enum irqreturn.
           */
          extern irqreturn_t handle_IRQ_event(unsigned int irq, struct irqaction *action);

          the works "handle_IRQ_event()" does :
            1>  if IRQ_DISABLED in @action is not set,then call to "local_irq_enable_in_hardirq()" to
                enable @irq.thus,new interrupt is able to be raised on this IRQ line.
                ("sti" assembly instruction.and if an action for an interrupt must disabled maskable
                 interrupts before start handling,that is the action is critical.) 
            
            2>  enter a loop,iterator is @action,until @action is NULL.

            3>  start trace irq handling through "trace_irq_handler_entry(@irq, @action)",
                call to @action->handler(@irq, @action->dev_id),
                stop trace irq handling through "trace_irq_handler_exit(@irq, @action, ret)".

            4>  switch-cases :
                  ret = IRQ_WAKE_THREAD >
                    ret := IRQ_HANDLED
                    wake_up_process(action->thread)  /*  action->thread_fn must be not NULL,
                                                      *  IRQF_DIED is not set in @action->thread_flags.
                                                      */

                  ret = IRQ_HANDLED >
                    local var @status |= action->flags

                  default >
                    none

            5>
                local var @retval |= ret         /*  this variable will be return value and initialized to
                                                  *  IRQ_NONE at first.
                                                  *  there is the only place in the function @retval is changed.
                                                  */
                update @action to next ISR

            6>  exit loop

            7>  if IRQF_SAMPLE_RANDOM is set in @status,@irq will be used to feed random number generator.

            8>  call to "local_irq_disable()" to restore the state of local IRQ line,if it was not diabled
                early,this function does nothing.("cli" assembly instruction)
                return @retval.

          #  Attention :
                value of IRQ_NONE is zero.
                and,even there is an ISR handled current interrupt in the loop,the loop is still continues
                unitl @action is NULL.
                thus,if the interrupt is serviced,just @retval is not able to reveal how many ISRs was called.

          #  register informations had stored on the stack by @SAVE_ALL assembly macro function,and "do_IRQ()"
             writes the address about the top of stack that is where esp points to into a percpu data which
             is named @irq_regs.
             so call to ISR do not need to transmit register contents.

          #  suppose,ISR1 requests IRQ line is disabled,but ISR2 requests IRQ line is enabled,then ISR2 will
             be called with IRQ line disabled,because that loop do not check whether local IRQ line have to
             be enabled or disabled.
                  
      Dynamic Allocation of IRQ Lines :
        except to reserved vectors for specific devices,the remaining ones are dynamically handled.
        there is,a way in which the same IRQ line can be used by several hardware devices even if they do
        not allow IRQ sharing.
        !  THE TRICK IS TO SERIALIZE THE ACTIVATION OF THE HARDWARE DEVICES SO THAT JUST ONE OWNS THE
           IRQ LINE AT A TIME.

        <linux/interrupt.h>
        typedef irqreturn_t (*irq_handler_t)(int, void *);

        #ifdef CONFIG_GENERIC_HARDIRQS
          extern int __must_check request_threaded_irq(unsigned int irq, irq_handler_t handler, 
                                                       irq_handler_t thread_fn, unsigned long flags,
                                                       const char *name, void *dev);
          static inline int __must_check
          request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev);
        #else
          extern int __must_check request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,
                                              const char *name, void *dev);
          extern int __must_check request_threaded_irq(unsigned int irq, irq_handler_t handler, 
                                                       irq_handler_t thread_fn, unsigned long flags,
                                                       const char *name, void *dev);
        #endif
        /*  request_irq - request to register an ISR on an IRQ line.
         *  @irq:         IRQ number.
         *  @handler:     handler.
         *  @flags:       flags.
         *  @name:        device specified information used in "/proc/irq" and "/proc/interrupts".
         *  @dev:         device specified data.
         *  return:       0 or error code.
         */ 

        /*  request_threaded_irq - request to register an ISR with threaded environment.
         *  @irq:                  IRQ number.
         *  @handler:              handler.
         *  @thread_fn:            thread function.
         *  @flags:                irqaction flags.
         *  @name:                 device specified information.
         *  @dev:                  device specified data.
         *  return:                0 or error code.
         */

        #  to insert an irqaction descriptor in the proper list,the kernel invokes the "setup_irq()" function,
           passing to it the parameters @irq IRQ number and an address about the new irqaction object.
           if there is device used @irq previously,then check whether IRQF_SHARED is set.if it is not setup,
           then register ISR on @irq will be refused.
           @new_irqaction is added into irq_desc[@irq]->action list.
           !  if no other device is sharing the same IRQ,the function("setup_irq()") clears the
              IRQ_DISABLED,IRQ_AUTODETECT,IRQ_WAITING,IRQ_INPROGRESS flags in the interrupt descriptor 
              corresponding to this @new_irqaction.

        !  IN THE CASE THAT CONFIG_GENERIC_HARDIRQS IS NOT DEFINED,FUNCTION "request_irq()" IS UNDEFINED,BUT
           "request_threaded_irq()" IS DEFINED AND EXPORTED.
           IN THE CASE THAT CONFIG_GENERIC_HARDIRQS IS DEFINED,FUNCTION "request_irq()" JUST A WRAPPER WHICH
           CALL TO "request_threaded_irq()" WITH NULL @thread_fn.

        flags for ISR :
          IRQF_DISABLED         keep irqs disabled when calling the action handler
          IRQF_SAMPLE_RANDOM    feed random number generator
          IRQF_SHARED           allow sharing the irq among several devices
          IRQF_PROBE_SHARED     set by callers when they expect sharing mismatches to occur
          IRQF_TIMER            mark this interrupt as timer interrupt
          IRQF_PERCPU           interrupt is percpu
          IRQF_NOBALANCING      exclude this interrupt from irq balancing
          IRQF_IRQPOLL          interrupt is used for polling
                                (only the interrupt that is registered first in an shared interrupt is
                                 considered for performance reasons)
          IRQF_ONESHOT          interrupt is not reenabled after the hardirq handler finished.
                                used by threaded interrupts which need to keep the irq line disabled
                                until the threaded handler has been run

          /*  free_irq - free a registered IRQ line.
           *  @irq:      the IRQ line.
           *  @dev:      identifier of the ISR in action list.(irq_desc[@irq]->action)
           *  #  if the ISR is the last interrupt service routine in the action list,
           *     then disable the IRQ line.(shut it down)
           */
          extern void free_irq(unsigned int irq, void *dev);

        !  DO NOT CALL TO "request_irq()" IN AN INTERRUPT CONTEXT,BECAUSE OF IT MIGHT ENTER SLEEP.

    Interprocessor Interrupt Handling :
      Interprocessor interrupts allow a CPU to send interrupt signals to any other CPU in the system.
      IPI is delivered not through an IRQ line,but directly as a message on the bus that connects the
      local APIC of all CPUs.

      Linux,IPI on multiprocessor system : (three kinds)
        CALL_FUNCTION_VECTOR(vector 0xfb)
          sent to all CPUs but the sender,forcing those CPUs to run a function passed by the sender.
          the corresponding interrupt handler is named "call_function_interrupt()".
          usually,this interrupt is sent to all CPUs except the CPU executing the calling function by
          means of the "smp_call_function()" facility function.
          /*  such function maybe stop the CPUs or force CPUs to set the contents of the
           *  Memory Type Range Registers(MTRRs).
           *  MTTRs : additional registers to easily customize cache operations.
           *          Linux may use them to disable the hardware cache for the address mapping the 
           *          frame buffer of a PCI/AGP graphic card while maintaining the "write combining"
           *          mode of operation : the paging unit combines write transfers into large chunks
           *          before copying them into the frame buffer.
           */

        RESCHEDULE_VECTOR(vector 0xfc)
          when a CPU receives this type of interrupt,the corresponding handler - named "reschedule_interrupt()" -
          limits itself to acknowledging the interrupt.
          rescheduling is done automatically when returning from the interrupt.
        
        INVALIDATE_TLB_VECTOR(vector 0xfd)
          send to all CPUs but the sender,forcing them to invalidate their Translation Lookaside Buffers.
          the corresponding handler,named "invalidate_interrupt()",flushes some TLB entries of the processor.

        /*  The assembly language macro "BUILD_INTERRUPT3(name, nr, fn)" is defined in
         *  <arch/x86/kernel/entry_32.S>,which is similar to "common_interrupt".(vector is still a negative number)
         *  The C language macro "BUILD_INTERRUPT(name, nr)" is defined in <arch/x86/kernel/entry_32.S>,which
         *  is used to define an interprocessor interrupt,actually,it is "BUILD_INTERRUPT3(name, nr, smp_##name)".
         *    e.g.  
         *      <arch/x86/include/asm/entry_arch.h>
         *      BUILD_INTERRUPT(call_function_interrupt, CALL_FUNCTION_VECTOR)
         *      BUILD_INTERRUPT(irq_move_cleanup_interrupt, IRQ_MOVE_CLEANUP_VECTOR)
         *      BUILD_INTERRUPT3(invalidate_interrupt0, INVALIDATE_TLB_VECTOR_START + 0)
         */

        source file <arch/x86/kernel/smp.c> defined some interprocessor interrupt handlers :
          e.g.
            /*  smp_reschedule_interrupt - handler for the IPI with vector RESCHEDULE_VECTOR.
             *  @regs:                     registers' contents saved on the stack via "SAVE_ALL".
             *                             @regs is the esp points to the top of stack.
             *  #  this function does nothing but acknowledge IPI,
             *     rescheduling is automatically done when returning from interrupt.
             */
            void smp_reschedule_interrupt(struct pt_regs *regs);
        
            /*  smp_call_function_interrupt - handler for the IPI with vector CALL_FUNCTION_VECTOR.
             *  @regs:                        registers' contents saved by "SAVE_ALL",@regs is the 
             *                                esp points to the top of stack.
             *  #  this function actually call to "generic_call_function_interrupt()" after it
             *     acknowledged the IPI.
             *     function "generic_call_function_interrupt()" is defined in <kernel/smp.c>.
             */
            void smp_call_function_interrupt(struct pt_regs *regs);
            
            /*  figure about smp_call_function_interrupt :
             *  smp_call_function_interrupt =>
             *  generic_smp_call_function_interrupt {
             *          traverse call_function list (defined in <kernel/smp.c>)
             *          for each entry is type of call_single_data (defined in <linux/smp.h>)
             *          retrive its container is type of call_function_data (defined in <kernel/smp.c>)
             *          call to @data->csd.func(@data->csd.info)
             *          if @data->refs == 0
             *              delete current entry from list
             *      ####   
             *              struct call_function_data {
             *                struct call_single_data csd;
             *                atomic_t                refs;
             *                cpumask_var_t           cpumask;
             *              };  /*  one @csd corresponding to one @cfd  */
             *
             *              call_function.queue -> csd1 -> csd2 -> ... -> call_function.queue
             *                                      |       |
             *                                      V       V
             *                                     cfd     cfd
             *  }
             */


            !!  the following IPIs are existed only CONFIG_SMP is defined :
                  call_function_interrupt       =>  CALL_FUNCTION_VECTOR
                  reschedule_interrupt          =>  RESCHEDULE_VECTOR
                  irq_move_cleanup_interrupt    =>  IRQ_MOVE_CLEANUP_VECTOR
                  reboot_interrupt              =>  REBOOT_VECTOR
                  invalidate_interrupt{0..7}    =>  INVALIDATE_TLB_VECTOR_START + {0..7}

                  /*  the corresponding "smp_##name()" functions are defined either <arch/x86/kernel/smp.c>
                   *  or <kernel/smp.c>.
                   *  TLB relative function is defined in <arch/x86/mm/tlb.c>.
                   */

      IPI operating functions :
        <arch/x86/include/asm/apic.h>
          /*  struct apic - the generic APIC sub-arch data struct.in other word,the object is type of
           *                struct apic represents the I/O APIC.
           *  @send_IPI_mask:           send IPI with @vector to the CPUs determined by @mask.
           *  @send_IPI_allbutself:     send IPI with @vector to all CPUs except sender.
           *  @send_IPI_all:            send IPI with @vector to all CPUs include sender.
           *  @send_IPI_self:           send IPI with @vector to @self.
           */
          struct apic {
                ...
                void (*send_IPI_mask)(const struct cpumask *mask, int vector);
                ...
                void (*send_IPI_allbutself)(int vector);
                void (*send_IPI_all)(int vector);
                void (*send_IPI_self)(int vector);
                ...
          };

          extern struct apic *apic;     /*  global apic object pointer  */

          /*  the corresponding function pointers will be initialized by kernel across to the CPU model.
           *  different CPU has different apic object.
           */

          /*  Linux 2.6 DOES NOT CONTAIN THE WRAPPERS FOR THESE FUNCTIONS,IN ORDER TO SEND IPI,HAVE TO USE THE
           *  GLOBAL OBJECT @apic IS TYPE OF "struct apic *",FOR EXAMPLE,"acpi->send_IPI_all(CALL_FUNCTION_VECTOR)".
           *  Linux SUPPORTS TO SEVERAL TYPES OF APIC,SO THE MEMBERS OF THE OBJECT MAYBE DIFFERENT.
           *  x86 DEFAULT APIC    : apic_default       <arch/x86/kernel/apic/probe_32.c>
           *  x86_64 DEFAULT APIC : apic_flat          <arch/x86/kernel/apic/apic_flat_64.c>
           */

          /*  call function interrupt outer interface :
           *  <kernel/smp.c>,
           *    smp_call_function - run a function on all other CPUs.
           *    @func:              the function to be executed.
           *    @info:              private data of @func.
           *    @wait:              T => wait until other CPUs completed function executing
           *                        F => does not waiting
           *    return:             always 0.
           *    #  can not call this function with disabled interrupts or from a hardirq handler or
           *      from a bottom half handler.
           *    int smp_call_function(void (*func)(void *), void *info, int wait);
           */

    Softirqs and Tasklets :
      non-critical tasks can be deferred for a long period of time,if necessary.
      ISRs are serialized,and often there should be no occurrence of an interrupt until the corresponding
      interrupt handler has terminated.
      deferrable tasks can execute with all interrupt enabled.

      Linux 2.6 non-urgent interruptible kernel functions :
        /*  deferrable functions  */
        /*  Intel manual called programmed exception as "softirq"  */

        softirqs
          statically allocated
          can run concurrently on several CPUs,even if they are of the same type(reentrant,the data
          structures that softirqs hold must be protected by spin lock)

        tasklets
          dynamically allocated
          the same type of tasklet cannot be executed by two CPUs at the same time(however,tasklets of
          different types can be executed concurrently on several CPUs)

        /*  softirqs and tasklets are strictly correlated,because tasklets are implemented on top of 
         *  softirqs.
         */

      Interrupt context :
        the kernel is currently executing either an interrupt handler or a deferrable function.

      The general operations can be performed on deferrable functions :
        Initialization
          defines a new deferrable function
          this is usually done when the kernel initializes iteself or a module is loaded

        Activation
          marks a deferrable function as "pending"
          it is to be run the next time the kernel schedules a round of executions of deferrable functions
          activation can be done at any time(even while handling interrupts)

        Masking
          selectively disables a deferrable function 
          it will not be executed by the kernel even if activated
        
        Execution
          executes a pending deferrable function together with all other pending deferrable functions of
          the same type
          execution is performed at well-specified times

        /*  a deferrable function that has been activated by a given CPU must be executed on the same CPU  */

      Softirq :
        ten kinds of softirqs > <linux/interrupt.h>
          HI_SOFTIRQ                handles high priority tasklets
          TIMER_SOFTIRQ             tasklets related to timer interrupts
          NET_TX_SOFTIRQ            transmits packets to network cards
          NET_RX_SOFTIRQ            recevies packets from network cards
          BLOCK_SOFTIRQ             block device softirq
          BLOCK_IOPOLL_SOFTIRQ      block device I/O poll softirq
          TASKLET_SOFTIRQ           handles regular tasklets
          SCHED_SOFTIRQ             scheduler softirq
          HRTIMER_SOFTIRQ           high-resolution timer
          RCU_SOFTIRQ               rcu lock

          NR_SOFTIRQS               /*  end of enumberated types  */
                                    /*  HI_SOFTIRQ = 0  */

        /*  Before Linux 2.6,the Bottom Half mechanism BH is used to handle non-critical works,
         *  the total number of BHs is 32.
         *  Since Linux 2.6,BH had abandoned,softirqs as a intead,and the maximum number of softirqs
         *  also is 32.all device drivers which used BH should convert it to tasklet.
         */

        data structures used for softirqs >
          <linux/interrupt.h>
            /*  struct softirq_action - softirq action wrapper.
             *  @action:                the deferrable function will be executed.
             */
            struct softirq_action {
                    void (*action)(struct softirq_action *);
                    /*  Linux 2.6 DID NOT DEFINE SUCH FIELD WHICH USED TO SAVE THE ARGUMENT OF
                     *  THE @action DEFERRABLE FUNCTION.
                     */
            };

          <kernel/softirq.c>
            /*  softirq_vec - an array contains all types of softirqs.
             *                the enumberated types defined in <linux/interrupt.h>
             *                as the vector for this array.
             */
            static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;

          thread_info.preempt_count :
            [0, 7]        preemption counter      /*  how many times preemption is explicitly disabled  */
            [8, 15]       softirq counter         /*  how many levels deep the disabling of deferrable functions is  */
            [16, 27]      hardirq counter         /*  specifies the number of nested interrupt handlers on the local CPU  */
            [28]          PREEMPT_ACTIVE flag     /*  allow preemption or refuse preemption  */
          
            /*  some bits in @preempt_count are used to keep track of kernel preemption and of nesting of kernel
             *  control paths.
             *  softirq counter = 0 => deferrable functions are enabled
             *  hardirq counter => irq_enter() increase it and irq_exit() decrease it
             */
          
            useful macro function to determine where the kernel path is now :
              <linux/hardirq.h>
                #define in_irq()  (hardirq_count())       /*  Is kernel running interrupt handler?  */
                #define in_softirq()  (softirq_count())   /*  Is kernel running deferrable function?  */
                #define in_interrupt()  (irq_count())     /*  Is kernel running interrupt handler or deferrable function?  */
  
                /*  if kernel is not make use of Kernel Mode stack
                 *    preempt_count get from current.thread_info
                 *  else
                 *    preempt_count get from irq_ctx union assocaited with the local CPU
                 */

            irq_cpustat_t.__softirq_pending :
              the field @__softirq_pending is a per-CPU 32-bit mask describing the pending softirqs.
              
              <linux/irq_cpustat.h>
                #define local_softirq_pending()  \
                        __IRQ_STAT(smp_processor_id(), __softirq_pending)

        Handling softirqs :
          linux softirq has defined two primitives for operating softirq mechanism.
            OPEN        -       install a softirq deferrable function.
            RAISE       -       raise a installed softirq.
                                /*  structure softirq_action is not chained,so there is only
                                 *  one deferrable function for one type of softirq at the
                                 *  same time.
                                 */

          <linux/interrupt.h>
            /*  open_softirq - install a softirq deferrable function @action at the
             *                 position @softirq_vec[@nr].
             *  @nr:           softirq vector.
             *  @action:       deferrable function.
             */
            extern void open_softirq(int nr, void (*action)(struct softirq_action *));

            /*  raise_softirq - raise a softirq have vector @nr.
             *  @nr:            softirq vector.
             *  #  this function will save the local IRQ flags(eflags.IF) and then disable
             *     local IRQ(through assembly language instruction "cli").
             *     call to "raise_softirq_irqoff()" which must run with irqs disabled,
             *     next,"__raise_softirq_irqoff()" will be called,which set the bit associated 
             *     to @nr in the pending softirqs on current CPU.check if current context
             *     is not interrupt context,if it is,wake up ksoftirqd.
             *     before "raise_softirq()" returns,"local_irq_restore()" is called for restore
             *     interrupt flags to the previously saved.
             */
            extern void raise_softirq(unsigned int nr);
            extern void raise_softirq_irqoff(unsigned int nr);

          checks for active(pending) softirqs should be performed periodically,but without inducing too much
          overhead,they are performed in a few points of the kernel code :
            >  when the kernel invokes the "local_bh_enable()" function to enable softirqs on the local CPU.
               /*  bh => bottom half,had removed from Linux kernel  */
            >  when the "do_IRQ()" function finishes handling an I/O interrupt and invokes the "irq_exit()" macro.
            >  if the system uses an I/O APIC,when the "smp_apic_timer_interrupt()" function finishes handling
               a local timer interrupt.
            >  in multiprocessor systems,when a CPU finishes handling a function triggered by a CALL_FUNCTION_VECTOR
               interprocessor interrupt(IPI).
            >  when one of the special "ksoftirqd/n" kernel threads is awakended.
               /*  on SMP,each CPU in the system has a kernel thread named "ksoftirqd" which deal with the
                *  softirq handling.
                *  Linux kernel make a balance between softirqs and User Mode processes through the task scheduler.
                */

          the do_softirq() function :
            <linux/interrupt.h> 
              /*  do_softirq - function deal with soft interrupt.
               *               defined in <kernel/softirq.c>
               */
              asmlinkage void do_softirq(void);

              the following actions this function will takes:
                1>  check whether in an interrupt context now,if it is,then return.
                    deferrable function can not be executed in an interrupt context.
                2>  call to local_irq_save(@flags) to saves the contents of eflags register to local
                    variable @flags.
                    /*  function local_irq_save() will disable local interrupt.  */
                3>  call to local_softirq_pending() to get the pending softirqs and saves them in
                    local variable @pending.
                4>  if there is a softirq pending,then call to __do_softirq(),which will does the
                    primary works.
                    /*  local interrupt still be disabled at the time control enter __do_softirq().  */
                5>  call to local_irq_restore(@flags) to restores the status of eflags.
                    /*  function local_irq_restore() restores eflags.if eflags.IF flag was not setted previously,
                     *  it will be unsetted after local_irq_restore() finished.
                     */

          the __do_softirq() function :
            <linux/interrupt.h>
              /*  __do_softirq - the main routine for softirq handling.
               *                 it is defined in <kernel/softirq.c>
               */
              asmlinkage void __do_softirq(void);

              /*  GCC feature:
               *    __builtin_return_address - GCC built-in function.
               *                               it returns the return address(eip) of the current function,or
               *                               of one of its callers.
               *    @level:                    it is number of frames to scan up the call stack.0 yields
               *                               the return address of the current function,and so forth.
               *    void *__builtin_return_address(unsigned int level);
               */

              the following actions this function will takes:
                1>  retrive pending local softirqs.
                2>  account system vtime via account_system_vtime(current).
                3>  call to __local_bh_disable((unsigned long)__builtin_return_address(0)) to updates preempt_count()
                    with SOFTIRQ_OFFSET.
                    /*  preempt_count() => current_thread_info()->preempt_count
                     *  @ip parameter of __local_bh_disable() is used to tracing kernel control path.
                     *  before updating,eflags.IF will be cleared,and eflags will be restored after updated.
                     */
                4>  set_softirq_pending(0),clean the softirq pending bitmap.
                    enable local irq.
                    /*  do_softirq() disabled local interrupt before __do_softirq() was called.  */
                5>  let local variable @h points to @softirq_vec array.
                6>  traverse @pending until @pending == 0 (bits traversing).
                7>  if (@pending & 1)
                      prepare account and tracing;
                      call to h->action(h);
                    h++;
                    pending >>= 1;
                8>  disable local irq.
                9>  check again if new softirq was raised.
                10> if @pending != 0 and @max_restart != 0
                      restart to 4>
                    if @pending != 0 and @max_restart == 0
                      can not restart,wake up ksoftirqd
                11> stop tracing,update system vtime,call to __local_bh_enable().
                12> return control to do_softirq().

                /*  before action 4> the function lockdep_softirq_enter() is called,current->softirq_context++,
                 *  before action 12> the function lockdep_softirq_exit() is called,current->softirq_context++.
                 *  these two functions are defined in <linux/irqflags.h>
                 */

        The ksoftirqd kernel threads :
          the kernel ksoftirqd is represent a solution for a critical trade-off problem.
          the detail of it is defined in <kernel/softirq.c>.

          !  softirq functions may reactive themselves,in fact,both the networking softirqs and the
             tasklet softirqs do this,moreover,external events,such as packet flooding on a network card
             may active softirqs at very high frequence.

          <kernel/softirq.c>
            /*  per-cpu data for per-cpu kernel thread [ksoftirqd]  */
            static DEFINE_PER_CPU(struct task_struct *, ksoftirqd);

            /*  wakeup_softirqd - wakeup the ksoftirqd kernel thread of local CPU.
             *  #  no indefinitely loop in this function to avoid userspace starvation.
             *     do_softirq() call to this function to deal with the new coming softirqs.
             */
            void wakeup_softirqd(void);

            /*  run_ksoftirqd - the main function to run for the kernel thread [ksoftirqd].
             *  @__bind_cpu:    the cpu associated to the [ksoftirqd],if the cpu is offline,
             *                  the corresponding [ksoftirqd] should to die.
             *  #  the main works this function does:
             *       >  set task state to TASK_INTERRUPTIBLE.
             *       >  enter a loop until kthread_should_stop() returns true.
             *       >  in the loop,set task state to TASK_RUNNING,disable kernel preempt and check local softirqs
             *          via local_softirq_pending().
             *       >  if any local softirqs are pending,call to do_softirq(),then enable preempt and call to
             *          cond_resched(),this function will call to schedule().(flag TIF_NEED_RESCHED of the current 
             *          thread_info set)
             *       >  if none of local softirqs are pending,then enable preempt and set task state to TASK_INTERRUPTIBLE,
             *          next call to schedule() to yield CPU time.
             */
            static int run_ksoftirqd(void *__bind_cpu);

            /*  spawn_ksoftirqd - init function which spawn the [ksoftirqd] kernel thread 
             *                    for current cpu.
             *  #  this function will be called at the time that is kernel initialization.
             *     it will call to cpu_callback()<kernel/softirq.c> to creates a kernel thread
             *     which is about to runs run_ksoftirqd() function.
             *     it call to cpu_callback() twice,the second of invocation is to wakeup [ksoftirqd].
             */
            static __init spawn_ksoftirqd(void) early_initcall(spawn_ksoftirqd);

          the potential for a continuous high-volume flow of softirqs creates a problem that is solved by
          introducing kernel threads.without them,developers are essentially faced with two alternative
          strategies:
            1>  ignoring new softirqs that occur while do_softirq() is running.
                the new coming softirqs will be deferred to next timer interrupt,this is can not be 
                acceptable for network system.
            2>  continuously rechecking for pending softirqs.
                the do_softirq() function could keep checking the pending softirqs and would terminate
                only when none of them is pending.
                userspace stravation will occur.(if a high-frequence flow of packets is received by a network card,
                or a softirq function keeps activating itself)

            !   [ksoftirqd] has low priority,the userspace programs will have a change to run.

        Tasklets :
          tasklets are the preferred way to implement deferrable functions in I/O drivers.
          tasklet is implemented through HI_SOFTIRQ or TASKLET_SOFTIRQ,several tasklets may be associated
          with the same softirq,each tasklet carrying its own function.
          do_softirq() deal with tasklet is type of HI_SOFTIRQ before the tasklet is type of TASKLET_SOFTIRQ.

          <linux/interrupt.h>
            /*  tasklet_struct - the structure represents a kernel tasklet.
             *  @next:           pointer to next tasklet.
             *  @state:          status of this tasklet.
             *                   value :
             *                     TASKLET_STATE_SCHED - pending
             *                     TASKLET_STATE_RUN   - running
             *  @count:          lock counter.
             *  @func:           function pointer to the function this tasklet carrying.
             *  @date:           date to the @func.
             */
            struct tasklet_struct {
                    struct tasklet_struct *next;
                    unsigned long state;
                    atomic_t count;
                    void (*func)(unsigned long);
                    unsigned long data;
            };

          <kernel/softirq.c>
            /*  tasklet_head - the structure represents a tasklet link-list.
             *  @head:         the head.
             *  @tail:         the tail(pointer to pointer).
             */
            struct tasklet_head {
                    struct tasklet_struct *head;
                    struct tasklet_struct **tail;
            };

            /*  --- per-cpu data ---  */

            /*  for TASKLET_SOFTIRQ  */
            static DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);
            /*  for HI_SOFTIRQ       */
            static DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);
            
          <linux/interrupt.h>
            /*  tasklet_init - initializes a tasklet_struct.
             *  @t:            pointer to the tasklet_struct structure.
             *  @func:         the function this tasklet_struct carrys.
             *  @data:         the data to @func.
             */
            extern void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data);

            /*  tasklet_disable_nosync - disable a tasklet without synchronize.
             *  @t:                      the tasklet_struct object.
             *  #  this function atomic increase the data member tasklet_struct.count.
             *     for smp,the function smp_mb_after_atomic_inc() will be called to synchronize to another cpu.
             */
            static inline void tasklet_disable_nosync(struct tasklet_struct *t);

            /*  tasklet_disable - synchrounous version.
             *  @t:               the tasklet_struct object.
             *  #  this function just call to tasklet_disable_nosync() and then call to tasklet_unlock_wait(@t)
             *     to wait the tasklet gets end if it is running on some cpu.
             */
            static inline void tasklet_disable(struct tasklet_struct *t);

            /*  tasklet_enable - enable a disabled tasklet.
             *  @t:              the tasklet_struct object which had been disabled.
             *  #  this function atomic decrease the data member tasklet_struct.count .
             */
            static inline void tasklet_enable(struct tasklet_struct *t);

            /*  tasklet_schedule - schedule a tasklet with type of TASKLET_SOFTIRQ.
             *  @t:                the tasklet it should be scheduled.
             *  #  this function call to the __tasklet_schedule()<kernel/softirq.c>,
             *     before the calling,the @t->state will be setted to TASKLET_STATE_SCHED.
             */
            static inline void tasklet_schedule(struct tasklet_struct *t);

            /*  tasklet_hi_schedule - schedule a tasklet with type of HI_SOFTIRQ.
             *  @t:                   the tasklet it should be scheduled.
             *  #  this function call to the __tasklet_hi_schedule()<kernel/softirq.c>,
             *     before the calling,the @t->state will be setted to TASKLET_STATE_SCHED.
             */
            static inline void tasklet_hi_schedule(struct tasklet_struct *t);

            !  if @t->state == TASKLET_STATE_SCHED
               then
                 tasklet_schedule() and tasklet_hi_schedule() return without something have been done.
               else
                 call to the internal functions defined in <kernel/softirq.c>

            __tasklet_schedule() and __tasklet_hi_schedule() :
              these two functions almost do the same works:
                1>  store local irq flags.
                2>  @t->next = NULL.
                3>  push @t to the tasklet_head link-list.
                4>  call to raise_softirq_irqoff().
                5>  restore local irq flags.

              the difference:
                __tasklet_schedule() push @t to the tail of local @tasklet_vec link-list.
                __tasklet_schedule() call raise_softirq_irqoff() with TASKLET_SOFTIRQ.
                __tasklet_hi_schedule() push @t to the tail of local @tasklet_hi_vec link-list.
                __tasklet_hi_schedule() call raise_softirq_irqoff() with HI_SOFTIRQ.

          <kernel/softirq.c>
            /*  tasklet_action - action function for TASKLET_SOFTIRQ type.
             *                   it is installed through open_softirq() by softirq_init().
             *  @a:              the softirq action structure.
             */
            static void tasklet_action(struct softirq_action *a);

            /*  tasklet_hi_action - action function for HI_SOFTIRQ type.
             *                      it is installed through open_softirq() by softirq_init().
             *  @a:                 the softirq action structure.
             */
            static void tasklet_hi_action(struct softirq_action *a);

            the works these two functions do:
              1>  disable local irq and retrive head of tasklet list.
              2>  empty the tasklet list.
              3>  enable local irq and enter a while-loop.
              4>  traverse the list to deal with each tasklet if it had not been disabled,
                  each tasklet only be actived once if it is not reactives itself.
                  if @t has been running on another cpu or it has been disabled,then it will
                  be push back to the tail of the tasklet list,raise_softirq_irqoff() will be
                  called before next loop.
              5>  traversed all tasklets in the list,function returns.
                  the new tasklet list will be deferred to the next time(it maybe contains
                  the running or disabled tasklets).

            !  while processing the tasklet,action function have to lock it(SMP) through tasklet_trylock() and
               unlock it after processed through tasklet_unlock().
               the two functions set tasklet_struct.state = TASKLET_STATE_RUN or unset it.
               /*  TASKLET_STATE_SCHED must be set before action by other kernel control path,
                *  otherwise,the bug occurred  */

          !  unless the tasklet function reactivates itself,every tasklet activation triggers at most one execution
             of the tasklet function.
